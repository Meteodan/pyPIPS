{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A notebook for computing the along-line average for the PIPS dataset from IOP2-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T14:40:32.290220Z",
     "start_time": "2020-06-24T14:40:28.958219Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid,make_axes_locatable,host_subplot\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "#import pyPIPS.disdrometer_module as dis\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "#import pyPIPS.simulator as sim\n",
    "import pyPIPS.pips_io as pipsio\n",
    "import pyPIPS.PIPS as pips\n",
    "import pyPIPS.parsivel_params as pp\n",
    "import pyPIPS.parsivel_qc as pqc\n",
    "import pyPIPS.polarimetric as dualpol\n",
    "import pyPIPS.timemodule as ptime\n",
    "# from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "# from pyCRMtools.pycaps import arps_read\n",
    "# from pyCRMtools.pycaps import pycaps_fields\n",
    "# from pyCRMtools.pycaps import calvars_radar as radar\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy.random as random\n",
    "from scipy.stats import gamma, uniform\n",
    "from scipy.special import gamma as gammafunc\n",
    "from scipy import ndimage\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.calc import wind_components\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.plots.wx_symbols import current_weather, sky_cover\n",
    "from metpy.units import units\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as feature\n",
    "# from natsort import natsorted\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(matplotlib.style.available)\n",
    "\n",
    "matplotlib.style.use('seaborn-v0_8-bright')\n",
    "\n",
    "def comp_plot(PIPS_names, ds_dict, varname='fasttemp', alpha=1.0, mask_below=None, x='time'):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    for PIPS_name in PIPS_names:\n",
    "        plotvar = ds_dict[PIPS_name][varname]\n",
    "        if mask_below is not None:\n",
    "            plotvar = plotvar.where(plotvar > mask_below)\n",
    "        plotvar.plot(ax=ax, label=PIPS_name, alpha=alpha, x=x)\n",
    "    ax.legend(loc='best')\n",
    "    return fig, ax\n",
    "\n",
    "def comp_var_plot(ds, varnames=['pcount', 'pcount_derived'], alpha=1.0, mask_below=None):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    for varname in varnames:\n",
    "        plotvar = ds[varname]\n",
    "        if mask_below is not None:\n",
    "            plotvar = plotvar.where(plotvar > mask_below)\n",
    "        plotvar.plot(ax=ax, label=varname, alpha=alpha)\n",
    "    ax.legend(loc='best')\n",
    "    return fig, ax\n",
    "\n",
    "# Define a formatter function to format the x-axis labels for timedeltas\n",
    "def time_formatter(x, pos):\n",
    "    td = pd.to_timedelta(x, unit='s')\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    if total_seconds < 0:\n",
    "        total_seconds = abs(total_seconds)\n",
    "        sign = \"-\"\n",
    "    else:\n",
    "        sign = \"\"\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f'{sign}{hours:02}:{minutes:02}:{seconds:02}'\n",
    "\n",
    "\n",
    "def adjust_time_coordinate(ds, gust_front_time):\n",
    "    # Calculate the relative time\n",
    "    relative_time = ds['time'] - gust_front_time\n",
    "    relative_time = relative_time.dt.total_seconds()\n",
    "    \n",
    "    # Assign the new coordinate\n",
    "    ds = ds.assign_coords(relative_time=relative_time)\n",
    "    \n",
    "    # Set the new time coordinate\n",
    "    ds = ds.swap_dims({'time': 'relative_time'})\n",
    "    \n",
    "    # Drop the old time coordinate if desired\n",
    "    # ds = ds.drop_vars('time')\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "def read_StickNet_locs_to_xarray(filepath):\n",
    "    \"\"\"Given the path to the StickNet locations file, read it into an xarray Dataset\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    ds = df.to_xarray()\n",
    "    ds = ds.assign_coords(ID=('index', ds['ID'].to_numpy()))\n",
    "    ds = ds.swap_dims({'index': 'ID'})\n",
    "\n",
    "    return ds\n",
    "\n",
    "def read_StickNet_level3_to_xarray(dir, deployment_name, probe_id, loc_ds):\n",
    "    \"\"\"Given the directory containing the level3 files and an xarray Dataset containing the location information,\n",
    "       read the data into an xarray Dataset\"\"\"\n",
    "    probe_filename = f\"0{probe_id}_{deployment_name}_level3.txt\"\n",
    "    probe_filepath = os.path.join(dir, probe_filename)\n",
    "    probe_df = pd.read_csv(probe_filepath)\n",
    "    # Set the time index\n",
    "    probe_df['Time'] = pd.DatetimeIndex(probe_df['Time'])\n",
    "    probe_df.set_index(\"Time\", inplace=True)\n",
    "    probe_ds = probe_df.to_xarray()\n",
    "\n",
    "    # Set location, probe id, start and end times, etc., as attributes\n",
    "    probe_ds.attrs['probe_name'] = probe_id\n",
    "    lat = loc_ds.sel(ID=probe_id)['Latitude'].to_numpy().item()\n",
    "    lon = loc_ds.sel(ID=probe_id)['Longitude'].to_numpy().item()\n",
    "    elev = loc_ds.sel(ID=probe_id)['Elevation'].to_numpy().item()\n",
    "    location_tuple = (lat, lon, elev)\n",
    "    probe_ds.attrs['location'] = str(location_tuple)\n",
    "    probe_ds.attrs['Array_Type'] = \"Fine\"\n",
    "    starting_time = probe_ds['Time'][0].dt.strftime(\"%Y%m%d%H%M%S\").item()\n",
    "    ending_time = probe_ds['Time'][-1].dt.strftime(\"%Y%m%d%H%M%S\").item()\n",
    "    probe_ds.attrs['starting_time'] = starting_time\n",
    "    probe_ds.attrs['ending_time'] = ending_time\n",
    "\n",
    "    return probe_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T14:40:48.238022Z",
     "start_time": "2020-06-24T14:40:47.848609Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# date = '052516' # '053122' # '030622' # '061416'\n",
    "\n",
    "PIPS_dir = \"/Users/dawson29/Projects/PERiLS/obsdata/2022/PIPS_data/IOP2_033022/netcdf\"\n",
    "deployment_name = \"IOP2_033022\"\n",
    "\n",
    "PIPS_names = ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS3B']\n",
    "parsivel_interval = 10\n",
    "parsivel_filenames = ['parsivel_combined_{}_{}_{:d}s.nc'.format(deployment_name, PIPS_name, parsivel_interval)\n",
    "                      for PIPS_name in PIPS_names]\n",
    "parsivel_filepaths = [os.path.join(PIPS_dir, parsivel_filename) for parsivel_filename in parsivel_filenames]\n",
    "conv_filenames = ['conventional_raw_{}_{}.nc'.format(deployment_name, PIPS_name) for PIPS_name in PIPS_names]\n",
    "conv_filepaths = [os.path.join(PIPS_dir, conv_filename) for conv_filename in conv_filenames]\n",
    "parsivel_ds_read_dict = {}\n",
    "conv_ds_read_dict = {}\n",
    "for PIPS_name, parsivel_filepath, conv_filepath in zip(PIPS_names, parsivel_filepaths, conv_filepaths):\n",
    "    parsivel_ds_read_dict[PIPS_name] = xr.load_dataset(parsivel_filepath)\n",
    "    conv_ds_read_dict[PIPS_name] = xr.load_dataset(conv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in StickNet data (level 3)\n",
    "\n",
    "stick_dir = \"/Users/dawson29/Projects/PERiLS/obsdata/2022/TTU_StickNet\"\n",
    "IOP_name = \"IOP2\"\n",
    "\n",
    "location_file = f\"{IOP_name}_StickNet_Locations.csv\"\n",
    "location_path = os.path.join(stick_dir, location_file)\n",
    "\n",
    "sticknet_locs_ds = read_StickNet_locs_to_xarray(location_path)\n",
    "sticknet_fine_locs_ds = sticknet_locs_ds.where(sticknet_locs_ds['Array_Type'] == 'Fine', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticknet_fine_locs_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticknet_fine_ids = sticknet_fine_locs_ds['ID'].to_numpy()\n",
    "\n",
    "sticknet_ds_list = [read_StickNet_level3_to_xarray(stick_dir, IOP_name, probe_id, sticknet_fine_locs_ds) for probe_id in sticknet_fine_ids]\n",
    "sticknet_ds_dict = {stick_id: stick_ds for stick_id, stick_ds in zip(sticknet_fine_ids, sticknet_ds_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ds_read_dict['PIPS1A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for PIPS_name in PIPS_names:\n",
    "    parsivel_ds = parsivel_ds_read_dict[PIPS_name]\n",
    "    print(parsivel_ds['time'][0], parsivel_ds['time'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to certain time range\n",
    "# start_time = '2022-05-31T23:00' # '2022-03-07T00:00'\n",
    "# end_time = '2022-06-01T00:05' # '2022-03-08T00:00'\n",
    "# start_time = '2022-03-30T23:40'\n",
    "# end_time = '2022-03-31T01:30'\n",
    "# start_time = '2023-03-12T00:15'\n",
    "# end_time = '2023-03-12T14:00'\n",
    "# start_time = '2023-02-22T16:00'\n",
    "# end_time = '2023-02-23T01:00'\n",
    "start_time = '2023-03-16T17:45'\n",
    "end_time = '2023-03-17T15:05'\n",
    "\n",
    "if False:\n",
    "    parsivel_ds_dict = {}\n",
    "    conv_ds_dict = {}\n",
    "    for PIPS_name in PIPS_names:\n",
    "        parsivel_ds_dict[PIPS_name] = parsivel_ds_read_dict[PIPS_name].sel(time=slice(start_time, end_time))\n",
    "        conv_ds_dict[PIPS_name] = conv_ds_read_dict[PIPS_name].sel(time=slice(start_time, end_time))\n",
    "else:\n",
    "    parsivel_ds_dict = parsivel_ds_read_dict\n",
    "    conv_ds_dict = conv_ds_read_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperatures\n",
    "fig, ax = comp_plot(PIPS_names, parsivel_ds_dict, 'fasttemp', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = comp_plot(sticknet_fine_ids, sticknet_ds_dict, 'T', alpha=0.5, x='Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the data a bit to remove short-range fluctuations\n",
    "window_size = 12 # Corresponds to 2 min for the 10-s data\n",
    "min_periods = 1\n",
    "\n",
    "for PIPS_name in PIPS_names:\n",
    "    parsivel_ds = parsivel_ds_dict[PIPS_name]\n",
    "    smooth_fasttemp = parsivel_ds['fasttemp'].rolling(time=window_size, center=True, min_periods=min_periods).mean()\n",
    "    parsivel_ds['smooth_fasttemp'] = smooth_fasttemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = comp_plot(PIPS_names, parsivel_ds_dict, 'smooth_fasttemp', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the 1st-order difference of the smoothed temperature field\n",
    "for PIPS_name in PIPS_names:\n",
    "    parsivel_ds = parsivel_ds_dict[PIPS_name]\n",
    "    diff_T = parsivel_ds['smooth_fasttemp'].diff(dim='time', label='upper')\n",
    "    # diff_T = diff_T.where(diff_T < -0.03, drop=True)\n",
    "    parsivel_ds['diff_fasttemp'] = diff_T\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the temperature difference in adjacent times\n",
    "fig, ax = comp_plot(PIPS_names, parsivel_ds_dict, 'diff_fasttemp', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plot, we see we can take the time of the *minimum* signed temp difference (the time where the temp is dropping the fastest)\n",
    "# as the reference time for the along line average\n",
    "# EDIT: It looks like a better criterion is for when the temperature drop rate first exceeds -0.06 deg C per 10 s (for the smoothed data)\n",
    "temp_drop_threshold = -0.06\n",
    "\n",
    "gust_front_times = {}\n",
    "for PIPS_name in PIPS_names:\n",
    "    # tindex = parsivel_ds_dict[PIPS_name]['diff_fasttemp'].argmin()\n",
    "    diff_T = parsivel_ds_dict[PIPS_name]['diff_fasttemp']\n",
    "    tindex = xr.where(diff_T < temp_drop_threshold, True, False).argmax(dim='time').item()\n",
    "    gust_front_time = parsivel_ds_dict[PIPS_name]['time'].isel(time=tindex).values\n",
    "    gust_front_times[PIPS_name] = gust_front_time\n",
    "    print(gust_front_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new time coordinate as time since gust front passage\n",
    "new_parsivel_ds_dict = {}\n",
    "for PIPS_name, parsivel_ds in parsivel_ds_dict.items():\n",
    "    gust_front_time = gust_front_times[PIPS_name]\n",
    "    new_parsivel_ds_dict[PIPS_name] = adjust_time_coordinate(parsivel_ds, gust_front_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = comp_plot(PIPS_names, new_parsivel_ds_dict, 'fasttemp', alpha=0.5, x='relative_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align datasets to common times\n",
    "aligned_datasets = xr.align(*new_parsivel_ds_dict.values(), join='inner')\n",
    "\n",
    "# Combine datasets into a new Dataset with a new dimension 'PIPS'\n",
    "combined_parsivel_ds = xr.concat(aligned_datasets, dim='PIPS')\n",
    "combined_parsivel_ds['PIPS'] = list(parsivel_ds_dict.keys())\n",
    "\n",
    "# Convert TimeDelta objects to seconds for plotting\n",
    "# combined_parsivel_ds = combined_parsivel_ds.assign_coords(\n",
    "#     seconds_since_gust_front=combined_parsivel_ds['relative_time'].dt.total_seconds()\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how to average winds. We can just take the direct average of the wind speeds, gust speeds, and u and v components\n",
    "# The rest we re-compute from the averaged u and v components\n",
    "var_da_dict = {}\n",
    "for var in ['windspd', 'windgust', 'uavg', 'vavg']:\n",
    "    var_da_dict[var] = combined_parsivel_ds[var].mean(dim='PIPS', skipna=True)\n",
    "\n",
    "# Compute vector average wind speed\n",
    "var_da_dict['windspdavgvec'] = np.sqrt(var_da_dict['uavg']**2. + var_da_dict['vavg']**2.)\n",
    "# Compute vector average wind direction\n",
    "var_da_dict['winddirabs'] = (270.0 - (180. / np.pi) * np.arctan2(var_da_dict['vavg'], var_da_dict['uavg'])) % 360.\n",
    "\n",
    "# Compute unit average wind speed/direction\n",
    "unit_u = combined_parsivel_ds['uavg'] / combined_parsivel_ds['windspd']\n",
    "unit_v = combined_parsivel_ds['vavg'] / combined_parsivel_ds['windspd']\n",
    "unit_u_avg = unit_u.mean(dim='PIPS', skipna=True)\n",
    "unit_v_avg = unit_v.mean(dim='PIPS', skipna=True)\n",
    "\n",
    "wind_dir_unit_vec_avg = (270.0 - (180. / np.pi) * np.arctan2(unit_v_avg, unit_u_avg)) % 360.\n",
    "wind_dir_unit_vec_avg = xr.where((unit_u_avg == 0.) & (unit_v_avg == 0.), np.nan, wind_dir_unit_vec_avg)\n",
    "\n",
    "var_da_dict['unit_uavg'] = unit_u_avg\n",
    "var_da_dict['unit_vavg'] = unit_v_avg\n",
    "var_da_dict['winddirunitavgvec'] = wind_dir_unit_vec_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'winddirunitavgvec'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "var_da_dict[var].plot(ax=ax, label='avg')\n",
    "combined_parsivel_ds.sel(PIPS='PIPS1A')[var].plot(ax=ax, label='PIPS1A')\n",
    "combined_parsivel_ds.sel(PIPS='PIPS1B')[var].plot(ax=ax, label='PIPS1B')\n",
    "combined_parsivel_ds.sel(PIPS='PIPS2A')[var].plot(ax=ax, label='PIPS2A')\n",
    "combined_parsivel_ds.sel(PIPS='PIPS3B')[var].plot(ax=ax, label='PIPS3B')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "spd = np.sqrt(var_da_dict['unit_uavg']**2. + var_da_dict['unit_vavg']**2.)\n",
    "spd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spd = np.sqrt(combined_parsivel_ds.sel(PIPS='PIPS1A')['unit_uavg']**2. + combined_parsivel_ds.sel(PIPS='PIPS1A')['unit_vavg']**2.)\n",
    "spd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the average across the 'PIPS' dimension\n",
    "parsivel_average_ds = combined_parsivel_ds.mean(dim='PIPS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_parsivel_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_new_parsivel_dict = {}\n",
    "for PIPS_name in PIPS_names:\n",
    "    new_new_parsivel_dict[PIPS_name] = combined_parsivel_ds.sel(PIPS=PIPS_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = comp_plot(PIPS_names, new_new_parsivel_dict, 'fasttemp', alpha=0.5, x='relative_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "parsivel_average_ds['fasttemp'].plot(ax=ax, x='relative_time')\n",
    "\n",
    "# Format the x-axis\n",
    "# ax.xaxis.set_major_formatter(ticker.FuncFormatter(time_formatter))\n",
    "ax.set_xlabel('Time since gust front passage (s)')\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(900.))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(300.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSD_times = parsivel_average_ds['relative_time']\n",
    "PSD_times_dict = pips.get_PSD_time_bins(PSD_times)\n",
    "\n",
    "\n",
    "PSD_times_dict['PSD_datetimes_edges'].astype('timedelta64[s]').astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute polarimetric fields from PIPS DSDs\n",
    "dD = parsivel_average_ds['max_diameter'] - parsivel_average_ds['min_diameter']\n",
    "dualpol_dict_PIPS_avg = dualpol.calpolrain_bulk_xr(10.7, \n",
    "                                                   '/Users/dawson29/Projects/pyPIPS/tmatrix/S-Band/SCTT_RAIN_fw100.dat',\n",
    "                                                   parsivel_average_ds['ND_roqc'], dD, diameter_bin_name='diameter_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dualpol_dict_PIPS_avg.keys()\n",
    "\n",
    "dualpol_dict_PIPS_avg['REF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot observed DSD meteograms\n",
    "\n",
    "ND_PIPS = parsivel_average_ds['ND_roqc']\n",
    "# ND_PIPS = combined_parsivel_ds.sel(PIPS='PIPS3B')['ND_roqc']\n",
    "ZH_PIPS = dualpol_dict_PIPS_avg['REF']\n",
    "ZH_rad = parsivel_average_ds['KGWX_at_PIPS'].loc[{'fields_KGWX': 'REF_filtered'}]\n",
    "\n",
    "# Truncate diameter range to less than 9 mm\n",
    "D_max = 9.\n",
    "D_range_full = ND_PIPS['diameter'].values\n",
    "D_max_ind = np.searchsorted(D_range_full, D_max)\n",
    "D_range = D_range_full[:D_max_ind]\n",
    "print(D_max_ind, D_range)\n",
    "ND_trunc = ND_PIPS.isel(diameter_bin=slice(0, D_max_ind))\n",
    "\n",
    "PSD_datetimes_PIPS = parsivel_average_ds['relative_time']  # pips.get_PSD_datetimes(ND_PIPS)\n",
    "PSD_datetimes_PIPS_dict = pips.get_PSD_time_bins(PSD_datetimes_PIPS)\n",
    "# PSDstarttimes = dates.date2num(PSD_datetimes_PIPS_dict['PSD_datetimes_edges'])\n",
    "# PSDmidtimes = dates.date2num(PSD_datetimes_PIPS_dict['PSD_datetimes_centers'])\n",
    "\n",
    "# Gotcha! For some reason the following only works because the dictionary entries are numpy arrays, not xarray DataArrays.\n",
    "# If they are the latter, I suppose we would have to extract the underlying numpy array, recast it, and then save the data back\n",
    "# to the original DataArray\n",
    "PSDstarttimes = PSD_datetimes_PIPS_dict['PSD_datetimes_edges'].astype('timedelta64[s]').astype('int')\n",
    "PSDmidtimes = PSD_datetimes_PIPS_dict['PSD_datetimes_centers'].astype('timedelta64[s]').astype('int')\n",
    "\n",
    "plot_start_datetime = PSDstarttimes[0]\n",
    "plot_end_datetime = PSDstarttimes[-1]\n",
    "\n",
    "# Prepare axis parameters\n",
    "timelimits = [plot_start_datetime, plot_end_datetime]\n",
    "diamlimits = [0.0, 9.0]\n",
    "diamytick = 1.0\n",
    "DSDtype = 'observed'\n",
    "locator = ticker.MultipleLocator(900) # dates.MinuteLocator(byminute=[0,15,30,45])\n",
    "minorlocator = ticker.MultipleLocator(300) # dates.MinuteLocator(byminute=range(0,60,5))\n",
    "dateformat = '%H:%M'\n",
    "formatter = None #  dates.DateFormatter(dateformat)\n",
    "\n",
    "axparams = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "            'minorxlocator': minorlocator,\n",
    "            'axeslimits': [timelimits, diamlimits],\n",
    "            'majorylocator': ticker.MultipleLocator(base=diamytick),\n",
    "            'axeslabels': [None, 'D (mm)']}\n",
    "\n",
    "logND = np.log10(ND_trunc)\n",
    "logND = logND.where(logND > -1.0)\n",
    "\n",
    "# Ok, now we should have everything ready to go to plot the meteograms.\n",
    "# Let'er rip!\n",
    "\n",
    "# D0 = D0_PIPS_interp_to_model_times_dict[dis_name] * 1000. # Get to mm again\n",
    "# dBZ = dBZ_PIPS_interp_to_model_times_dict[dis_name]\n",
    "# ZDR = dualpol_PIPS_interp_to_model_times_dict[dis_name]['ZDR']\n",
    "\n",
    "diameter_bin_edges = pp.parsivel_parameters['diameter_bin_edges_mm']\n",
    "diameter_bin_edges = diameter_bin_edges[:D_max_ind+1]\n",
    "\n",
    "disvars = {'diameter_bin_edges': diameter_bin_edges, 'PSDstarttimes': PSDstarttimes,\n",
    "           'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'REF': ZH_PIPS} # , 'D_m': Dm_sorted_PIPS_da, 'dBZ': ZH_sorted_PIPS_da, \n",
    "           # 'ZDR': ZDR_sorted_PIPS_da}\n",
    "\n",
    "# radvars = None\n",
    "radvars = {'radmidtimes': PSDmidtimes, 'REF': ZH_rad}\n",
    "\n",
    "plot_dir = './'\n",
    "dis_plot_name = 'PIPSAVG_' + DSDtype\n",
    "PIPSplot.plotDSDmeteograms(dis_plot_name, plot_dir, axparams, disvars, radvars=radvars, close_fig=False, use_plot_date=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsivel_average_ds"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pyPIPS]",
   "language": "python",
   "name": "conda-env-pyPIPS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:11:21.970271Z",
     "start_time": "2021-04-20T16:11:17.718992Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid, make_axes_locatable, host_subplot\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "#import pyPIPS.disdrometer_module as dis\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "#import pyPIPS.simulator as sim\n",
    "import pyPIPS.pips_io as pipsio\n",
    "import pyPIPS.PIPS as pips\n",
    "import pyPIPS.parsivel_params as pp\n",
    "import pyPIPS.parsivel_qc as pqc\n",
    "import pyPIPS.radarmodule as radar\n",
    "import pyPIPS.polarimetric as dualpol\n",
    "#from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy.random as random\n",
    "from scipy.stats import gamma, uniform\n",
    "from scipy.special import gamma as gammafunc\n",
    "from scipy import ndimage\n",
    "from scipy import interpolate\n",
    "from metpy.plots import StationPlot\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.calc import wind_components\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.plots.wx_symbols import current_weather, sky_cover\n",
    "from metpy.units import units\n",
    "from scipy.signal import medfilt2d\n",
    "import pyart\n",
    "import cartopy.crs as ccrs\n",
    "from IPython.display import HTML\n",
    "from io import StringIO\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:11:24.052477Z",
     "start_time": "2021-04-20T16:11:23.921311Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "def readsound(path,stype,rmqc=False):\n",
    "    \"\"\"Reads in a sounding from a text file and returns a pandas dataframe. Accepts various formats.\"\"\"\n",
    "    if(stype == 'ESC'):\n",
    "        return readESC(path)\n",
    "    elif(stype == 'CM1'):\n",
    "        return readCM1(path)\n",
    "    elif(stype == 'sharppy'):\n",
    "        return readsharppy(path)\n",
    "    else:\n",
    "        print(\"Sounding type not supported\")\n",
    "        return\n",
    "    \n",
    "def readCM1(path):\n",
    "    \"\"\"Reads in a sounding in CM1 (or COMMAS) input sounding format\"\"\"\n",
    "    col_names = ['height','potential temperature','water vapor mixing ratio','u_wind','v_wind']\n",
    "    with open(path) as f:\n",
    "        header = f.readline().strip().split()\n",
    "    psfc = np.float(header[0])\n",
    "    thetasfc = np.float(header[1])\n",
    "    qvsfc = np.float(header[2])\n",
    "    # Check whether mixing ratio is in g/kg or kg/kg and convert to kg/kg if needed\n",
    "    qvscale = 1.\n",
    "    if qvsfc > 0.1:\n",
    "        qvscale = 1.e-3\n",
    "    qvsfc = qvsfc*qvscale\n",
    "    df = pd.read_csv(path, skiprows=1, names=col_names, delim_whitespace=True)\n",
    "    df['water vapor mixing ratio'] = df['water vapor mixing ratio'].values*qvscale\n",
    "    # Check that height is in m, in some cases it's in km and needs to be converted\n",
    "    # z = df['height'].values\n",
    "    # If the final height is < 100. assume that the units are km and convert to m\n",
    "    if(df['height'].values[-1] < 100.):\n",
    "        df['height'] = df['height'].values*1000.\n",
    "    # Compute pressure\n",
    "    p = compute_pressure(df['height'].values, df['potential temperature'].values, \n",
    "                         df['water vapor mixing ratio'].values, psfc, qvsfc, thetasfc)\n",
    "    df['pressure'] = p\n",
    "    # Compute temperature\n",
    "    df['temperature'] = thermo.calT(df['pressure'].values*100., df['potential temperature'].values)-273.15\n",
    "    # Compute water vapor specific humidity and dewpoint\n",
    "    wv = df['water vapor mixing ratio'].values\n",
    "    df['water vapor specific humidity'] = wv/(1.+wv)\n",
    "    df['dewpoint'] = thermo.calTd(df['pressure'].values*100., df['water vapor specific humidity'].values)-273.15\n",
    "    return df\n",
    "\n",
    "def readESC(sounding_path, interpnan=True, handle=False):\n",
    "    \"\"\"\n",
    "    Reads in a sounding in ESC format from a provided file path or handle (can be a StringIO object or an open\n",
    "    file handle)\n",
    "    \"\"\"\n",
    "    col_names = ['pressure','temperature','dewpoint','u_wind','v_wind','speed','direction','height',\n",
    "                 'Qp_code','Qt_code','Qrh_code','Qu_code','Qv_code']\n",
    "    # First read the file and extract the field widths from the 14th header line\n",
    "    if not handle:\n",
    "        f = open(sounding_path, 'r')\n",
    "    else:\n",
    "        f = sounding_path\n",
    "\n",
    "    # Read in the header and extract some metadata from it\n",
    "    dummy = f.readline()\n",
    "    dummy = f.readline()\n",
    "    header2 = f.readline().strip().split(':')\n",
    "    # Read next header line and extract station id and wmo number from it (if it exists)\n",
    "    staid_wmo_str = header2[1]\n",
    "    if ' / ' in staid_wmo_str:\n",
    "        staid_wmo = staid_wmo_str.strip().split(' / ')\n",
    "        staid = staid_wmo[0][1:4]\n",
    "        wmo = int(staid_wmo[1])\n",
    "    else:\n",
    "        if '. ' in staid_wmo_str:\n",
    "            staid = staid_wmo_str.replace('. ', '').strip()[:4]\n",
    "        else:\n",
    "            staid = staid_wmo_str.strip()[:4]\n",
    "            staid = staid.replace(\" \", \"\")\n",
    "        wmo = 99999\n",
    "    print(staid)\n",
    "    # Read the next header line and extract the location information from it\n",
    "    header3 = f.readline().strip().split(':')\n",
    "    location = header3[1].strip().split(',')\n",
    "    print(location)\n",
    "    lon = np.float(location[2])\n",
    "    lat = np.float(location[3])\n",
    "    elev = np.float(location[4])\n",
    "    # Read the next header line and extract the time information from it\n",
    "    header4 = f.readline().strip()[31:].lstrip()   \n",
    "    sounding_datetime = datetime.strptime(header4, '%Y, %m, %d, %H:%M:%S')\n",
    "    \n",
    "    # Now read and dump the rest of the header\n",
    "    for i in range(9):\n",
    "        f.readline()\n",
    "    \n",
    "    # Except for the last header line, which is used to determine the widths of the fields\n",
    "    line = f.readline().strip().split()\n",
    "    fw = [len(field)+1 for field in line]\n",
    "\n",
    "    # Now read the file into the dataframe, using the extracted field widths\n",
    "    df = pd.read_fwf(f, usecols=[1, 2, 3, 5, 6, 7, 8, 14, 15, 16, 17, 18, 19],\n",
    "                     names=col_names, na_values=['99999.0', '9999.0', '999.0'], widths=fw)\n",
    "    \n",
    "    # For some reason, need to convert all the columns to floating point here, as some get interpreted as strings\n",
    "    # when they shouldn't be...\n",
    "    # print(df['pressure'], df['temperature'])\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].astype(np.float)\n",
    "    \n",
    "    # Drop rows where height or pressure is NaN. TODO: Can't remember why I have to use reset_index(drop=True). \n",
    "    # Figure this out.\n",
    "    df = df.dropna(subset=('height', 'pressure')).reset_index(drop=True)\n",
    "    # Set the height as the index so we can use it as weights to interpolate other columns across NaN\n",
    "    df = df.set_index('height')\n",
    "    df['height'] = df.index\n",
    "    \n",
    "    if interpnan:\n",
    "        # First convert direction and speed to u, v components\n",
    "        df['u'], df['v'] = mpcalc.wind_components(df['speed'].values*units('m/s'),\n",
    "                                                      df['direction'].values*units.degrees)\n",
    "        # Now interpolate\n",
    "        df = df.interpolate(method='values')\n",
    "        # Finally recompute direction and speed from u, v components\n",
    "        df['speed'] = mpcalc.wind_speed(df['u'].values*units('m/s'), df['v'].values*units('m/s'))\n",
    "        df['direction'] = mpcalc.wind_direction(df['u'].values*units('m/s'), df['v'].values*units('m/s'))\n",
    "    else:\n",
    "        # Drop any rows with all NaN values for T, Td, winds\n",
    "        df = df.dropna(subset=('temperature', 'dewpoint', 'direction', 'speed',\n",
    "                               'u_wind', 'v_wind'), how='all').reset_index(drop=True)\n",
    "    \n",
    "    df = df[(df.Qp_code == 1.0) & (df.Qt_code == 1.0) & (df.Qrh_code == 1.0) & (df.Qu_code == 1.0) & \n",
    "            (df.Qv_code == 1.0)]\n",
    "\n",
    "    nlines = df.count()['pressure']\n",
    "    \n",
    "    if not handle:\n",
    "        f.close()\n",
    "    \n",
    "    snd_metadata = {\n",
    "        'sounding_datetime': sounding_datetime,\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'selev': elev,\n",
    "        'staid': staid,\n",
    "        'wmo': wmo,\n",
    "        'nlevs': nlines,\n",
    "        'staid_long': staid_wmo_str\n",
    "    }\n",
    "    \n",
    "    return snd_metadata, df\n",
    "\n",
    "\n",
    "def readsharppy(path):\n",
    "    \"\"\"Reads in a sounding in sharppy format\"\"\"\n",
    "        ## read in the file\n",
    "    f = open(path, 'r')\n",
    "    lines = f.read()\n",
    "    data = np.array([l.strip() for l in lines.split('\\n')])\n",
    "    f.close()\n",
    "\n",
    "    ## necessary index points\n",
    "    title_idx = np.where( data == '%TITLE%')[0][0]\n",
    "    start_idx = np.where( data == '%RAW%' )[0][0] + 1\n",
    "    finish_idx = np.where( data == '%END%')[0][0]\n",
    "    \n",
    "    ## create the plot title\n",
    "    data_header = data[title_idx + 1].split()\n",
    "    location = data_header[0]\n",
    "    time = data_header[1][:11]\n",
    "\n",
    "    ## put it all together for StringIO\n",
    "    full_data = '\\n'.join(data[start_idx : finish_idx][:])\n",
    "    sound_data = StringIO( full_data )\n",
    "\n",
    "    ## read the data into arrays\n",
    "    p, h, T, Td, wdir, wspd = np.genfromtxt( sound_data, delimiter=',', comments=\"%\", unpack=True )\n",
    "    \n",
    "    col_names = ['pressure','height','temperature','dewpoint','speed','direction']\n",
    "    data_dict = {key:value for (key,value) in zip(col_names,[p,h,T,Td,wspd,wdir])}\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(data_dict)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def roundPartial(value, resolution, decimals=4):\n",
    "    return np.around(np.round(value / resolution) * resolution, decimals=decimals)\n",
    "\n",
    "\n",
    "def rain_Brandes(D):\n",
    "    \"\"\"Given a range of diameters D, compute rain fall speed curve, a quartic polynomial\n",
    "       fit after Brandes et al. (2002).\"\"\"\n",
    "    \n",
    "    D_mm=D*1000. # get it to (mm)\n",
    "    \n",
    "    Vtr = -0.1021 + 4.932*D_mm - 0.9551*D_mm**2. + 0.07934*D_mm**3. - 0.002362*D_mm**4.\n",
    "    \n",
    "    return Vtr\n",
    "\n",
    "\n",
    "def cal_xf_tf(usm, vsm, vt, H, perturb_vt=False, sigma=0.1):\n",
    "    \"\"\"Computes final horizontal position and residence time (relative to starting position) of a raindrop\n",
    "       falling through a horizontally homogeneous layer H with terminal velocity vt and \n",
    "       storm releative mean wind given by (usm, vsm).\"\"\"\n",
    "    \n",
    "    if perturb_vt:\n",
    "        rng = np.random.default_rng()\n",
    "        vt_perts = sigma * rng.standard_normal(vt.size)\n",
    "        vt = vt + vt_perts\n",
    "    \n",
    "    tf = H / vt\n",
    "    xf = tf * usm\n",
    "    yf = tf * vsm\n",
    "    \n",
    "    return xf, yf, tf\n",
    "\n",
    "\n",
    "def mtokm(val,pos):\n",
    "    \"\"\"Convert m to km for formatting axes tick labels\"\"\"\n",
    "    val=val/1000.0\n",
    "    return '%i' % val\n",
    "\n",
    "def interpolate_all(gridded_radar, tinterp_intv, base_field_name='reflectivity_masked'):\n",
    "    # Get list of intervals in seconds between subsequent radar times\n",
    "    tdiffs = gridded_radar['time_seconds'].diff(dim='time')\n",
    "    \n",
    "    # This list will hold all the time-interpolated grids (xarray Datasets). \n",
    "    # Can later be concatenated into a new xarray Dataset containing all times\n",
    "    gridded_radar_interp_list = []\n",
    "    \n",
    "    # Grab first time from full dataset and restore singular time dimension\n",
    "    first_time_ds = gridded_radar.isel(time=0)\n",
    "    first_time_ds = first_time_ds.expand_dims(dim='time')\n",
    "\n",
    "    gridded_radar_interp_list.append(first_time_ds)\n",
    "    \n",
    "#     tbgn = first_time_ds.coords['time_seconds'].values.item()  # Need to get scalar value, not 0-d\n",
    "#                                                                # numpy array\n",
    "    \n",
    "    # Loop through the gridded_radar times, perform advection correction/interpolation between successive times\n",
    "    # and add each to the list, making sure the time coordinate is consistent\n",
    "    # new_time = tbgn\n",
    "    for i, tdiff in enumerate(tdiffs.values):\n",
    "        gridded_radar_interp_sublist = advection_correction_ds(gridded_radar.isel(time=slice(i, i+2)), \n",
    "                                                               tdiff, tinterp_intv, \n",
    "                                                               base_field_name=base_field_name)\n",
    "        for t, gridded_radar_interp in enumerate(gridded_radar_interp_sublist):\n",
    "#             new_time = new_time + tinterp_intv\n",
    "#             new_ds = first_time_ds.copy()\n",
    "#             new_ds[:] = gridded_radar_interp\n",
    "#             new_ds.coords['time'] = new_ds['time'] + np.timedelta64(int(new_time), 's')\n",
    "#             new_ds.coords['time_seconds'] = new_time\n",
    "            gridded_radar_interp_list.append(gridded_radar_interp)\n",
    "    \n",
    "    return gridded_radar_interp_list\n",
    "\n",
    "\n",
    "def advection_correction_ds(radar_ds, tintv_obs, tintv, base_field_name='reflectivity_masked', method=\"LK\"):\n",
    "    # Evaluate advection\n",
    "    oflow_method = motion.get_method(method)\n",
    "    fd_kwargs = {\"buffer_mask\": 10}  # avoid edge effects\n",
    "\n",
    "    base_field = radar_ds[base_field_name]\n",
    "    oflow_field = oflow_method(base_field, fd_kwargs=fd_kwargs)\n",
    "    \n",
    "    # Perform temporal interpolation on all variables in Dataset using the flow field derived from the \"base\"\n",
    "    # field (by default, reflectivity)\n",
    "    \n",
    "    tbgn = base_field[0].coords['time_seconds'].values.item()   # Need to get scalar value, not 0-d\n",
    "                                                                # numpy array\n",
    "    \n",
    "    radar_ds_list = []\n",
    "    x, y = np.meshgrid(\n",
    "        np.arange(base_field[0].shape[1], dtype=float), np.arange(base_field[0].shape[0], dtype=float),\n",
    "    )\n",
    "    \n",
    "    new_time = tbgn\n",
    "    for i in np.arange(tintv, tintv_obs + tintv, tintv):\n",
    "\n",
    "        new_time = new_time + tintv\n",
    "        \n",
    "        pos1 = (y - i / tintv_obs * oflow_field[1], x - i / tintv_obs * oflow_field[0])\n",
    "        pos2 = (y + (tintv_obs - i) / tintv_obs * oflow_field[1], \n",
    "                x + (tintv_obs - i) / tintv_obs * oflow_field[0])\n",
    "        \n",
    "        field_interp_list = []\n",
    "        for field_name, field_da in radar_ds.items():\n",
    "            fieldt1 = map_coordinates(field_da[0], pos1, order=1)\n",
    "            fieldt2 = map_coordinates(field_da[1], pos2, order=1)\n",
    "       \n",
    "            field_interp = field_da.isel(time=[0]).copy()\n",
    "            field_interp[:] = ((tintv_obs - i) * fieldt1 + i * fieldt2) / tintv_obs\n",
    "            field_interp.coords['time'] = field_interp['time'] + np.timedelta64(int(new_time - tbgn), 's')\n",
    "            field_interp.coords['time_seconds'] = new_time\n",
    "            field_interp_list.append(field_interp)\n",
    "        \n",
    "        radar_ds_interp = xr.merge(field_interp_list)\n",
    "        radar_ds_list.append(radar_ds_interp)\n",
    "        \n",
    "    return radar_ds_list\n",
    "\n",
    "\n",
    "def advection_correction(arr, tintv_obs, tintv):\n",
    "    \"\"\"\n",
    "    R = np.array([qpe_previous, qpe_current])\n",
    "    T = time between two observations (5 min)\n",
    "    t = interpolation timestep (1 min)\n",
    "    \"\"\"\n",
    "\n",
    "    # Evaluate advection\n",
    "    oflow_method = motion.get_method(\"LK\")\n",
    "    fd_kwargs = {\"buffer_mask\": 10}  # avoid edge effects\n",
    "    V = oflow_method(arr, fd_kwargs=fd_kwargs)\n",
    "\n",
    "    # Perform temporal interpolation\n",
    "    # arr_d = np.zeros((arr[0].shape))\n",
    "    arr_list = []\n",
    "    x, y = np.meshgrid(\n",
    "        np.arange(arr[0].shape[1], dtype=float), np.arange(arr[0].shape[0], dtype=float),\n",
    "    )\n",
    "    for i in np.arange(tintv, tintv_obs + tintv, tintv):\n",
    "\n",
    "        pos1 = (y - i / tintv_obs * V[1], x - i / tintv_obs * V[0])\n",
    "        R1 = map_coordinates(arr[0], pos1, order=1)\n",
    "        \n",
    "        pos2 = (y + (tintv_obs - i) / tintv_obs * V[1], x + (tintv_obs - i) / tintv_obs * V[0])\n",
    "        R2 = map_coordinates(arr[1], pos2, order=1)\n",
    "\n",
    "        arr_interp = ((tintv_obs - i) * R1 + i * R2) / tintv_obs\n",
    "        arr_list.append(arr_interp)\n",
    "\n",
    "    return arr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:11:24.923391Z",
     "start_time": "2021-04-20T16:11:24.779043Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the gridded radar data\n",
    "radar_name = 'KGWX'\n",
    "radar_type= 'NEXRAD'\n",
    "\n",
    "# For 04/30 case\n",
    "# date = '0430'\n",
    "# radar_start_datetimestamp = '20170430190000'\n",
    "# radar_end_datetimestamp = '20170430235959'\n",
    "# height = 1000.\n",
    "\n",
    "# For 03/27 case\n",
    "# date = '0327'\n",
    "# radar_start_datetimestamp = '20170327190000'\n",
    "# radar_end_datetimestamp = '20170327220000'\n",
    "# height = 1000.\n",
    "\n",
    "# For 03/27 case, deployment 1\n",
    "#date = '0327'\n",
    "radar_start_datetimestamp = '20170327190000'\n",
    "radar_end_datetimestamp = '20170327235900'\n",
    "height = 1000.\n",
    "\n",
    "# Create datetime objects for start and end times\n",
    "datetime_start = datetime.strptime(radar_start_datetimestamp, '%Y%m%d%H%M%S')\n",
    "datetime_end = datetime.strptime(radar_end_datetimestamp, '%Y%m%d%H%M%S')\n",
    "\n",
    "radar_basedir = \\\n",
    "    '/Users/terrell8/sshfs_mounts/depot/data/Projects/VORTEXSE/obsdata/2017/NEXRAD/IOP_1B'\n",
    "# FIXME: need to standardize naming of radar data directories\n",
    "# radar_basedir = os.path.join(radar_basedir, '{}/{}'.format(date, radar_name[1:]))\n",
    "gridded_radar_dir = os.path.join(radar_basedir, 'gridded_new')\n",
    "\n",
    "radar_start_timestamp = datetime_start.strftime('%Y%m%d%H%M')\n",
    "radar_end_timestamp = datetime_end.strftime('%Y%m%d%H%M')\n",
    "gridded_radar_interp_filename = '{}_{}_{}_z{:d}_gridded_interp.nc'.format(radar_name, radar_start_timestamp,\n",
    "                                                                          radar_end_timestamp, int(height))\n",
    "gridded_radar_interp_filepath = os.path.join(gridded_radar_dir, gridded_radar_interp_filename)\n",
    "\n",
    "gridded_radar_interp_ds = xr.open_dataset(gridded_radar_interp_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:11:31.587429Z",
     "start_time": "2021-04-20T16:11:31.508425Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_dir = '/Users/terrell8/Dropbox/Presentations/IOP_1B/New_D1_precip_traj'\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:11:35.460163Z",
     "start_time": "2021-04-20T16:11:34.805917Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in PIPS data (just to get lat/lon for now)\n",
    "deployment = 'IOP1B_D1_2017'\n",
    "PIPS_list = ['PIPS1A', 'PIPS1B', 'PIPS2B']\n",
    "PIPS_data_dir = '/Users/terrell8/sshfs_mounts/depot/data/Projects/VORTEXSE/obsdata/full_PIPS_dataset_RB15'\n",
    "\n",
    "PIPS_ds_list = []\n",
    "PIPS_locs = []\n",
    "\n",
    "for PIPS in PIPS_list:\n",
    "    PIPS_filename = 'parsivel_combined_{}_{}_60s.nc'.format(deployment, PIPS)\n",
    "    PIPS_filepath = os.path.join(PIPS_data_dir, PIPS_filename)\n",
    "    PIPS_ds = xr.load_dataset(PIPS_filepath)\n",
    "    PIPS_ds_list.append(PIPS_ds)\n",
    "    PIPS_loc = eval(PIPS_ds.location)\n",
    "    PIPS_locs.append(PIPS_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'KGWX_beam_height_at_PIPS' ()>\n",
      "array(2323.83469914)\n",
      "<xarray.DataArray 'KGWX_beam_height_at_PIPS' ()>\n",
      "array(1854.59417135)\n",
      "<xarray.DataArray 'KGWX_beam_height_at_PIPS' ()>\n",
      "array(1881.69744907)\n"
     ]
    }
   ],
   "source": [
    "for PIPS_ds in PIPS_ds_list:\n",
    "    print(PIPS_ds[\"KGWX_beam_height_at_PIPS\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:11:43.305214Z",
     "start_time": "2021-04-20T16:11:43.183556Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in sounding file to get low-level wind field and then derive storm-relative wind\n",
    "# Storm motion taken from subjective reflectivity tag tracking using GRLevel2\n",
    "# EDIT: don't need storm motion because it is implicitly handled in time-dependent trajectory model\n",
    "ustorm = 12.51\n",
    "vstorm = 12.95\n",
    "\n",
    "# EDIT: setting ustorm, vstorm to 0 to force ground-relative flow\n",
    "ustorm = 0.\n",
    "vstorm = 0.\n",
    "\n",
    "# For 04/30 case\n",
    "# sounding_dir = '/Users/dawson29/sshfs_mounts/depot/data/Projects/VORTEXSE/obsdata/2017/soundings/COMP5mb'\n",
    "# sounding_filename = 'Hollywood_201704301954.cls'\n",
    "\n",
    "# For 03/27 case\n",
    "# sounding_dir = '/Users/dawson29/Projects/plotsnd/notebooks/'\n",
    "# sounding_filename = '201703272100_3469_8600.sharppy'\n",
    "\n",
    "# For 03/27 case (D1)\n",
    "sounding_dir = '/Users/terrell8/Dropbox/0327_soundings/soundings/'\n",
    "sounding_filename = 'Haleyville_20170327_D1_1924.cls'\n",
    "\n",
    "sounding_path = os.path.join(sounding_dir, sounding_filename)\n",
    "\n",
    "# For 04/30 case\n",
    "sounding_metadata, sounding_df = readESC(sounding_path)\n",
    "\n",
    "# For 03/27 case\n",
    "#sounding_df = readsharppy(sounding_path)\n",
    "#wind_dir = sounding_df['direction'].values*units.degrees\n",
    "#print(wind_dir)\n",
    "#wind_speed_kts = sounding_df['speed'].values*units.knots \n",
    "#wind_speed_ms = wind_speed_kts.to(units('m/s'))\n",
    "#print(wind_speed_ms)\n",
    "#u, v = wind_components(wind_speed_ms, wind_dir)\n",
    "#print(u, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:12:17.276731Z",
     "start_time": "2021-04-20T16:11:45.987654Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find PIPS x, y location by interpolating to its lat/lon point\n",
    "gridded_radar_interp_latlon_ds = gridded_radar_interp_ds.swap_dims({'x': 'lon', 'y': 'lat'})\n",
    "\n",
    "radar_at_PIPS_list = []\n",
    "PIPS_xy_list = []\n",
    "\n",
    "for PIPS_loc in PIPS_locs:\n",
    "    PIPS_lat = PIPS_loc[0]\n",
    "    PIPS_lon = PIPS_loc[1]\n",
    "    radar_at_PIPS_da = gridded_radar_interp_latlon_ds.interp(lat=PIPS_lat, lon=PIPS_lon)\n",
    "    print(PIPS_lat, PIPS_lon)\n",
    "    PIPS_x = radar_at_PIPS_da['x'].values.item()\n",
    "    PIPS_y = radar_at_PIPS_da['y'].values.item()\n",
    "    PIPS_xy = (PIPS_x, PIPS_y)\n",
    "    PIPS_xy_list.append(PIPS_xy)\n",
    "    print(PIPS_x, PIPS_y)\n",
    "    radar_at_PIPS_list.append(radar_at_PIPS_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:12:20.541944Z",
     "start_time": "2021-04-20T16:12:20.468320Z"
    }
   },
   "outputs": [],
   "source": [
    "# Choose a subset of times to keep animation size down\n",
    "# For 04/30 case\n",
    "\n",
    "# anim_start = '2017-04-30T19:30'\n",
    "# anim_end = '2017-04-30T21:00'\n",
    "\n",
    "# For 03/27 case\n",
    "\n",
    "# anim_start = '2017-03-27T19:30'\n",
    "# anim_end = '2017-03-27T21:00'\n",
    "\n",
    "\n",
    "anim_start = '2017-03-27T19:00'\n",
    "anim_end = '2017-03-27T22:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:15:17.819141Z",
     "start_time": "2021-04-20T16:14:44.402360Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot reflectivity for time-interpolated grid\n",
    "var_da = gridded_radar_interp_ds['reflectivity_masked'].sel(time=slice(anim_start, anim_end))\n",
    "xplt = var_da.coords['x']\n",
    "yplt = var_da.coords['y']\n",
    "\n",
    "clevels =np.arange(0., 61., 1.)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=60.)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xplt, yplt, var.squeeze(), levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    # Plot PIPS location\n",
    "    for PIPS, PIPS_xy in zip(PIPS_list, PIPS_xy_list):\n",
    "        PIPS_x = PIPS_xy[0]\n",
    "        PIPS_y = PIPS_xy[1]\n",
    "        ax.plot([PIPS_x], [PIPS_y], 'k*')\n",
    "        #ax.text([PIPS_x], [PIPS_y], str(PIPS_list['val'])\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        ax.set_xlim(50000., 120000.)\n",
    "        ax.set_ylim(50000., 120000.)\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "plt.close()\n",
    "HTML(ani.to_jshtml())\n",
    "# ani.save('test.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'interp_masked_ref_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:16:24.476214Z",
     "start_time": "2021-04-20T16:15:52.060401Z"
    }
   },
   "outputs": [],
   "source": [
    "var_da = gridded_radar_interp_ds['D0'].sel(time=slice(anim_start, anim_end))\n",
    "\n",
    "clevels =np.arange(0., 6., 0.1)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=6.)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xplt, yplt, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    # Plot PIPS location\n",
    "    for PIPS, PIPS_xy in zip(PIPS_list, PIPS_xy_list):\n",
    "        PIPS_x = PIPS_xy[0]\n",
    "        PIPS_y = PIPS_xy[1]\n",
    "        ax.plot([PIPS_x], [PIPS_y], 'k*')\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        ax.set_xlim(50000., 120000.)\n",
    "        ax.set_ylim(50000., 120000.)\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "plt.close()\n",
    "HTML(ani.to_jshtml())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'D0_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:16:26.590866Z",
     "start_time": "2021-04-20T16:16:26.494971Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract within a small bounding box and for a limited time slice\n",
    "\n",
    "# For 04/30 case\n",
    "# tstart = '2017-04-30T20:00'\n",
    "# tstop = '2017-04-30T21:30'\n",
    "\n",
    "# For 03/27 case\n",
    "# tstart = '2017-03-27T19:30'\n",
    "# tstop = '2017-03-27T21:00'\n",
    "\n",
    "# For 03/27 case (D2)\n",
    "tstart = '2017-03-27T19:00'\n",
    "tstop = '2017-03-27T22:00'\n",
    "\n",
    "lat_bgn = 33.5\n",
    "lat_end = 35.0\n",
    "lon_bgn = -87.5\n",
    "lon_end = -87.0\n",
    "\n",
    "# ibgn = 50\n",
    "# iend = 150\n",
    "# jbgn = 125\n",
    "# jend = 225\n",
    "# level = 2\n",
    "# z_level = gridded_radar.point_z['data'][level, 0, 0]\n",
    "# z_level = 1000.\n",
    "gridded_radar_interp_ds = gridded_radar_interp_ds.swap_dims({'y': 'lat', 'x': 'lon'})\n",
    "gridded_radar_subgrid = gridded_radar_interp_ds.sel(lat=slice(lat_bgn, lat_end), lon=slice(lon_bgn, lon_end),\n",
    "                                                    time=slice(tstart, tstop))\n",
    "# gridded_radar_subgrid = gridded_radar_subgrid.squeeze()\n",
    "gridded_radar_subgrid = gridded_radar_subgrid.transpose('time', 'lat', 'lon')\n",
    "print(gridded_radar_subgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:16:37.019651Z",
     "start_time": "2021-04-20T16:16:36.937823Z"
    }
   },
   "outputs": [],
   "source": [
    "print(gridded_radar_subgrid.coords['time_seconds'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:16:42.756631Z",
     "start_time": "2021-04-20T16:16:41.447824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate ND for each grid point from gamma dist. parameters using Parsivel bins\n",
    "avg_diameters = pp.parsivel_parameters['avg_diameter_bins_mm']\n",
    "avg_diameters = xr.DataArray(avg_diameters, coords = {'diameter': ('diameter_bin', avg_diameters)}, \n",
    "                             dims=['diameter_bin'])\n",
    "\n",
    "lamda = gridded_radar_subgrid['lamda'] * 1000. # get to m^-1\n",
    "alpha = gridded_radar_subgrid['mu']\n",
    "N0 = gridded_radar_subgrid['N0'] * 1000**(1 + alpha) # get to m^-4\n",
    "ND = dsd.calc_binned_DSD_from_params(N0, lamda, alpha, avg_diameters) * 1.e-3 # Get to m^-3 mm^-1\n",
    "ND.coords['max_diameter'] = ('diameter_bin', pp.parsivel_parameters['max_diameter_bins_mm'])\n",
    "ND.coords['min_diameter'] = ('diameter_bin', pp.parsivel_parameters['min_diameter_bins_mm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:16:48.005032Z",
     "start_time": "2021-04-20T16:16:47.923392Z"
    }
   },
   "outputs": [],
   "source": [
    "# THIS ONE DOESN'T WORK\n",
    "# Set up grid for precip trajectories\n",
    "# For 04/30 case (FIX THIS to be more general, but we are using ESC format for 04/30, and sharppy for 03/27)\n",
    "# height_AGL_snd = sounding_df['height'] - sounding_metadata['selev']\n",
    "# For 03/27 case\n",
    "height_AGL_snd = sounding_df['height']\n",
    "# print(gridded_radar_subgrid['x'])\n",
    "grid_height = gridded_radar_subgrid['z'].values\n",
    "# grid_height = 2000.\n",
    "# print(gridded_radar.origin_altitude)\n",
    "dz = 1.\n",
    "new_heights = np.arange(0., grid_height + dz, dz)\n",
    "\n",
    "# Interpolate sounding u, v to new regularly spaced heights\n",
    "# For 04/30 case (FIXME)\n",
    "# u_snd = sounding_df['u'].values\n",
    "# For 03/27 case\n",
    "u_snd = u\n",
    "f = interpolate.interp1d(height_AGL_snd, u_snd, bounds_error=False, fill_value=(u_snd[0], u_snd[-1]))\n",
    "ug = f(new_heights)\n",
    "\n",
    "# For 04/30 case (FIXME)\n",
    "# v_snd = sounding_df['v'].values\n",
    "# For 03/27 case\n",
    "v_snd = v\n",
    "f = interpolate.interp1d(height_AGL_snd, v_snd, bounds_error=False, fill_value=(v_snd[0], v_snd[-1]))\n",
    "vg = f(new_heights)\n",
    "\n",
    "# Storm-relative winds\n",
    "usr = ug - ustorm\n",
    "vsr = vg - vstorm\n",
    "\n",
    "# Layer-mean storm-relative winds\n",
    "usm = np.mean(usr)\n",
    "vsm = np.mean(vsr)\n",
    "print(usm, vsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COPIED FROM PREVIOUS PRECIP_TRAJ SCRIPT\n",
    "# Set up grid for precip trajectories\n",
    "# For 04/30 case (FIX THIS to be more general, but we are using ESC format for 04/30, and sharppy for 03/27)\n",
    "height_AGL_snd = sounding_df['height'] - sounding_metadata['selev']\n",
    "# For 03/27 case\n",
    "# height_AGL_snd = sounding_df['height']\n",
    "# print(gridded_radar_subgrid['x'])\n",
    "grid_height = gridded_radar_subgrid['z'].values\n",
    "# grid_height = 2000.\n",
    "# print(gridded_radar.origin_altitude)\n",
    "dz = 1.\n",
    "new_heights = np.arange(0., grid_height + dz, dz)\n",
    "\n",
    "# Interpolate sounding u, v to new regularly spaced heights\n",
    "# For 04/30 case (FIXME)\n",
    "u_snd = sounding_df['u'].values\n",
    "# For 03/27 case\n",
    "# u_snd = u\n",
    "f = interpolate.interp1d(height_AGL_snd, u_snd, bounds_error=False, fill_value=(u_snd[0], u_snd[-1]))\n",
    "ug = f(new_heights)\n",
    "\n",
    "# For 04/30 case (FIXME)\n",
    "v_snd = sounding_df['v'].values\n",
    "# For 03/27 case\n",
    "# v_snd = v\n",
    "f = interpolate.interp1d(height_AGL_snd, v_snd, bounds_error=False, fill_value=(v_snd[0], v_snd[-1]))\n",
    "vg = f(new_heights)\n",
    "\n",
    "# Storm-relative winds\n",
    "usr = ug - ustorm\n",
    "vsr = vg - vstorm\n",
    "\n",
    "# Layer-mean storm-relative winds\n",
    "usm = np.mean(usr)\n",
    "vsm = np.mean(vsr)\n",
    "print(usm, vsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:17:09.942329Z",
     "start_time": "2021-04-20T16:17:01.602272Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Truncate diameter range to less than 9 mm\n",
    "D_max = 9.\n",
    "D_range_full = ND['diameter'].values\n",
    "D_max_ind = np.searchsorted(D_range_full, D_max)\n",
    "D_range = D_range_full[:D_max_ind]\n",
    "print(D_range)\n",
    "ND_trunc = ND.isel(diameter_bin=slice(0, D_max_ind))\n",
    "\n",
    "# Compute range of terminal velocities from Brandes relation\n",
    "vt_range = rain_Brandes(D_range / 1000.)\n",
    "print(vt_range)\n",
    "\n",
    "# Set dimensions back from lat/lon to y/x for ND_trunc\n",
    "ND_trunc = ND_trunc.swap_dims({'lon': 'x', 'lat': 'y'})\n",
    "ND_trunc = ND_trunc.swap_dims({'time': 'time_seconds'})\n",
    "\n",
    "# Interpolate ND to a finer grid\n",
    "# Set up grid of locations\n",
    "x_coords = ND_trunc['x']\n",
    "y_coords = ND_trunc['y']\n",
    "t_coords = ND_trunc['time_seconds']\n",
    "\n",
    "refinement_factor = 4\n",
    "time_refinement_factor = 1\n",
    "\n",
    "new_x_coords = np.linspace(x_coords.x[0], x_coords.x[-1], (x_coords.sizes['x'] - 1) * refinement_factor + 1)\n",
    "new_y_coords = np.linspace(y_coords.y[0], y_coords.y[-1], (y_coords.sizes['y'] - 1) * refinement_factor + 1)\n",
    "new_t_coords = np.linspace(t_coords.time_seconds[0], t_coords.time_seconds[-1], \n",
    "                           (t_coords.sizes['time_seconds'] - 1) * time_refinement_factor + 1)\n",
    "\n",
    "print(new_t_coords)\n",
    "\n",
    "ND_trunc = ND_trunc.interp(x=new_x_coords, y=new_y_coords, time_seconds=new_t_coords)\n",
    "\n",
    "x_grid, y_grid, t_grid = xr.broadcast(ND_trunc['x'], ND_trunc['y'], ND_trunc['time_seconds'])\n",
    "\n",
    "x_flat = x_grid.stack(loc=['time_seconds', 'y', 'x']).values\n",
    "y_flat = y_grid.stack(loc=['time_seconds', 'y', 'x']).values\n",
    "t_flat = t_grid.stack(loc=['time_seconds', 'y', 'x']).values\n",
    "\n",
    "# Compute horizontal deviations of drops and residence time at bottom of layer for each grid point and drop size\n",
    "# TODO: Generalize this for spatially varying velocity field. Would require a numerical trajectory integration\n",
    "# TODO: Update this to perturb the terminal velocities for all grid points (already modified the function above)\n",
    "xf, yf, tf = cal_xf_tf(usm, vsm, vt_range, grid_height)\n",
    "x_flat_f = x_flat[:, np.newaxis] + xf\n",
    "y_flat_f = y_flat[:, np.newaxis] + yf\n",
    "\n",
    "# Create array of times corresponding to each initial time for trajectory endpoints as a function of diameter\n",
    "t_flat_f = t_flat[:, np.newaxis] + tf\n",
    "\n",
    "x_flat_f = x_flat_f.T\n",
    "y_flat_f = y_flat_f.T\n",
    "t_flat_f = t_flat_f.T\n",
    "\n",
    "# Perturb the endpoints a bit in space and time\n",
    "xpertscale = 20. # m\n",
    "tpertscale = 1. # s\n",
    "rng = np.random.default_rng()\n",
    "xpert = xpertscale * rng.standard_normal(size=x_flat_f.shape)\n",
    "ypert = xpertscale * rng.standard_normal(size=y_flat_f.shape)\n",
    "tpert = tpertscale * rng.standard_normal(size=t_flat_f.shape)\n",
    "\n",
    "xpert = np.where(xpert < -10.*xpertscale, 0., xpert)\n",
    "xpert = np.where(xpert > 10.*xpertscale, 0., xpert)\n",
    "ypert = np.where(ypert < -10.*xpertscale, 0., ypert)\n",
    "ypert = np.where(ypert > 10.*xpertscale, 0., ypert)\n",
    "tpert = np.where(tpert < -10.*tpertscale, 0., tpert)\n",
    "tpert = np.where(tpert > 10.*tpertscale, 0., tpert)\n",
    "\n",
    "# x_flat_f = x_flat_f + xpert\n",
    "# y_flat_f = y_flat_f + ypert\n",
    "# t_flat_f = t_flat_f + tpert\n",
    "\n",
    "ND_trunc = ND_trunc.transpose('diameter_bin', 'time_seconds', 'y', 'x')\n",
    "print(x_flat_f.shape, y_flat_f.shape, t_flat_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:34:33.622095Z",
     "start_time": "2021-04-09T14:34:32.461940Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test plot of endpoints\n",
    "\n",
    "x_grid_plt = x_grid.sel(time_seconds=10620.)\n",
    "y_grid_plt = y_grid.sel(time_seconds=10620.)\n",
    "\n",
    "x_grid_plt = x_grid_plt.thin(indexers=5)\n",
    "y_grid_plt = y_grid_plt.thin(indexers=5)\n",
    "\n",
    "x_flat_plt = x_grid_plt.stack(loc=['y', 'x']).values\n",
    "y_flat_plt = y_grid_plt.stack(loc=['y', 'x']).values\n",
    "\n",
    "# Compute horizontal deviations of drops and residence time at bottom of layer for each grid point and drop size\n",
    "# TODO: Generalize this for spatially varying velocity field. Would require a numerical trajectory integration\n",
    "# TODO: Update this to perturb the terminal velocities for all grid points (already modified the function above)\n",
    "x_flat_f_plt = x_flat_plt[:, np.newaxis] + xf\n",
    "y_flat_f_plt = y_flat_plt[:, np.newaxis] + yf\n",
    "\n",
    "print(x_flat_f_plt.shape)\n",
    "\n",
    "Nt = ND_trunc.sel(time_seconds=10620.).sum(dim='diameter_bin')\n",
    "Nt = Nt.thin(indexers=5)\n",
    "print(Nt)\n",
    "Nt_flat = Nt.values.flatten()\n",
    "indices = np.where(Nt_flat > 0.)[0]\n",
    "# indices = indices[::100]\n",
    "\n",
    "print(ND_trunc['diameter'].values)\n",
    "\n",
    "x_flat_f_0 = x_flat_f_plt[:, 8]\n",
    "y_flat_f_0 = y_flat_f_plt[:, 8]\n",
    "x_flat_f_1 = x_flat_f_plt[:, 16]\n",
    "y_flat_f_1 = y_flat_f_plt[:, 16]\n",
    "\n",
    "gridded_radar_subgrid_2 = gridded_radar_subgrid.swap_dims({'time': 'time_seconds'})\n",
    "\n",
    "var_da = gridded_radar_subgrid_2['differential_reflectivity_masked'].sel(time_seconds=10620.)\n",
    "xplt = gridded_radar_subgrid_2.coords[\"x\"]\n",
    "yplt = gridded_radar_subgrid_2.coords[\"y\"]\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels =np.arange(0., 4., 0.1)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=4.)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ci = ax.contourf(xplt, yplt, var_da.squeeze(), levels=clevels, cmap='plasma', norm=norm)\n",
    "ax.scatter(x_flat_plt[indices], y_flat_plt[indices], marker='*', color='k', label='Initial points')\n",
    "ax.scatter(x_flat_f_0[indices], y_flat_f_0[indices], marker='x', color='b', label='Endpoint (D = 1 mm)')\n",
    "ax.scatter(x_flat_f_1[indices], y_flat_f_1[indices], marker='o', color='g', label='Endpoint (D = 3.25 mm)')\n",
    "\n",
    "cbarintv = 1.\n",
    "cbarlevels = ticker.MultipleLocator(base=cbarintv)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(ci, orientation='vertical', ticks=cbarlevels, cax=cax)\n",
    "cax.set_ylabel('dB')\n",
    "\n",
    "\n",
    "\n",
    "# ax.set_xlim(-26000., -16000.)\n",
    "# ax.set_ylim(-40000., -30000.)\n",
    "formatter = ticker.FuncFormatter(mtokm)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "ax.set_xlabel('km')\n",
    "ax.set_ylabel('km')\n",
    "ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plot_filename = 'trajectory_endpoint_example.png'\n",
    "plot_filepath = os.path.join(plot_dir, plot_filename)\n",
    "fig.savefig(plot_filepath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:34:50.922126Z",
     "start_time": "2021-04-09T14:34:50.847922Z"
    }
   },
   "outputs": [],
   "source": [
    "print(gridded_radar_subgrid['time_seconds'])\n",
    "print(gridded_radar_subgrid['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:17:23.431696Z",
     "start_time": "2021-04-20T16:17:23.350016Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up 3D bins (2 for space, 1 for time) for bottom of sorting layer\n",
    "\n",
    "dx_bins = 500.\n",
    "dx_orig = new_x_coords[1] - new_x_coords[0]\n",
    "print(\"dx (top), dx (bottom)\", dx_orig, dx_bins)\n",
    "area_ratio = dx_bins**2. / dx_orig**2.\n",
    "print(\"area ratio: \", area_ratio)\n",
    "# Get bounding box of bottom of domain\n",
    "# xmin = int(x_flat_f.min()) # -5000.\n",
    "# xmax = int(x_flat_f.max())\n",
    "# ymin = int(y_flat_f.min()) # -5000.\n",
    "# ymax = int(y_flat_f.max())\n",
    "\n",
    "# Or, just use the original bounds\n",
    "xmin = new_x_coords[0]\n",
    "xmax = new_x_coords[-1]\n",
    "ymin = new_y_coords[0]\n",
    "ymax = new_y_coords[-1]\n",
    "\n",
    "# Create bins for bottom of domain\n",
    "xbins = int((xmax-xmin)/dx_bins)\n",
    "ybins = int((ymax-ymin)/dx_bins)\n",
    "\n",
    "print(xbins)\n",
    "print(ybins)\n",
    "xmax = xmin+dx_bins*xbins # +5000.\n",
    "ymax = ymin+dx_bins*ybins # +5000.\n",
    "print(xmin, xmax, ymin, ymax)\n",
    "\n",
    "# Set up time bins\n",
    "# EDIT: just use original time bins\n",
    "tintv = 60.\n",
    "# tmin = t_flat_f.min()\n",
    "# tmax = t_flat_f.max()\n",
    "# print(tmin, tmax)\n",
    "# tbins = int((tmax - tmin) / tintv)\n",
    "tmin = ND_trunc['time_seconds'][0].values\n",
    "tmax = ND_trunc['time_seconds'][-1].values + tintv\n",
    "tbins = int((tmax - tmin) / tintv)\n",
    "print(tmin, tmax, tbins)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:17:35.675116Z",
     "start_time": "2021-04-20T16:17:26.381655Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create 3D histogram (x, y, t) for number density for each diameter bin for drop trajectory endpoints\n",
    "\n",
    "ND_D_binned_list = []\n",
    "\n",
    "for i, ND_D in enumerate(ND_trunc):\n",
    "    print(\"Index: \", i)\n",
    "    x = x_flat_f[i]\n",
    "    y = y_flat_f[i]\n",
    "    t = t_flat_f[i]\n",
    "    \n",
    "    coords = np.stack([x, y, t], axis=1)\n",
    "    ND_D_binned, edges = np.histogramdd(coords,\n",
    "                                        bins=[xbins, ybins, tbins],\n",
    "                                        range=[[xmin, xmax], [ymin, ymax], [tmin, tmax]],\n",
    "                                        weights=ND_D.values.flatten())\n",
    "    ND_D_binned_list.append(ND_D_binned)\n",
    "\n",
    "    \n",
    "ND_D_binned = np.array(ND_D_binned_list)\n",
    "xedges, yedges, tedges = edges\n",
    "# Shift times to start at 0 again\n",
    "tedges = tedges - tedges[0]\n",
    "start_time = ND['time'][0].values\n",
    "attrs = {\"units\": \"seconds since {}\".format(start_time)}\n",
    "\n",
    "ND_f_da = xr.DataArray(ND_D_binned,\n",
    "                       coords={\n",
    "                           \"diameter\": ND_trunc['diameter'], \n",
    "                           \"x\": xedges[:-1],\n",
    "                           \"y\": yedges[:-1],\n",
    "                           \"time_seconds\": tedges[:-1],\n",
    "                       },\n",
    "                       dims=[\"diameter_bin\", \"x\", \"y\", \"time_seconds\"])\n",
    "\n",
    "ND_f_da.coords[\"time\"] = (\"time_seconds\", ND_f_da[\"time_seconds\"], attrs)\n",
    "ND_f_ds = xr.decode_cf(ND_f_da.to_dataset(name='ND'))\n",
    "ND_f_ds = ND_f_ds.swap_dims({\"time_seconds\": \"time\"})\n",
    "ND_f_ds.coords['max_diameter'] = ('diameter_bin', pp.parsivel_parameters['max_diameter_bins_mm'][:D_max_ind])\n",
    "ND_f_ds.coords['min_diameter'] = ('diameter_bin', pp.parsivel_parameters['min_diameter_bins_mm'][:D_max_ind])\n",
    "ND_f_ds = ND_f_ds.transpose(\"time\", \"y\", \"x\", \"diameter_bin\")\n",
    "ND_f_ds = ND_f_ds.swap_dims({'diameter_bin': 'diameter'}) # Do this so we can use it for sel function. May\n",
    "                                                          # break other stuff so make sure to check later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-20T16:18:30.326178Z",
     "start_time": "2021-04-20T16:17:45.865774Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot ND animation for a given diameter bin\n",
    "D_to_plot = 1.\n",
    "\n",
    "xctr = 0.5 * (xedges[1:] + xedges[:-1])\n",
    "yctr = 0.5 * (yedges[1:] + yedges[:-1])\n",
    "\n",
    "var_da = ND_f_ds['ND'].sel(diameter=D_to_plot, method='nearest')\n",
    "var_da = var_da.sel(time=slice(anim_start, anim_end))\n",
    "\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels = np.logspace(-1., 4., num=100)\n",
    "norm = cm.colors.LogNorm(vmin=1., vmax=10000.)\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values\n",
    "    ci = ax.contourf(xctr, yctr, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='plasma', norm=norm)\n",
    "    # Plot PIPS location\n",
    "    for PIPS, PIPS_xy in zip(PIPS_list, PIPS_xy_list):\n",
    "        PIPS_x = PIPS_xy[0]\n",
    "        PIPS_y = PIPS_xy[1]\n",
    "        ax.plot([PIPS_x], [PIPS_y], 'k*')\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        ax.set_xlim(78000., 120000.)\n",
    "        ax.set_ylim(50000., 120000.)\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "plt.close()\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'ND_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:41:47.603140Z",
     "start_time": "2021-04-09T14:41:42.438623Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate radar variables for new surface DSDs\n",
    "# Get polarimetric variables\n",
    "# This uses a *ton* of memory. Need to think of ways to lower the memory footprint\n",
    "# ND_f_ds = ND_f_ds.swap_dims({'diameter': 'diameter_bin'})\n",
    "dD = ND_f_ds['max_diameter'] - ND_f_ds['min_diameter']\n",
    "dualpol_dict = dualpol.calpolrain_bulk_xr(10.7, \n",
    "                                          '/Users/terrell8/Projects/pyPIPS/tmatrix/S-Band/SCTT_RAIN_fw100.dat',\n",
    "                                          ND_f_ds['ND'], dD, diameter_bin_name='diameter')\n",
    "print(dualpol_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:42:53.751091Z",
     "start_time": "2021-04-09T14:42:25.842687Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot reflectivity at bottom of sorting layer\n",
    "\n",
    "xctr = 0.5 * (xedges[1:] + xedges[:-1])\n",
    "yctr = 0.5 * (yedges[1:] + yedges[:-1])\n",
    "\n",
    "var_da = dualpol_dict['REF']\n",
    "# var_da = var_da.sel(time=slice(anim_start, anim_end))\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels =np.arange(0., 61., 1.)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=60.)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xctr, yctr, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    # Plot PIPS location\n",
    "    for PIPS, PIPS_xy in zip(PIPS_list, PIPS_xy_list):\n",
    "        PIPS_x = PIPS_xy[0]\n",
    "        PIPS_y = PIPS_xy[1]\n",
    "        ax.plot([PIPS_x], [PIPS_y], 'k*')\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        ax.set_xlim(78000., 120000.)\n",
    "        ax.set_ylim(50000., 120000.)\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "plt.close()\n",
    "HTML(ani.to_jshtml())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'Sur_Calc_REF_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:44:03.856395Z",
     "start_time": "2021-04-09T14:43:38.770147Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# xctr = 0.5 * (xedges[1:] + xedges[:-1])\n",
    "# yctr = 0.5 * (yedges[1:] + yedges[:-1])\n",
    "\n",
    "var_da = gridded_radar_subgrid['reflectivity_masked']\n",
    "xplt = gridded_radar_subgrid.coords[\"x\"]\n",
    "yplt = gridded_radar_subgrid.coords[\"y\"]\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels =np.arange(0., 61., 1.)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=60.)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xplt, yplt, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "\n",
    "    for PIPS, PIPS_xy in zip(PIPS_list, PIPS_xy_list):\n",
    "        PIPS_x = PIPS_xy[0]\n",
    "        PIPS_y = PIPS_xy[1]\n",
    "        ax.plot([PIPS_x], [PIPS_y], 'k*')\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        ax.set_xlim(78000., 120000.)\n",
    "        ax.set_ylim(50000., 120000.)\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "HTML(ani.to_jshtml())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = '1km_AGL_REF_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:44:33.755198Z",
     "start_time": "2021-04-09T14:44:05.220255Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot ZDR at bottom of sorting layer\n",
    "\n",
    "# xctr = 0.5 * (xedges[1:] + xedges[:-1])\n",
    "# yctr = 0.5 * (yedges[1:] + yedges[:-1])\n",
    "\n",
    "var_da = dualpol_dict['ZDR']\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels =np.arange(0., 6., 0.1)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=6.)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xctr, yctr, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    # Plot PIPS location\n",
    "    for PIPS, PIPS_xy in zip(PIPS_list, PIPS_xy_list):\n",
    "        PIPS_x = PIPS_xy[0]\n",
    "        plt.close()\n",
    "        PIPS_y = PIPS_xy[1]\n",
    "        ax.plot([PIPS_x], [PIPS_y], 'k*')\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        ax.set_xlim(78000., 120000.)\n",
    "        ax.set_ylim(50000., 120000.)\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "plt.close()\n",
    "HTML(ani.to_jshtml())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'Sur_Calc_ZDR_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:29:39.637349Z",
     "start_time": "2020-12-16T20:29:20.285671Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# xctr = 0.5 * (xedges[1:] + xedges[:-1])\n",
    "# yctr = 0.5 * (yedges[1:] + yedges[:-1])\n",
    "\n",
    "var_da = gridded_radar_subgrid['differential_reflectivity_masked']\n",
    "xplt = gridded_radar_subgrid.coords[\"x\"]\n",
    "yplt = gridded_radar_subgrid.coords[\"y\"]\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels =np.arange(0., 6., 0.1)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=6.)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xplt, yplt, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    for PIPS, PIPS_xy in zip(PIPS_list, PIPS_xy_list):\n",
    "        PIPS_x = PIPS_xy[0]\n",
    "        PIPS_y = PIPS_xy[1]\n",
    "        ax.plot([PIPS_x], [PIPS_y], 'k*')\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        ax.set_xlim(78000., 120000.)\n",
    "        ax.set_ylim(50000., 120000.)\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "HTML(ani.to_jshtml())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = '1km_AGL_ZDR_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:49:41.286164Z",
     "start_time": "2021-04-09T14:49:41.205667Z"
    }
   },
   "outputs": [],
   "source": [
    "PIPS_xy = PIPS_xy_list[0]\n",
    "PIPS_x = PIPS_xy[0]\n",
    "PIPS_y = PIPS_xy[1]\n",
    "\n",
    "PIPS_ds = PIPS_ds_list[0]\n",
    "radar_at_PIPS_da = radar_at_PIPS_list[0]\n",
    "\n",
    "dD = PIPS_ds['max_diameter'] - PIPS_ds['min_diameter']\n",
    "dualpol_dict_PIPS = dualpol.calpolrain_bulk_xr(10.7, \n",
    "                                               '/Users/terrell8/Projects/pyPIPS/tmatrix/S-Band/SCTT_RAIN_fw100.dat',\n",
    "                                               PIPS_ds['ND_qc'], dD, diameter_bin_name='diameter_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:49:47.468049Z",
     "start_time": "2021-04-09T14:49:47.386088Z"
    }
   },
   "outputs": [],
   "source": [
    "ZH_interp_PIPS_da = dualpol_dict['REF'].interp(x=PIPS_x, y=PIPS_y)\n",
    "print(ZH_interp_PIPS_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:50:04.474867Z",
     "start_time": "2021-04-09T14:50:04.136226Z"
    }
   },
   "outputs": [],
   "source": [
    "ZH_PIPS = dualpol_dict_PIPS['REF']\n",
    "ZH_PIPS.plot(xlim=(anim_start, anim_end), color='k')\n",
    "ZH_interp_PIPS_da.plot(xlim=(anim_start, anim_end), color='b')\n",
    "radar_at_PIPS_da['reflectivity_masked'].plot(xlim=(anim_start, anim_end),\n",
    "                                                   color='g')\n",
    "PIPS_ds['KGWX_at_PIPS'].sel(fields_KGWX='REF').plot(xlim=(anim_start, anim_end),\n",
    "                                                             color='purple')\n",
    "\n",
    "figname_2 = 'KGWX_REF_0327_PIPS1A.png'\n",
    "figpath = os.path.join(plot_dir, figname_2)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:51:30.516300Z",
     "start_time": "2021-04-09T14:51:30.408888Z"
    }
   },
   "outputs": [],
   "source": [
    "ZDR_interp_PIPS_da = dualpol_dict['ZDR'].interp(x=PIPS_x, y=PIPS_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:51:54.930201Z",
     "start_time": "2021-04-09T14:51:54.578125Z"
    }
   },
   "outputs": [],
   "source": [
    "ZDR_PIPS = dualpol_dict_PIPS['ZDR']\n",
    "ZDR_PIPS.plot(xlim=(anim_start, anim_end), color='k')\n",
    "ZDR_interp_PIPS_da.plot(xlim=(anim_start, anim_end), color='b')\n",
    "radar_at_PIPS_da['differential_reflectivity_masked'].plot(xlim=(anim_start, anim_end),\n",
    "                                                          color='g')\n",
    "PIPS_ds['KGWX_at_PIPS'].sel(fields_KGWX='ZDR').plot(xlim=(anim_start, anim_end),\n",
    "                                                             color='purple')\n",
    "\n",
    "figname_3 = 'KGWX_ZDR_0327_PIPS1A.png'\n",
    "figpath = os.path.join(plot_dir, figname_3)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:54:02.585090Z",
     "start_time": "2021-04-09T14:54:02.496106Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine sorted ND and polarimetric arrays together into a single dataset and dump to disk\n",
    "print(ND_f_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:54:04.833110Z",
     "start_time": "2021-04-09T14:54:04.759079Z"
    }
   },
   "outputs": [],
   "source": [
    "print(dualpol_dict['REF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:54:09.264543Z",
     "start_time": "2021-04-09T14:54:09.189533Z"
    }
   },
   "outputs": [],
   "source": [
    "sorted_ds = ND_f_ds.copy()\n",
    "sorted_ds['REF'] = dualpol_dict['REF']\n",
    "sorted_ds['ZDR'] = dualpol_dict['ZDR']\n",
    "print(sorted_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-09T14:54:32.512396Z",
     "start_time": "2021-04-09T14:54:28.418102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dump to file \n",
    "\n",
    "# Add some metadata first\n",
    "sorted_ds.attrs['orig_dx'] = dx_orig * refinement_factor\n",
    "sorted_ds.attrs['top_dx'] = dx_orig\n",
    "sorted_ds.attrs['bottom_dx'] = dx_bins\n",
    "sorted_ds.attrs['sorting_layer_top'] = height\n",
    "sorted_ds.attrs['sorting_layer_bottom'] = 0.  # Generalize this later\n",
    "\n",
    "# print(sorted_ds)\n",
    "\n",
    "tstart_datetime = datetime.strptime(tstart, '%Y-%m-%dT%H:%M')\n",
    "tstop_datetime = datetime.strptime(tstop, '%Y-%m-%dT%H:%M')\n",
    "\n",
    "tstart_out = tstart_datetime.strftime('%Y%m%d%H%M')\n",
    "tstop_out = tstop_datetime.strftime('%Y%m%d%H%M')\n",
    "\n",
    "sorted_filename = '{}_{}_{}_d{:d}_gridded_sorted.nc'.format(radar_name, tstart_out, tstop_out, int(height))\n",
    "print(sorted_filename)\n",
    "sorted_path = os.path.join(gridded_radar_dir, sorted_filename)\n",
    "print(sorted_path)\n",
    "sorted_ds.to_netcdf(sorted_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

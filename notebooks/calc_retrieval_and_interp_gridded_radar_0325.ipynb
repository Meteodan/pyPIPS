{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T03:24:44.835706Z",
     "start_time": "2021-01-03T03:24:41.764585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "from matplotlib import dates\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid, make_axes_locatable, host_subplot\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "#import pyPIPS.disdrometer_module as dis\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "#import pyPIPS.simulator as sim\n",
    "import pyPIPS.pips_io as pipsio\n",
    "import pyPIPS.PIPS as pips\n",
    "import pyPIPS.parsivel_params as pp\n",
    "import pyPIPS.parsivel_qc as pqc\n",
    "import pyPIPS.radarmodule as radar\n",
    "import pyPIPS.polarimetric as dualpol\n",
    "#from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy.random as random\n",
    "from scipy.stats import gamma, uniform\n",
    "from scipy.special import gamma as gammafunc\n",
    "from scipy import ndimage\n",
    "from scipy import interpolate\n",
    "from metpy.plots import StationPlot\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.calc import wind_components\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.plots.wx_symbols import current_weather, sky_cover\n",
    "from metpy.units import units\n",
    "from scipy.signal import medfilt2d\n",
    "import pyart\n",
    "import cartopy.crs as ccrs\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T03:24:45.071769Z",
     "start_time": "2021-01-03T03:24:44.973045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "def readESC(sounding_path, interpnan=True, handle=False):\n",
    "    \"\"\"\n",
    "    Reads in a sounding in ESC format from a provided file path or handle (can be a StringIO object or an open\n",
    "    file handle)\n",
    "    \"\"\"\n",
    "    col_names = ['pressure','temperature','dewpoint','u_wind','v_wind','speed','direction','height',\n",
    "                 'Qp_code','Qt_code','Qrh_code','Qu_code','Qv_code']\n",
    "    # First read the file and extract the field widths from the 14th header line\n",
    "    if not handle:\n",
    "        f = open(sounding_path, 'r')\n",
    "    else:\n",
    "        f = sounding_path\n",
    "\n",
    "    # Read in the header and extract some metadata from it\n",
    "    dummy = f.readline()\n",
    "    dummy = f.readline()\n",
    "    header2 = f.readline().strip().split(':')\n",
    "    # Read next header line and extract station id and wmo number from it (if it exists)\n",
    "    staid_wmo_str = header2[1]\n",
    "    if ' / ' in staid_wmo_str:\n",
    "        staid_wmo = staid_wmo_str.strip().split(' / ')\n",
    "        staid = staid_wmo[0][1:4]\n",
    "        wmo = int(staid_wmo[1])\n",
    "    else:\n",
    "        if '. ' in staid_wmo_str:\n",
    "            staid = staid_wmo_str.replace('. ', '').strip()[:4]\n",
    "        else:\n",
    "            staid = staid_wmo_str.strip()[:4]\n",
    "            staid = staid.replace(\" \", \"\")\n",
    "        wmo = 99999\n",
    "    print(staid)\n",
    "    # Read the next header line and extract the location information from it\n",
    "    header3 = f.readline().strip().split(':')\n",
    "    location = header3[1].strip().split(',')\n",
    "    print(location)\n",
    "    lon = np.float(location[2])\n",
    "    lat = np.float(location[3])\n",
    "    elev = np.float(location[4])\n",
    "    # Read the next header line and extract the time information from it\n",
    "    header4 = f.readline().strip()[31:].lstrip()   \n",
    "    sounding_datetime = datetime.strptime(header4, '%Y, %m, %d, %H:%M:%S')\n",
    "    \n",
    "    # Now read and dump the rest of the header\n",
    "    for i in range(9):\n",
    "        f.readline()\n",
    "    \n",
    "    # Except for the last header line, which is used to determine the widths of the fields\n",
    "    line = f.readline().strip().split()\n",
    "    fw = [len(field)+1 for field in line]\n",
    "\n",
    "    # Now read the file into the dataframe, using the extracted field widths\n",
    "    df = pd.read_fwf(f, usecols=[1, 2, 3, 5, 6, 7, 8, 14, 15, 16, 17, 18, 19],\n",
    "                     names=col_names, na_values=['99999.0', '9999.0', '999.0'], widths=fw)\n",
    "    \n",
    "    # For some reason, need to convert all the columns to floating point here, as some get interpreted as strings\n",
    "    # when they shouldn't be...\n",
    "    # print(df['pressure'], df['temperature'])\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].astype(np.float)\n",
    "    \n",
    "    # Drop rows where height or pressure is NaN. TODO: Can't remember why I have to use reset_index(drop=True). \n",
    "    # Figure this out.\n",
    "    df = df.dropna(subset=('height', 'pressure')).reset_index(drop=True)\n",
    "    # Set the height as the index so we can use it as weights to interpolate other columns across NaN\n",
    "    df = df.set_index('height')\n",
    "    df['height'] = df.index\n",
    "    \n",
    "    if interpnan:\n",
    "        # First convert direction and speed to u, v components\n",
    "        df['u'], df['v'] = mpcalc.wind_components(df['speed'].values*units('m/s'),\n",
    "                                                      df['direction'].values*units.degrees)\n",
    "        # Now interpolate\n",
    "        df = df.interpolate(method='values')\n",
    "        # Finally recompute direction and speed from u, v components\n",
    "        df['speed'] = mpcalc.wind_speed(df['u'].values*units('m/s'), df['v'].values*units('m/s'))\n",
    "        df['direction'] = mpcalc.wind_direction(df['u'].values*units('m/s'), df['v'].values*units('m/s'))\n",
    "    else:\n",
    "        # Drop any rows with all NaN values for T, Td, winds\n",
    "        df = df.dropna(subset=('temperature', 'dewpoint', 'direction', 'speed',\n",
    "                               'u_wind', 'v_wind'), how='all').reset_index(drop=True)\n",
    "    \n",
    "    df = df[(df.Qp_code == 1.0) & (df.Qt_code == 1.0) & (df.Qrh_code == 1.0) & (df.Qu_code == 1.0) & \n",
    "            (df.Qv_code == 1.0)]\n",
    "\n",
    "    nlines = df.count()['pressure']\n",
    "    \n",
    "    if not handle:\n",
    "        f.close()\n",
    "    \n",
    "    snd_metadata = {\n",
    "        'sounding_datetime': sounding_datetime,\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'selev': elev,\n",
    "        'staid': staid,\n",
    "        'wmo': wmo,\n",
    "        'nlevs': nlines,\n",
    "        'staid_long': staid_wmo_str\n",
    "    }\n",
    "    \n",
    "    return snd_metadata, df\n",
    "\n",
    "\n",
    "def roundPartial(value, resolution, decimals=4):\n",
    "    return np.around(np.round(value / resolution) * resolution, decimals=decimals)\n",
    "\n",
    "\n",
    "def rain_Brandes(D):\n",
    "    \"\"\"Given a range of diameters D, compute rain fall speed curve, a quartic polynomial\n",
    "       fit after Brandes et al. (2002).\"\"\"\n",
    "    \n",
    "    D_mm=D*1000. # get it to (mm)\n",
    "    \n",
    "    Vtr = -0.1021 + 4.932*D_mm - 0.9551*D_mm**2. + 0.07934*D_mm**3. - 0.002362*D_mm**4.\n",
    "    \n",
    "    return Vtr\n",
    "\n",
    "\n",
    "def cal_xf_tf(usm, vsm, vt, H, perturb_vt=False, sigma=0.1):\n",
    "    \"\"\"Computes final horizontal position and residence time (relative to starting position) of a raindrop\n",
    "       falling through a horizontally homogeneous layer H with terminal velocity vt and \n",
    "       storm releative mean wind given by (usm, vsm).\"\"\"\n",
    "    \n",
    "    if perturb_vt:\n",
    "        rng = np.random.default_rng()\n",
    "        vt_perts = sigma * rng.standard_normal(vt.size)\n",
    "        vt = vt + vt_perts\n",
    "    \n",
    "    tf = H / vt\n",
    "    xf = tf * usm\n",
    "    yf = tf * vsm\n",
    "    \n",
    "    return xf, yf, tf\n",
    "\n",
    "\n",
    "def mtokm(val,pos):\n",
    "    \"\"\"Convert m to km for formatting axes tick labels\"\"\"\n",
    "    val=val/1000.0\n",
    "    return '%i' % val\n",
    "\n",
    "def interpolate_all(gridded_radar, tinterp_intv, base_field_name='reflectivity_masked'):\n",
    "    # Get list of intervals in seconds between subsequent radar times\n",
    "    tdiffs = gridded_radar['time_seconds'].diff(dim='time')\n",
    "    \n",
    "    # This list will hold all the time-interpolated grids (xarray Datasets). \n",
    "    # Can later be concatenated into a new xarray Dataset containing all times\n",
    "    gridded_radar_interp_list = []\n",
    "    \n",
    "    # Grab first time from full dataset and restore singular time dimension\n",
    "    first_time_ds = gridded_radar.isel(time=0)\n",
    "    first_time_ds = first_time_ds.expand_dims(dim='time')\n",
    "\n",
    "    gridded_radar_interp_list.append(first_time_ds)\n",
    "    \n",
    "#     tbgn = first_time_ds.coords['time_seconds'].values.item()  # Need to get scalar value, not 0-d\n",
    "#                                                                # numpy array\n",
    "    \n",
    "    # Loop through the gridded_radar times, perform advection correction/interpolation between successive times\n",
    "    # and add each to the list, making sure the time coordinate is consistent\n",
    "    # new_time = tbgn\n",
    "    for i, tdiff in enumerate(tdiffs.values):\n",
    "        gridded_radar_interp_sublist = advection_correction_ds(gridded_radar.isel(time=slice(i, i+2)), \n",
    "                                                               tdiff, tinterp_intv, \n",
    "                                                               base_field_name=base_field_name)\n",
    "        for t, gridded_radar_interp in enumerate(gridded_radar_interp_sublist):\n",
    "#             new_time = new_time + tinterp_intv\n",
    "#             new_ds = first_time_ds.copy()\n",
    "#             new_ds[:] = gridded_radar_interp\n",
    "#             new_ds.coords['time'] = new_ds['time'] + np.timedelta64(int(new_time), 's')\n",
    "#             new_ds.coords['time_seconds'] = new_time\n",
    "            gridded_radar_interp_list.append(gridded_radar_interp)\n",
    "    \n",
    "    return gridded_radar_interp_list\n",
    "\n",
    "\n",
    "def advection_correction_ds(radar_ds, tintv_obs, tintv, base_field_name='reflectivity_masked', method=\"LK\"):\n",
    "    # Evaluate advection\n",
    "    oflow_method = motion.get_method(method)\n",
    "    fd_kwargs = {\"buffer_mask\": 10}  # avoid edge effects\n",
    "\n",
    "    base_field = radar_ds[base_field_name]\n",
    "    oflow_field = oflow_method(base_field, fd_kwargs=fd_kwargs)\n",
    "    \n",
    "    # Perform temporal interpolation on all variables in Dataset using the flow field derived from the \"base\"\n",
    "    # field (by default, reflectivity)\n",
    "    \n",
    "    tbgn = base_field[0].coords['time_seconds'].values.item()   # Need to get scalar value, not 0-d\n",
    "                                                                # numpy array\n",
    "    print(tbgn)\n",
    "    print(tintv)\n",
    "    radar_ds_list = []\n",
    "    x, y = np.meshgrid(\n",
    "        np.arange(base_field[0].shape[1], dtype=float), np.arange(base_field[0].shape[0], dtype=float),\n",
    "    )\n",
    "    \n",
    "    new_time = tbgn\n",
    "    for i in np.arange(tintv, tintv_obs + tintv, tintv):\n",
    "\n",
    "        new_time = new_time + tintv\n",
    "        \n",
    "        pos1 = (y - i / tintv_obs * oflow_field[1], x - i / tintv_obs * oflow_field[0])\n",
    "        pos2 = (y + (tintv_obs - i) / tintv_obs * oflow_field[1], \n",
    "                x + (tintv_obs - i) / tintv_obs * oflow_field[0])\n",
    "        \n",
    "        field_interp_list = []\n",
    "        for field_name, field_da in radar_ds.items():\n",
    "            fieldt1 = map_coordinates(field_da[0], pos1, order=1)\n",
    "            fieldt2 = map_coordinates(field_da[1], pos2, order=1)\n",
    "       \n",
    "            field_interp = field_da.isel(time=[0]).copy()\n",
    "            field_interp[:] = ((tintv_obs - i) * fieldt1 + i * fieldt2) / tintv_obs\n",
    "            try:\n",
    "                field_interp.coords['time'] = field_interp['time'] + np.timedelta64(int(new_time - tbgn), 's')\n",
    "            except TypeError:\n",
    "                field_interp.coords['time'] = field_interp['time'] + timedelta(seconds=int(new_time - tbgn))\n",
    "            field_interp.coords['time_seconds'] = new_time\n",
    "            field_interp_list.append(field_interp)\n",
    "        \n",
    "        radar_ds_interp = xr.merge(field_interp_list)\n",
    "        radar_ds_list.append(radar_ds_interp)\n",
    "        \n",
    "    return radar_ds_list\n",
    "\n",
    "\n",
    "def advection_correction(arr, tintv_obs, tintv):\n",
    "    \"\"\"\n",
    "    R = np.array([qpe_previous, qpe_current])\n",
    "    T = time between two observations (5 min)\n",
    "    t = interpolation timestep (1 min)\n",
    "    \"\"\"\n",
    "\n",
    "    # Evaluate advection\n",
    "    oflow_method = motion.get_method(\"LK\")\n",
    "    fd_kwargs = {\"buffer_mask\": 10}  # avoid edge effects\n",
    "    V = oflow_method(arr, fd_kwargs=fd_kwargs)\n",
    "\n",
    "    # Perform temporal interpolation\n",
    "    # arr_d = np.zeros((arr[0].shape))\n",
    "    arr_list = []\n",
    "    x, y = np.meshgrid(\n",
    "        np.arange(arr[0].shape[1], dtype=float), np.arange(arr[0].shape[0], dtype=float),\n",
    "    )\n",
    "    for i in np.arange(tintv, tintv_obs + tintv, tintv):\n",
    "\n",
    "        pos1 = (y - i / tintv_obs * V[1], x - i / tintv_obs * V[0])\n",
    "        R1 = map_coordinates(arr[0], pos1, order=1)\n",
    "        \n",
    "        pos2 = (y + (tintv_obs - i) / tintv_obs * V[1], x + (tintv_obs - i) / tintv_obs * V[0])\n",
    "        R2 = map_coordinates(arr[1], pos2, order=1)\n",
    "\n",
    "        arr_interp = ((tintv_obs - i) * R1 + i * R2) / tintv_obs\n",
    "        arr_list.append(arr_interp)\n",
    "\n",
    "    return arr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T03:24:46.859300Z",
     "start_time": "2021-01-03T03:24:46.735847Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the gridded radar data\n",
    "radar_name = 'KGWX'\n",
    "radar_type= 'NEXRAD'\n",
    "\n",
    "# For 03/25 case\n",
    "#date = '0325'\n",
    "radar_start_datetimestamp = '20170325170500'\n",
    "radar_end_datetimestamp = '20170325183559'\n",
    "\n",
    "# For 03/27 case\n",
    "# date = '0327'\n",
    "# radar_start_datetimestamp = '20170327190000'\n",
    "# radar_end_datetimestamp = '20170327220000'\n",
    "\n",
    "# Create datetime objects for start and end times\n",
    "datetime_start = datetime.strptime(radar_start_datetimestamp, '%Y%m%d%H%M%S')\n",
    "datetime_end = datetime.strptime(radar_end_datetimestamp, '%Y%m%d%H%M%S')\n",
    "\n",
    "radar_basedir = \\\n",
    "    '/Volumes/scr_fast/Projects/VORTEXSE/obsdata/2017/NEXRAD/IOP_1A'\n",
    "#radar_basedir = os.path.join(radar_basedir, '{}/{}'.format(date, radar_name[1:]))\n",
    "gridded_radar_dir = os.path.join(radar_basedir, 'gridded_new')\n",
    "\n",
    "radar_start_timestamp = datetime_start.strftime('%H%M%S')\n",
    "radar_end_timestamp = datetime_end.strftime('%H%M%S')\n",
    "gridded_radar_combined_filename = '{}_{}_{}_gridded.nc'.format(radar_name, radar_start_timestamp,\n",
    "                                                               radar_end_timestamp)\n",
    "\n",
    "gridded_radar_combined_filepath = os.path.join(gridded_radar_dir, gridded_radar_combined_filename)\n",
    "if os.path.exists(gridded_radar_combined_filepath):\n",
    "    # Read in file since we already dumped it out in a previous run of the notebook\n",
    "    gridded_radar_xr = xr.open_dataset(gridded_radar_combined_filepath)\n",
    "else:\n",
    "    # Read in individual gridded radar volumes, stack them into a combined Dataset and dump to disk\n",
    "    gridded_radar_paths = glob.glob(gridded_radar_dir + '/{}2017{}_*V06_gridded.nc'.format(radar_name, date))\n",
    "    print(gridded_radar_dir + '/{}2017{}_*V06_gridded.nc'.format(radar_name, date))\n",
    "    gridded_radar_paths = sorted(gridded_radar_paths)\n",
    "    gridded_radar_input_list = []\n",
    "    #print(gridded_radar_paths)\n",
    "    for path in gridded_radar_paths:\n",
    "        filename = os.path.basename(path)\n",
    "        file_timestamp = filename[4:19]\n",
    "        file_datetime = datetime.strptime(file_timestamp, '%Y%m%d_%H%M%S')\n",
    "        if file_datetime >= datetime_start and file_datetime <= datetime_end:\n",
    "            gridded_radar_input_list.append(path)\n",
    "    #print(gridded_radar_input_list)        \n",
    "    gridded_radar_list = []\n",
    "    gridded_radar_xr_list = []\n",
    "    for gridded_radar_path in gridded_radar_input_list:\n",
    "        print(\"Reading {}\".format(os.path.basename(gridded_radar_path)))\n",
    "        gridded_radar = pyart.io.read_grid(gridded_radar_path)\n",
    "        gridded_radar_xr = gridded_radar.to_xarray()\n",
    "        gridded_radar_xr_list.append(gridded_radar_xr)\n",
    "    gridded_radar_xr = xr.concat(gridded_radar_xr_list, dim='time')\n",
    "    print(\"Writing {}\".format(gridded_radar_combined_filename))\n",
    "    gridded_radar_xr.to_netcdf(gridded_radar_combined_filepath)\n",
    "\n",
    "print(gridded_radar_xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T03:24:53.712193Z",
     "start_time": "2021-01-03T03:24:53.651695Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_dir = '/Users/terrell8/Dropbox/Presentations/IOP_1A/retriev_interp'\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T03:25:40.029261Z",
     "start_time": "2021-01-03T03:25:36.825222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Check to see if masked versions of reflectivity and differential reflectivity exist in the file. \n",
    "# If not, create them here.\n",
    "ZH_thresh = 5.\n",
    "ZDR_thresh = 0.1\n",
    "\n",
    "print(\"Z and ZDR thresholds are {:f} and {:f}\".format(ZH_thresh, ZDR_thresh))\n",
    "\n",
    "if 'reflectivity_masked' not in gridded_radar_xr:\n",
    "    print(\"Masking Z and ZDR on thresholds of {:f} and {:f}\".format(ZH_thresh, ZDR_thresh))\n",
    "    ZH_mask = np.where(gridded_radar_xr['reflectivity'] < ZH_thresh, True, False)\n",
    "    ZH_mask = np.where(np.isfinite(gridded_radar_xr['reflectivity']), ZH_mask, False)\n",
    "    ZDR_mask = np.where(gridded_radar_xr['differential_reflectivity'] < ZDR_thresh, True, False)\n",
    "    ZDR_mask = np.where(np.isfinite(gridded_radar_xr['differential_reflectivity']), ZDR_mask, False)\n",
    "    full_mask = np.ma.mask_or(ZH_mask, ZDR_mask)\n",
    "\n",
    "    gridded_radar_xr['reflectivity_masked'] = gridded_radar_xr['reflectivity'].where(~full_mask)\n",
    "    gridded_radar_xr['differential_reflectivity_masked'] = \\\n",
    "        gridded_radar_xr['differential_reflectivity'].where(~full_mask)\n",
    "    print(\"Writing {}\".format(gridded_radar_combined_filename))\n",
    "    #gridded_radar_xr.to_netcdf(gridded_radar_combined_filepath)\n",
    "print(gridded_radar_xr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T21:31:55.331211Z",
     "start_time": "2021-01-02T21:31:54.748004Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in PIPS data\n",
    "PIPS_data_dir = '/Users/terrell8/sshfs_mounts/depot/data/Projects/VORTEXSE/obsdata/full_PIPS_dataset_RB15/'\n",
    "PIPS_filename = 'parsivel_combined_IOP1A_D1_2017_PIPS1A_60s.nc'.format(dates)\n",
    "PIPS_filepath = os.path.join(PIPS_data_dir, PIPS_filename)\n",
    "PIPS_ds = xr.load_dataset(PIPS_filepath)\n",
    "print(PIPS_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T21:31:56.674362Z",
     "start_time": "2021-01-02T21:31:56.610851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Grab the location of the PIPS\n",
    "PIPS_loc = eval(PIPS_ds.location)\n",
    "PIPS_lat = PIPS_loc[0]\n",
    "PIPS_lon = PIPS_loc[1]\n",
    "print(PIPS_loc)\n",
    "print(PIPS_lat, PIPS_lon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T21:32:04.703950Z",
     "start_time": "2021-01-02T21:32:04.575600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in sounding file to get low-level wind field and then derive storm-relative wind\n",
    "# Storm motion taken from subjective reflectivity tag tracking using GRLevel2\n",
    "#ustorm = 0.\n",
    "#vstorm = 0.\n",
    "\n",
    "# EDIT: setting ustorm, vstorm to 0 to force ground-relative flow\n",
    "ustorm = 0.\n",
    "vstorm = 0.\n",
    "# \n",
    "sounding_dir = '/Users/terrell8/Dropbox/0325_sounding/sounding_zip'\n",
    "sounding_filename = 'Courtland_1759.txt'\n",
    "sounding_path = os.path.join(sounding_dir, sounding_filename)\n",
    "sounding_metadata, sounding_df = readESC(sounding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T03:26:00.978075Z",
     "start_time": "2021-01-03T03:26:00.874248Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datetime_substart = datetime_start\n",
    "datetime_subend = datetime_end\n",
    "timestamp_substart = datetime_substart.strftime('%Y-%m-%dT%H:%M')\n",
    "timestamp_subend = datetime_subend.strftime('%Y-%m-%dT%H:%M')\n",
    "\n",
    "gridded_radar_xr_subset = gridded_radar_xr.sel(time=slice(timestamp_substart, timestamp_subend))\n",
    "print(gridded_radar_xr_subset['time'])\n",
    "\n",
    "# Round times to nearest minute\n",
    "rounded_times = gridded_radar_xr_subset['time'].dt.round('60S')\n",
    "print(rounded_times)\n",
    "gridded_radar_xr_subset['time'] = rounded_times\n",
    "\n",
    "time_seconds = (gridded_radar_xr_subset['time'] - gridded_radar_xr_subset['time'][0]) / np.timedelta64(1, 's')\n",
    "print(time_seconds)\n",
    "gridded_radar_xr_subset.coords['time_seconds'] = ('time', time_seconds)\n",
    "print(gridded_radar_xr_subset)\n",
    "# total_seconds = (gridded_radar_xr_subset['time'] - gridded_radar_xr_subset['time'][0]).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T03:26:02.489581Z",
     "start_time": "2021-01-03T03:26:02.421224Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract one level from the gridded radar Dataset\n",
    "height = 1000.\n",
    "gridded_radar_xr_subset_onelevel = gridded_radar_xr_subset.sel(z=height).squeeze()\n",
    "gridded_radar_xr_subset_onelevel = gridded_radar_xr_subset_onelevel.transpose(\"time\", \"y\", \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T03:26:59.132213Z",
     "start_time": "2021-01-03T03:26:57.788438Z"
    }
   },
   "outputs": [],
   "source": [
    "# Use pysteps for advection correction and temporal interpolation\n",
    "from pysteps import io, motion, rcparams\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "oflow_method = motion.get_method(\"LK\")\n",
    "fd_kwargs = {\"buffer_mask\": 10} # avoid edge effects\n",
    "\n",
    "# Plot example of optical flow field\n",
    "dBZ = gridded_radar_xr_subset_onelevel['reflectivity_masked']\n",
    "# print(dBZ[0])\n",
    "velocity_field = oflow_method(dBZ[5:7], fd_kwargs=fd_kwargs)\n",
    "\n",
    "qintv = 10\n",
    "xplt = gridded_radar_xr_subset_onelevel['x']\n",
    "yplt = gridded_radar_xr_subset_onelevel['y']\n",
    "uplt = velocity_field[0]\n",
    "vplt = velocity_field[1]\n",
    "print(velocity_field.shape)\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "clevels = np.arange(0., 61., 1.)\n",
    "dBZ = ax.contourf(xplt, yplt, dBZ[5], clevels=clevels, cmap='pyart_HomeyerRainbow')\n",
    "ax.quiver(xplt[::qintv], yplt[::qintv], uplt[::qintv,::qintv], vplt[::qintv,::qintv])\n",
    "cbarintv = 5.\n",
    "cbarlevels = ticker.MultipleLocator(base=cbarintv)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(dBZ, orientation='vertical', ticks=cbarlevels, cax=cax)\n",
    "cax.set_ylabel('dBZ')\n",
    "formatter = ticker.FuncFormatter(mtokm)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "# ax.xaxis.set_major_locator(ticker.MultipleLocator(base=axestickintv))\n",
    "# ax.yaxis.set_major_locator(ticker.MultipleLocator(base=axestickintv))\n",
    "ax.set_xlabel('km')\n",
    "ax.set_ylabel('km')\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plot_filename='pysteps_adv_correction.png'\n",
    "plot_filepath = os.path.join(plot_dir, plot_filename)\n",
    "fig.savefig(plot_filepath, dpi=300, bbox_inches='tight')\n",
    "\n",
    "print(uplt.mean(), vplt.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T21:23:34.879435Z",
     "start_time": "2020-12-30T21:23:19.780723Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Perform advection correction and interpolate gridded radar sequence to 1-min intervals\n",
    "# Just do Z and ZDR\n",
    "\n",
    "gridded_Z_ZDR = gridded_radar_xr_subset_onelevel[['reflectivity_masked', 'differential_reflectivity_masked']]\n",
    "tinterp_intv = 60.\n",
    "\n",
    "print(gridded_Z_ZDR)\n",
    "\n",
    "# print(gridded_Z_ZDR.isel(time=[0]))\n",
    "\n",
    "# for varname, var in gridded_Z_ZDR.items():\n",
    "#     print(varname)\n",
    "#     print(var[1])\n",
    "\n",
    "gridded_Z_ZDR_interp_list = interpolate_all(gridded_Z_ZDR, tinterp_intv, \n",
    "                                            base_field_name='reflectivity_masked')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T21:24:48.161774Z",
     "start_time": "2020-12-30T21:24:47.796936Z"
    }
   },
   "outputs": [],
   "source": [
    "gridded_Z_ZDR_interp_ds = xr.concat(gridded_Z_ZDR_interp_list, 'time')\n",
    "print(gridded_Z_ZDR_interp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T21:25:14.523719Z",
     "start_time": "2020-12-30T21:25:14.457207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Apply retrieval to get N0, alpha, and lamda\n",
    "# at 1-min intervals. Then compute N(D)\n",
    "# Then get times that different D reach surface. Store as new coordinate\n",
    "# Do \"groupby_bins\" operation on new coordinate to bin up trajectories within 1-min bins\n",
    "# Then either do the numpy histogram 2d thing or find another way \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T21:25:18.935924Z",
     "start_time": "2020-12-30T21:25:18.146963Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set retrieval lookup table to use\n",
    "retrieval_tag = 'Z01'\n",
    "lookup_dir = os.path.join('/Users/terrell8/Projects/pyPIPS/data/lookups/', retrieval_tag)\n",
    "\n",
    "# Retrieve gamma DSD parameters from ZH and ZDR\n",
    "print(\"Getting ZH and ZDR fields\")\n",
    "# Get the ZH and ZDR fields from the xarray Dataset\n",
    "ZH_rad = gridded_Z_ZDR_interp_ds['reflectivity_masked']\n",
    "ZDR_rad = gridded_Z_ZDR_interp_ds['differential_reflectivity_masked']\n",
    "\n",
    "# Read in first lookup table to get the interval between reflectivity and ZDR\n",
    "lookup_path = os.path.join(lookup_dir, 'D0.csv')\n",
    "retr_table = pd.read_csv(lookup_path, sep=',', header=0, index_col='dBZ')\n",
    "# Massage the index and column labels to get rid of extraneous zeros\n",
    "# Also convert column labels from strings to floats\n",
    "retr_table.index = retr_table.index.to_series().apply(np.around, decimals=4)\n",
    "retr_table.columns = [np.around(np.float(col), decimals=4) for col in retr_table.columns]\n",
    "\n",
    "dBZ_lookup_min = retr_table.index[0]\n",
    "dBZ_lookup_max = retr_table.index[-1]\n",
    "ZDR_lookup_min = retr_table.columns[0]\n",
    "ZDR_lookup_max = retr_table.columns[-1]\n",
    "dBZ_intv = retr_table.index[1] - retr_table.index[0]\n",
    "ZDR_intv = float(retr_table.columns[1]) - float(retr_table.columns[0])\n",
    "\n",
    "# Replace masked entries in ZH_rad and ZDR_rad with the minimum value of the lookup table\n",
    "ZH_mask = ZH_rad.isnull()\n",
    "ZDR_mask = ZDR_rad.isnull()\n",
    "full_mask = xr.where(ZH_mask | ZDR_mask, True, False)\n",
    "ZH_rad = ZH_rad.fillna(dBZ_lookup_min)\n",
    "ZDR_rad = ZDR_rad.fillna(ZDR_lookup_min)\n",
    "# Now limit values to within lookup table limits\n",
    "ZH_rad = ZH_rad.where(ZH_rad > dBZ_lookup_min, dBZ_lookup_min)\n",
    "ZH_rad = ZH_rad.where(ZH_rad < dBZ_lookup_max, dBZ_lookup_max)\n",
    "ZDR_rad = ZDR_rad.where(ZDR_rad > ZDR_lookup_min, ZDR_lookup_min)\n",
    "ZDR_rad = ZDR_rad.where(ZDR_rad < ZDR_lookup_max, ZDR_lookup_max)\n",
    "# Round ZH and ZDR fields to the nearest interval\n",
    "ZH_round = roundPartial(ZH_rad, dBZ_intv)\n",
    "ZDR_round = roundPartial(ZDR_rad, ZDR_intv)\n",
    "# Get the shape of the arrays for later, so we can reshape the flattened arrays of retrieved\n",
    "# values\n",
    "ZH_shape = ZH_round.shape\n",
    "print(ZH_shape)\n",
    "ZH_flat = ZH_round.values.flatten()\n",
    "ZDR_flat = ZDR_round.values.flatten()\n",
    "print(ZH_flat.max())\n",
    "print(ZDR_flat.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T21:27:27.550003Z",
     "start_time": "2020-12-30T21:25:27.558729Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "retr_var_da_dict = {}\n",
    "for retr_varname in radar.retrieval_metadata.keys():\n",
    "    print(\"Retrieving {} using lookup tables\".format(retr_varname))\n",
    "    lookup_path = os.path.join(lookup_dir, '{}.csv'.format(retr_varname))\n",
    "    retr_table = pd.read_csv(lookup_path, sep=',', header=0, index_col='dBZ')\n",
    "    # Round the indices and columns of the DataFrame (i.e. the dBZ values) to some sane\n",
    "    # number of decimal places to facilitate using it as a lookup table. The floating point\n",
    "    # precision gets in the way sometimes here. For example 56.4 is dumped out as\n",
    "    # 56.4<some bunch of zeros>1\n",
    "    retr_table.index = retr_table.index.to_series().apply(np.around, decimals=4)\n",
    "    retr_table.columns = [np.around(np.float(col), decimals=4) for col in\n",
    "                          retr_table.columns]\n",
    "    # Gah, for some reason DataFrame.lookup sometimes barfs on perfectly good floating point\n",
    "    # values in columns, so convert them back to strings here. :rolleyes:\n",
    "    # EDIT 11/09/2020: Now this is happening for the rows as well. Not sure why... So change the row labels\n",
    "    # to strings as well.\n",
    "    retr_table.index = [str(row) for row in retr_table.index]\n",
    "    retr_table.columns = [str(col) for col in retr_table.columns]\n",
    "    # print(list(retr_table.index))\n",
    "    # print(list(retr_table.columns))\n",
    "    # Ok, now retrieve the desired retrieval variable\n",
    "    # for each ZH/ZDR pair in the flattened radar sweep\n",
    "#     for ZH, ZDR in zip(ZH_flat, ZDR_flat):\n",
    "#         print(ZH, ZDR)\n",
    "#         retr_val = retr_table.lookup([ZH.astype('str')], [ZDR.astype('str')])\n",
    "    retr_vals = retr_table.lookup(ZH_flat.astype('str'), ZDR_flat.astype('str'))\n",
    "    # retr_vals = retr_table.lookup(ZH_flat, ZDR_flat)\n",
    "    # Reshape back to original shape\n",
    "    retr_vals_data = retr_vals.reshape(ZH_shape)\n",
    "    retr_vals_data = np.where(full_mask, np.nan, retr_vals_data)\n",
    "    # retr_vals_data = np.ma.masked_array(retr_vals_data, mask=full_mask)\n",
    "    retr_var_da = ZH_rad.copy()\n",
    "    retr_var_da.name = retr_varname\n",
    "    retr_var_da[:] = retr_vals_data\n",
    "    retr_var_da_dict[retr_varname] = retr_var_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T21:29:38.828602Z",
     "start_time": "2020-12-30T21:29:38.727749Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine retrieved fields and Z and ZDR fields into a single Dataset\n",
    "gridded_radar_interp_ds = gridded_Z_ZDR_interp_ds.copy()\n",
    "for varname, var_da in retr_var_da_dict.items():\n",
    "    gridded_radar_interp_ds[varname] = var_da\n",
    "    \n",
    "print(gridded_radar_interp_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T21:29:56.837718Z",
     "start_time": "2020-12-30T21:29:48.374162Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save interpolated grid to file\n",
    "out_start_timestamp = datetime_substart.strftime('%Y%m%d%H%M')\n",
    "out_end_timestamp = datetime_subend.strftime('%Y%m%d%H%M')\n",
    "gridded_radar_interp_filename = '{}_{}_{}_z{:d}_gridded_interp.nc'.format(radar_name, out_start_timestamp,\n",
    "                                                                          out_end_timestamp, int(height))\n",
    "gridded_radar_interp_filepath = os.path.join(gridded_radar_dir, gridded_radar_interp_filename)\n",
    "gridded_radar_interp_ds.to_netcdf(gridded_radar_interp_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:58:30.747079Z",
     "start_time": "2020-12-28T17:58:29.206688Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find PIPS x, y location by interpolating to its lat/lon point\n",
    "gridded_radar_interp_latlon_ds = gridded_radar_interp_ds.swap_dims({'x': 'lon', 'y': 'lat'})\n",
    "radar_at_PIPS_da = gridded_radar_interp_latlon_ds.interp(lat=PIPS_lat, lon=PIPS_lon)\n",
    "PIPS_x = radar_at_PIPS_da['x'].values.item()\n",
    "PIPS_y = radar_at_PIPS_da['y'].values.item()\n",
    "print(radar_at_PIPS_da)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T17:58:35.968034Z",
     "start_time": "2020-12-28T17:58:35.625096Z"
    }
   },
   "outputs": [],
   "source": [
    "radar_at_PIPS_da['reflectivity_masked'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filename='reflectivity_masked_plot.png'\n",
    "plot_filepath = os.path.join(plot_dir, plot_filename)\n",
    "fig.savefig(plot_filepath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T18:00:30.238262Z",
     "start_time": "2020-12-28T17:59:41.812323Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot reflectivity for time-interpolated grid\n",
    "# Choose a subset of times to keep animation size down\n",
    "anim_start = '2017-03-25T17:00'\n",
    "anim_end = '2017-03-25T18:36'\n",
    "\n",
    "var_da = gridded_radar_interp_ds['reflectivity_masked'].sel(time=slice(anim_start, anim_end))\n",
    "\n",
    "clevels =np.arange(0., 61., 1.)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=60.)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xplt, yplt, var.squeeze(), levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    # Plot PIPS location\n",
    "    ax.plot([PIPS_x], [PIPS_y], 'k*')\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "plt.close()\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'interp_masked_ref_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:03:45.542364Z",
     "start_time": "2020-12-16T20:03:25.988717Z"
    }
   },
   "outputs": [],
   "source": [
    "print(retr_var_da_dict.keys())\n",
    "\n",
    "D0_da = retr_var_da_dict['D0']\n",
    "\n",
    "clevels =np.arange(0., 6., 0.1)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=6.)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(D0_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xplt, yplt, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "plt.close()\n",
    "HTML(ani.to_jshtml())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'D0_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:04:44.070644Z",
     "start_time": "2020-12-16T20:04:29.212683Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "var_da = retr_var_da_dict['mu']\n",
    "\n",
    "clevels =np.arange(0., 30., 1.)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=30.)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xplt, yplt, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "plt.close()\n",
    "HTML(ani.to_jshtml())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'mu_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T18:01:04.761088Z",
     "start_time": "2020-12-28T18:01:04.671225Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract within a small bounding box for testing\n",
    "lat_bgn = 34.0\n",
    "lat_end = 35.5\n",
    "lon_bgn = -87.5\n",
    "lon_end = -86.75\n",
    "\n",
    "# ibgn = 50\n",
    "# iend = 150\n",
    "# jbgn = 125\n",
    "# jend = 225\n",
    "# level = 2\n",
    "# z_level = gridded_radar.point_z['data'][level, 0, 0]\n",
    "# z_level = 1000.\n",
    "gridded_radar_interp_ds = gridded_radar_interp_ds.swap_dims({'y': 'lat', 'x': 'lon'})\n",
    "gridded_radar_subgrid = gridded_radar_interp_ds.sel(lat=slice(lat_bgn, lat_end), lon=slice(lon_bgn, lon_end))\n",
    "#gridded_radar_subgrid = gridded_radar_subgrid.squeeze()\n",
    "gridded_radar_subgrid = gridded_radar_subgrid.transpose('time', 'lat', 'lon')\n",
    "print(gridded_radar_subgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T18:01:13.987603Z",
     "start_time": "2020-12-28T18:01:11.155374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate ND for each grid point from gamma dist. parameters using Parsivel bins\n",
    "avg_diameters = pp.parsivel_parameters['avg_diameter_bins_mm']\n",
    "#avg_diameters = avg_diameters[:, np.newaxis, np.newaxis]\n",
    "#avg_diameters = xr.DataArray(avg_diameters, dims=['diameter_bin', 'y', 'x'])\n",
    "avg_diameters = xr.DataArray(avg_diameters, coords = {'diameter': ('diameter_bin', avg_diameters)}, \n",
    "                             dims=['diameter_bin'])\n",
    "\n",
    "lamda = gridded_radar_subgrid['lamda'] * 1000. # get to m^-1\n",
    "alpha = gridded_radar_subgrid['mu']\n",
    "N0 = gridded_radar_subgrid['N0'] * 1000**(1 + alpha) # get to m^-4\n",
    "ND = dsd.calc_binned_DSD_from_params(N0, lamda, alpha, avg_diameters) * 1.e-3 # Get to m^-3 mm^-1\n",
    "ND.coords['max_diameter'] = ('diameter_bin', pp.parsivel_parameters['max_diameter_bins_mm'])\n",
    "ND.coords['min_diameter'] = ('diameter_bin', pp.parsivel_parameters['min_diameter_bins_mm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T18:01:18.959105Z",
     "start_time": "2020-12-28T18:01:18.882108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up grid for precip trajectories\n",
    "height_AGL_snd = sounding_df['height'] - sounding_metadata['selev']\n",
    "# print(gridded_radar_subgrid['x'])\n",
    "grid_height = gridded_radar_subgrid['z'].values\n",
    "# grid_height = 2000.\n",
    "# print(gridded_radar.origin_altitude)\n",
    "dz = 1.\n",
    "new_heights = np.arange(0., grid_height + dz, dz)\n",
    "\n",
    "# Interpolate sounding u, v to new regularly spaced heights\n",
    "u_snd = sounding_df['u'].values\n",
    "f = interpolate.interp1d(height_AGL_snd, u_snd, bounds_error=False, fill_value=(u_snd[0], u_snd[-1]))\n",
    "ug = f(new_heights)\n",
    "\n",
    "v_snd = sounding_df['v'].values\n",
    "f = interpolate.interp1d(height_AGL_snd, v_snd, bounds_error=False, fill_value=(v_snd[0], v_snd[-1]))\n",
    "vg = f(new_heights)\n",
    "\n",
    "# Storm-relative winds\n",
    "usr = ug - ustorm\n",
    "vsr = vg - vstorm\n",
    "\n",
    "# Layer-mean storm-relative winds\n",
    "usm = np.mean(usr)\n",
    "vsm = np.mean(vsr)\n",
    "print(usm, vsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T18:04:24.002361Z",
     "start_time": "2020-12-28T18:01:21.588704Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Truncate diameter range to less than 9 mm\n",
    "D_max = 9.\n",
    "D_range_full = ND['diameter'].values\n",
    "D_max_ind = np.searchsorted(D_range_full, D_max)\n",
    "D_range = D_range_full[:D_max_ind]\n",
    "print(D_range)\n",
    "ND_trunc = ND.isel(diameter_bin=slice(0, D_max_ind))\n",
    "\n",
    "# Compute range of terminal velocities from Brandes relation\n",
    "vt_range = rain_Brandes(D_range / 1000.)\n",
    "print(vt_range)\n",
    "\n",
    "# Set dimensions back from lat/lon to y/x for ND_trunc\n",
    "ND_trunc = ND_trunc.swap_dims({'lon': 'x', 'lat': 'y'})\n",
    "ND_trunc = ND_trunc.swap_dims({'time': 'time_seconds'})\n",
    "\n",
    "# Interpolate ND to a finer grid\n",
    "# Set up grid of locations\n",
    "x_coords = ND_trunc['x']\n",
    "y_coords = ND_trunc['y']\n",
    "t_coords = ND_trunc['time_seconds']\n",
    "\n",
    "refinement_factor = 4\n",
    "time_refinement_factor = 1\n",
    "\n",
    "new_x_coords = np.linspace(x_coords.x[0], x_coords.x[-1], x_coords.sizes['x'] * refinement_factor)\n",
    "new_y_coords = np.linspace(y_coords.y[0], y_coords.y[-1], y_coords.sizes['y'] * refinement_factor)\n",
    "new_t_coords = np.linspace(t_coords.time_seconds[0], t_coords.time_seconds[-1], \n",
    "                           t_coords.sizes['time_seconds'] * time_refinement_factor)\n",
    "\n",
    "ND_trunc = ND_trunc.interp(x=new_x_coords, y=new_y_coords, time_seconds=new_t_coords)\n",
    "\n",
    "x_grid, y_grid, t_grid = xr.broadcast(ND_trunc['x'], ND_trunc['y'], ND_trunc['time_seconds'])\n",
    "\n",
    "x_flat = x_grid.stack(loc=['time_seconds', 'y', 'x']).values\n",
    "y_flat = y_grid.stack(loc=['time_seconds', 'y', 'x']).values\n",
    "t_flat = t_grid.stack(loc=['time_seconds', 'y', 'x']).values\n",
    "\n",
    "# Compute horizontal deviations of drops and residence time at bottom of layer for each grid point and drop size\n",
    "# TODO: Generalize this for spatially varying velocity field. Would require a numerical trajectory integration\n",
    "# TODO: Update this to perturb the terminal velocities for all grid points (already modified the function above)\n",
    "xf, yf, tf = cal_xf_tf(usm, vsm, vt_range, grid_height)\n",
    "x_flat_f = x_flat[:, np.newaxis] + xf\n",
    "y_flat_f = y_flat[:, np.newaxis] + yf\n",
    "\n",
    "# Create array of times corresponding to each initial time for trajectory endpoints as a function of diameter\n",
    "t_flat_f = t_flat[:, np.newaxis] + tf\n",
    "\n",
    "x_flat_f = x_flat_f.T\n",
    "y_flat_f = y_flat_f.T\n",
    "t_flat_f = t_flat_f.T\n",
    "\n",
    "# Perturb the endpoints a bit in space and time\n",
    "xpertscale = 20. # m\n",
    "tpertscale = 1. # s\n",
    "rng = np.random.default_rng()\n",
    "xpert = xpertscale * rng.standard_normal(size=x_flat_f.shape)\n",
    "ypert = xpertscale * rng.standard_normal(size=y_flat_f.shape)\n",
    "tpert = tpertscale * rng.standard_normal(size=t_flat_f.shape)\n",
    "\n",
    "xpert = np.where(xpert < -10.*xpertscale, 0., xpert)\n",
    "xpert = np.where(xpert > 10.*xpertscale, 0., xpert)\n",
    "ypert = np.where(ypert < -10.*xpertscale, 0., ypert)\n",
    "ypert = np.where(ypert > 10.*xpertscale, 0., ypert)\n",
    "tpert = np.where(tpert < -10.*tpertscale, 0., tpert)\n",
    "tpert = np.where(tpert > 10.*tpertscale, 0., tpert)\n",
    "\n",
    "x_flat_f = x_flat_f + xpert\n",
    "y_flat_f = y_flat_f + ypert\n",
    "t_flat_f = t_flat_f + tpert\n",
    "\n",
    "ND_trunc = ND_trunc.transpose('diameter_bin', 'time_seconds', 'y', 'x')\n",
    "print(x_flat_f.shape, y_flat_f.shape, t_flat_f.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T18:04:34.214726Z",
     "start_time": "2020-12-28T18:04:32.426549Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up 3D bins (2 for space, 1 for time) for bottom of sorting layer\n",
    "\n",
    "dx_bins = 500.\n",
    "dx_orig = new_x_coords[1] - new_x_coords[0]\n",
    "print(\"dx (top), dx (bottom)\", dx_orig, dx_bins)\n",
    "area_ratio = dx_bins**2. / dx_orig**2.\n",
    "print(\"area ratio: \", area_ratio)\n",
    "# Get bounding box of bottom of domain\n",
    "xmin = int(x_flat_f.min()) # -5000.\n",
    "xmax = int(x_flat_f.max())\n",
    "ymin = int(y_flat_f.min()) # -5000.\n",
    "ymax = int(y_flat_f.max())\n",
    "\n",
    "# Create bins for bottom of domain\n",
    "xbins = int((xmax-xmin)/dx_bins)\n",
    "ybins = int((ymax-ymin)/dx_bins)\n",
    "\n",
    "print(xbins)\n",
    "print(ybins)\n",
    "xmax = xmin+dx_bins*xbins # +5000.\n",
    "ymax = ymin+dx_bins*ybins # +5000.\n",
    "print(xmin, xmax, ymin, ymax)\n",
    "\n",
    "# Set up time bins\n",
    "# EDIT: just use original time bins\n",
    "tintv = 60.\n",
    "# tmin = t_flat_f.min()\n",
    "# tmax = t_flat_f.max()\n",
    "# print(tmin, tmax)\n",
    "# tbins = int((tmax - tmin) / tintv)\n",
    "tmin = ND_trunc['time_seconds'][0].values\n",
    "tmax = ND_trunc['time_seconds'][-1].values + tintv\n",
    "tbins = int((tmax - tmin) / tintv)\n",
    "print(tmin, tmax, tbins)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T18:06:16.416754Z",
     "start_time": "2020-12-28T18:04:43.416050Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create 3D histogram (x, y, t) for number density for each diameter bin for drop trajectory endpoints\n",
    "\n",
    "ND_D_binned_list = []\n",
    "\n",
    "for i, ND_D in enumerate(ND_trunc):\n",
    "    print(\"Index: \", i)\n",
    "    x = x_flat_f[i]\n",
    "    y = y_flat_f[i]\n",
    "    t = t_flat_f[i]\n",
    "    \n",
    "    coords = np.stack([x, y, t], axis=1)\n",
    "    ND_D_binned, edges = np.histogramdd(coords,\n",
    "                                        bins=[xbins, ybins, tbins],\n",
    "                                        range=[[xmin, xmax], [ymin, ymax], [tmin, tmax]],\n",
    "                                        weights=ND_D.values.flatten())\n",
    "    ND_D_binned_list.append(ND_D_binned)\n",
    "\n",
    "    \n",
    "ND_D_binned = np.array(ND_D_binned_list)\n",
    "xedges, yedges, tedges = edges\n",
    "start_time = ND['time'][0].values\n",
    "attrs = {\"units\": \"seconds since {}\".format(start_time)}\n",
    "\n",
    "ND_f_da = xr.DataArray(ND_D_binned,\n",
    "                       coords={\n",
    "                           \"diameter\": ND_trunc['diameter'], \n",
    "                           \"x\": xedges[:-1],\n",
    "                           \"y\": yedges[:-1],\n",
    "                           \"time_seconds\": tedges[:-1],\n",
    "                       },\n",
    "                       dims=[\"diameter_bin\", \"x\", \"y\", \"time_seconds\"])\n",
    "\n",
    "ND_f_da.coords[\"time\"] = (\"time_seconds\", ND_f_da[\"time_seconds\"], attrs)\n",
    "ND_f_ds = xr.decode_cf(ND_f_da.to_dataset(name='ND'))\n",
    "ND_f_ds = ND_f_ds.swap_dims({\"time_seconds\": \"time\"})\n",
    "ND_f_ds.coords['max_diameter'] = ('diameter_bin', pp.parsivel_parameters['max_diameter_bins_mm'][:D_max_ind])\n",
    "ND_f_ds.coords['min_diameter'] = ('diameter_bin', pp.parsivel_parameters['min_diameter_bins_mm'][:D_max_ind])\n",
    "ND_f_ds = ND_f_ds.transpose(\"time\", \"y\", \"x\", \"diameter_bin\")\n",
    "ND_f_ds = ND_f_ds.swap_dims({'diameter_bin': 'diameter'}) # Do this so we can use it for sel function. May\n",
    "                                                          # break other stuff so make sure to check later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-28T18:16:15.620842Z",
     "start_time": "2020-12-28T18:06:41.299690Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "D_to_plot = 1.\n",
    "\n",
    "xctr = 0.5 * (xedges[1:] + xedges[:-1])\n",
    "yctr = 0.5 * (yedges[1:] + yedges[:-1])\n",
    "\n",
    "var_da = ND_f_ds['ND'].sel(diameter=D_to_plot, method='nearest')\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels = np.logspace(-1., 4., num=100)\n",
    "norm = cm.colors.LogNorm(vmin=1., vmax=10000.)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values\n",
    "    ci = ax.contourf(xctr, yctr, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='plasma', norm=norm)\n",
    "    ax.plot([PIPS_x], [PIPS_y], 'k*')\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        # ax.set_xlim(xplt[0], xplt[-1])\n",
    "        # ax.set_ylim(yplt[0], yplt[-1])\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "plt.close()\n",
    "HTML(ani.to_jshtml())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'ND_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-28T18:19:35.333Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate radar variables for new surface DSDs\n",
    "# Get polarimetric variables\n",
    "dD = ND_f_ds['max_diameter'] - ND_f_ds['min_diameter']\n",
    "print(dD)\n",
    "# ND_f_ds_flat = ND_f_ds.stack(loc=['time', 'y', 'x'])\n",
    "# ND_f_ds_flat = ND_f_ds_flat.transpose(\"loc\", \"diameter_bin\")\n",
    "# print(ND_f_ds_flat)\n",
    "ND_f_ds = ND_f_ds.swap_dims({'diameter': 'diameter_bin'})\n",
    "dualpol_dict = dualpol.calpolrain_xr(10.7, '/Users/terrell8/Projects/pyPIPS/tmatrix/S-Band/SCTT_RAIN_fw100.dat',\n",
    "                                     ND_f_ds['ND'], dD)\n",
    "print(dualpol_dict.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dualpol_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:24:14.558841Z",
     "start_time": "2020-12-16T20:23:49.606131Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "xctr = 0.5 * (xedges[1:] + xedges[:-1])\n",
    "yctr = 0.5 * (yedges[1:] + yedges[:-1])   \n",
    "\n",
    "var_da = dualpol_dict['REF']\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels =np.arange(0., 61., 1.)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=60.)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xctr, yctr, var.squeeze(),\n",
    "                     levels=clevels,\n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        #ax.set_xlim(xplt[0], xplt[-1])\n",
    "        #ax.set_ylim(yplt[0], yplt[-1])\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "\n",
    "HTML(ani.to_jshtml())\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'REF_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:25:11.434912Z",
     "start_time": "2020-12-16T20:24:51.033401Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# xctr = 0.5 * (xedges[1:] + xedges[:-1])\n",
    "# yctr = 0.5 * (yedges[1:] + yedges[:-1])\n",
    "\n",
    "var_da = gridded_radar_subgrid['reflectivity_masked']\n",
    "xplt = gridded_radar_subgrid.coords[\"x\"]\n",
    "yplt = gridded_radar_subgrid.coords[\"y\"]\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels =np.arange(0., 61., 1.)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=60.)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xplt, yplt, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        # ax.set_xlim(xplt[0], xplt[-1])\n",
    "        # ax.set_ylim(yplt[0], yplt[-1])\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "HTML(ani.to_jshtml())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'Reflectivity_Masked_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:28:52.781845Z",
     "start_time": "2020-12-16T20:28:26.481573Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "xctr = 0.5 * (xedges[1:] + xedges[:-1])\n",
    "yctr = 0.5 * (yedges[1:] + yedges[:-1])\n",
    "\n",
    "var_da = dualpol_dict['ZDR']\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels =np.arange(0., 6., 0.1)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=6.)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xctr, yctr, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        # ax.set_xlim(xplt[0], xplt[-1])\n",
    "        # ax.set_ylim(yplt[0], yplt[-1])\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "HTML(ani.to_jshtml())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'ZDR_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T20:29:39.637349Z",
     "start_time": "2020-12-16T20:29:20.285671Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "# xctr = 0.5 * (xedges[1:] + xedges[:-1])\n",
    "# yctr = 0.5 * (yedges[1:] + yedges[:-1])\n",
    "\n",
    "var_da = gridded_radar_subgrid['differential_reflectivity_masked']\n",
    "xplt = gridded_radar_subgrid.coords[\"x\"]\n",
    "yplt = gridded_radar_subgrid.coords[\"y\"]\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels =np.arange(0., 6., 0.1)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=6.)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "ims = []\n",
    "for i, var in enumerate(var_da):\n",
    "    time = var.coords['time_seconds'].values.item()\n",
    "    ci = ax.contourf(xplt, yplt, var.squeeze(), \n",
    "                     levels=clevels, \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm)\n",
    "    if i == 0.:\n",
    "        fig.colorbar(ci, ax=ax)\n",
    "        # ax.set_xlim(xplt[0], xplt[-1])\n",
    "        # ax.set_ylim(yplt[0], yplt[-1])\n",
    "        ax.set_aspect('equal')\n",
    "    ims.append(ci.collections)\n",
    "    \n",
    "ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000)\n",
    "\n",
    "HTML(ani.to_jshtml())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = 'ZDR_Masked_{}_{}_z{:d}.mp4'.format(anim_start, anim_end, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

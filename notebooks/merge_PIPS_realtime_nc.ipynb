{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T21:18:48.553425Z",
     "start_time": "2019-09-03T21:18:48.478698Z"
    }
   },
   "outputs": [],
   "source": [
    "#This notebook is for plotting of PIPS data from the real-time script's netCDF file dumps and merging \n",
    "#with netCDF\n",
    "#files produced from the onboard card data if necessary\n",
    "# IMPORTANT: It should be run right after running PIPS_to_nc.py\n",
    "# TODO: make this into a stand-alone command-line driven script like the others\n",
    "%matplotlib notebook\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from pyPIPS import thermolib as thermo\n",
    "from pyPIPS import timemodule as tm\n",
    "import pyPIPS.PIPS as pips\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid, make_axes_locatable, host_subplot\n",
    "import pyPIPS.plotmodule as pm\n",
    "from pyPIPS.PIPS import avg_diameter, avg_fall_bins, max_diameter, \\\n",
    "    min_diameter, min_fall_bins, diameter_edges, fall_bins_edges\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T21:18:49.917577Z",
     "start_time": "2019-09-03T21:18:49.821037Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function definitions. \n",
    "\n",
    "def get_files(file_list, starttime, endtime, ftype='onesec'):\n",
    "    ''' this seems like a janky way to do it, but is actually 3x faster than\n",
    "        making a loop of files.'''\n",
    "\n",
    "    len_prefix = 8 + len(ftype)\n",
    "\n",
    "    day_str = [(starttime + timedelta(days=i)).strftime(\"%Y%m%d\")\n",
    "               for i in range((endtime - starttime).days + 1)]\n",
    "\n",
    "    # find all PIPS files with days between starttime and endtime\n",
    "    file_list = [file_name for file_name in file_list if any(day in file_name for day in day_str)]\n",
    "    # file_list = [f for subf in file_list for f in subf]  # flatten list in case of multiple days\n",
    "\n",
    "    if file_list:\n",
    "        # sort files by date, then find nearest indices for all the dates, and loop over that\n",
    "        sorted_files = sorted(file_list,\n",
    "                              key=lambda f: datetime.strptime(f[len_prefix:len_prefix + 14],\n",
    "                                                              '%Y%m%d%H%M%S'))\n",
    "        starttimes = [datetime.strptime(f[len_prefix:len_prefix + 14], '%Y%m%d%H%M%S')\n",
    "                      for f in sorted_files]\n",
    "        endtimes = [datetime.strptime(f[len_prefix + 15:len_prefix + 29], '%Y%m%d%H%M%S')\n",
    "                    for f in sorted_files]\n",
    "        _, idx1 = min((abs(val - starttime), idx) for (idx, val) in enumerate(starttimes))\n",
    "        _, idx2 = min((abs(val - endtime), idx) for (idx, val) in enumerate(endtimes))\n",
    "        file_list = sorted_files[idx1:idx2 + 1]\n",
    "\n",
    "    return file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T21:18:51.314834Z",
     "start_time": "2019-09-03T21:18:51.244790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up dictionaries to control plotting parameters\n",
    "\n",
    "dateformat = '%H:%M'\n",
    "\n",
    "# Temperature and dewpoint\n",
    "temp_dewp_ax_params = {\n",
    "    'majorxlocator': dates.MinuteLocator(byminute=[0, 15, 30, 45], interval=1), \n",
    "    'majorxformatter': dates.DateFormatter(dateformat),\n",
    "    'minorxlocator': dates.MinuteLocator(byminute=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55], interval=1),\n",
    "    'axeslimits': [None, (-5., 35.)],\n",
    "    'axeslabels': ['Time (H:M) UTC', r'Temperature ($^{\\circ}$C)']\n",
    "}\n",
    "\n",
    "# Wind speed and direction\n",
    "windspd_ax_params = {\n",
    "    'majorxlocator': dates.MinuteLocator(byminute=[0, 15, 30, 45], interval=1), \n",
    "    'majorxformatter': dates.DateFormatter(dateformat),\n",
    "    'minorxlocator': dates.MinuteLocator(byminute=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55], interval=1),\n",
    "    'axeslimits': [None, [0.0, 25.0]],\n",
    "    'axeslabels': ['Time (H:M) UTC', r'wind speed (m s$^{-1}$)']\n",
    "}\n",
    "\n",
    "winddir_ax_params = {\n",
    "    'majorylocator': ticker.MultipleLocator(45.),\n",
    "    'axeslimits': [None, [0.0, 360.0]],\n",
    "    'axeslabels': [None, r'Wind direction ($^{\\circ}$C)']\n",
    "}\n",
    "\n",
    "pressure_ax_params = {\n",
    "    'majorylocator': ticker.MultipleLocator(5.),\n",
    "    'axeslimits': [None, [940., 980.]],\n",
    "    'axeslabels': [None, r'Pressure (hPa)']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Number concentration\n",
    "log_ND_params = {\n",
    "    'type': 'pcolor', \n",
    "    'vlimits': [-1.0, 3.0],\n",
    "    'clabel': r'log[N ($m^{-3} mm^{-1}$)]'\n",
    "}\n",
    "\n",
    "log_ND_ax_params = {\n",
    "    'majorxlocator': dates.MinuteLocator(byminute=[0, 15, 30, 45], interval=1), \n",
    "    'majorxformatter': dates.DateFormatter(dateformat),\n",
    "    'minorxlocator': dates.MinuteLocator(byminute=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55], interval=1),\n",
    "    'axeslimits': [None, [0.0, 9.0]],\n",
    "    'majorylocator': ticker.MultipleLocator(base=0.25),\n",
    "    'axeslabels': [None, 'D (mm)']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-03T21:18:50.671417Z",
     "start_time": "2019-09-03T21:18:50.612780Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up directories reading the data and plotting\n",
    "# base_output_dir = '/Users/dawson29/sshfs_mounts/depot/data/Projects/TriPIPS/webdata/'\n",
    "deployment_name = '022723_mass_test' # 'IOP2_030323'\n",
    "\n",
    "base_realtime_input_dir = '/Users/dawson29/Dropbox/Projects/PERiLS/obsdata/2023/2023_realtime'\n",
    "realtime_netcdf_input_dir = os.path.join(base_realtime_input_dir, deployment_name)\n",
    "\n",
    "base_card_input_dir = '/Users/dawson29/Dropbox/Projects/PERiLS/obsdata/2023/'\n",
    "card_netcdf_input_dir = os.path.join(base_card_input_dir, deployment_name, 'netcdf')\n",
    "card_netcdf_output_dir = os.path.join(base_card_input_dir, deployment_name, 'netcdf_rt_merged')\n",
    "if not os.path.exists(card_netcdf_output_dir):\n",
    "    os.makedirs(card_netcdf_output_dir)\n",
    "\n",
    "plot_output_dir = os.path.join(base_realtime_input_dir, 'plots')\n",
    "\n",
    "if not os.path.exists(plot_output_dir):\n",
    "    os.makedirs(plot_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the PIPS name, dates and times to read and plot\n",
    "\n",
    "PIPS_name = 'PIPS3B'\n",
    "\n",
    "starttime_stamp = '20230227030000'\n",
    "endtime_stamp = '20230227213000'\n",
    "\n",
    "starttime_dt = datetime.strptime(starttime_stamp, tm.timefmt3)\n",
    "endtime_dt = datetime.strptime(endtime_stamp, tm.timefmt3)\n",
    "\n",
    "file_path_list_onePIPS = glob.glob(realtime_netcdf_input_dir + f'/*{PIPS_name}*nc')\n",
    "file_list_onePIPS = [os.path.basename(file_path) for file_path in file_path_list_onePIPS]\n",
    "\n",
    "file_list_onesec = [file_name for file_name in file_list_onePIPS if 'onesec' in file_name]\n",
    "file_list_onesec = [file_name for file_name in file_list_onesec if 'current' not in file_name]\n",
    "file_list_onesec = get_files(file_list_onesec, starttime_dt, endtime_dt)\n",
    "file_path_list_onesec = [os.path.join(realtime_netcdf_input_dir, file_name) for file_name in file_list_onesec]\n",
    "\n",
    "\n",
    "file_list_ND = [file_name for file_name in file_list_onePIPS if 'ND' in file_name]\n",
    "file_list_ND = [file_name for file_name in file_list_ND if 'current' not in file_name]\n",
    "file_list_ND = get_files(file_list_ND, starttime_dt, endtime_dt, ftype='ND')\n",
    "file_path_list_ND = [os.path.join(realtime_netcdf_input_dir, file_name) for file_name in file_list_ND]\n",
    "\n",
    "file_list_spectrum = [file_name for file_name in file_list_onePIPS if 'spectrum' in file_name]\n",
    "file_list_spectrum = [file_name for file_name in file_list_spectrum if 'current' not in file_name]\n",
    "file_list_spectrum = get_files(file_list_spectrum, starttime_dt, endtime_dt, ftype='spectrum')\n",
    "file_path_list_spectrum = [os.path.join(realtime_netcdf_input_dir, file_name) for file_name in file_list_spectrum]\n",
    "\n",
    "file_list_telegram = [file_name for file_name in file_list_onePIPS if 'telegram' in file_name]\n",
    "file_list_telegram = [file_name for file_name in file_list_telegram if 'current' not in file_name]\n",
    "file_list_telegram = get_files(file_list_telegram, starttime_dt, endtime_dt, ftype='telegram')\n",
    "file_path_list_telegram = [os.path.join(realtime_netcdf_input_dir, file_name) for file_name in file_list_telegram]\n",
    "\n",
    "# datetime_stamp = '20220505210000'\n",
    "# ND_file = 'ND_{}.nc'.format(datetime_stamp)\n",
    "# ND_path = os.path.join(netcdf_input_dir, ND_file)\n",
    "# ND_ds = xr.load_dataset(ND_path)\n",
    "\n",
    "# conv_file = 'onesec_{}.nc'.format(datetime_stamp)\n",
    "# conv_path = os.path.join(netcdf_input_dir, conv_file)\n",
    "# conv_ds = xr.load_dataset(conv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read in real-time netCDF files\n",
    "onesec_rt_ds = xr.open_mfdataset(file_path_list_onesec, combine='nested', concat_dim='logger_datetime',\n",
    "                                 decode_timedelta=False)\n",
    "onesec_rt_ds = onesec_rt_ds.rename({'logger_datetime': 'time'})\n",
    "onesec_rt_ds = onesec_rt_ds.drop_duplicates('time')\n",
    "ND_rt_ds = xr.open_mfdataset(file_path_list_ND, combine='nested', concat_dim='time',\n",
    "                             decode_timedelta=False)\n",
    "ND_rt_ds = ND_rt_ds.drop_duplicates('time')\n",
    "ND_rt_ds = ND_rt_ds.rename_dims({'diameter': 'diameter_bin'})\n",
    "spectrum_rt_ds = xr.open_mfdataset(file_path_list_spectrum, combine='nested', concat_dim='time',\n",
    "                                   decode_timedelta=False)\n",
    "spectrum_rt_ds = spectrum_rt_ds.drop_duplicates('time')\n",
    "spectrum_rt_ds = spectrum_rt_ds.rename_dims({'diameter': 'diameter_bin', 'velocity': 'fallspeed_bin'})\n",
    "spectrum_rt_ds = spectrum_rt_ds.rename({'velocity': 'fallspeed'})\n",
    "telegram_rt_ds = xr.open_mfdataset(file_path_list_telegram, combine='nested', concat_dim='index',\n",
    "                                   decode_timedelta=False)\n",
    "telegram_rt_ds = telegram_rt_ds.rename({'index': 'time'})\n",
    "telegram_rt_ds = telegram_rt_ds.drop_duplicates('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read netCDF files from card\n",
    "parsivel_combined_card_filename = f'parsivel_combined_{deployment_name}_{PIPS_name}_10s.nc'\n",
    "parsivel_combined_card_path = os.path.join(card_netcdf_input_dir, parsivel_combined_card_filename)\n",
    "\n",
    "onesec_card_filename = f'conventional_raw_{deployment_name}_{PIPS_name}.nc'\n",
    "onesec_card_path = os.path.join(card_netcdf_input_dir, onesec_card_filename)\n",
    "\n",
    "parsivel_combined_card_ds = xr.open_dataset(parsivel_combined_card_path, decode_timedelta=False)\n",
    "onesec_card_ds = xr.open_dataset(onesec_card_path, decode_timedelta=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct times from from the real-time files to match the GPS times. This is already done for the times\n",
    "# from the card-derived netCDF files\n",
    "\n",
    "# Get first good GPS time in file\n",
    "\n",
    "first_good_GPS_time = onesec_rt_ds.where(onesec_rt_ds['GPS_status'].compute() == 'A', drop=True).isel(time=0)\n",
    "\n",
    "logger_datetime = first_good_GPS_time['time'].values\n",
    "logger_datetime = pd.to_datetime(logger_datetime).to_pydatetime()\n",
    "\n",
    "GPS_date = str(first_good_GPS_time['GPS_date'].values)\n",
    "GPS_time = str(first_good_GPS_time['GPS_time'].values)\n",
    "\n",
    "# Next, construct datetime object from GPS info\n",
    "# Construct datetime object\n",
    "gyear = int('20' + GPS_date[4:])\n",
    "gmonth = int(GPS_date[2:4])\n",
    "gday = int(GPS_date[:2])\n",
    "ghour = int(GPS_time[:2])\n",
    "gmin = int(GPS_time[2:4])\n",
    "gsec = int(GPS_time[4:6])\n",
    "\n",
    "GPS_datetime = datetime(gyear, gmonth, gday, ghour, gmin, gsec)\n",
    "GPS_offset = GPS_datetime - logger_datetime\n",
    "print('GPS time: {}, Logger time: {}'.format(GPS_datetime.ctime(),\n",
    "                                             logger_datetime.ctime()))\n",
    "print('GPS Offset: {}'.format(str(GPS_offset)))\n",
    "\n",
    "# print(onesec_card_ds.where(onesec_card_ds['GPS_status'] == 'A', drop=True).isel(time=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_times = pd.to_datetime(onesec_rt_ds['time']).to_pydatetime()\n",
    "new_times = old_times + GPS_offset\n",
    "onesec_rt_ds = onesec_rt_ds.assign_coords({'time': new_times})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_ND_times = pd.to_datetime(ND_rt_ds['time']).to_pydatetime()\n",
    "new_times = old_ND_times + GPS_offset\n",
    "ND_rt_ds = ND_rt_ds.assign_coords({'time': new_times})\n",
    "\n",
    "old_spectrum_times = pd.to_datetime(spectrum_rt_ds['time']).to_pydatetime()\n",
    "new_times = old_spectrum_times + GPS_offset\n",
    "spectrum_rt_ds = spectrum_rt_ds.assign_coords({'time': new_times})\n",
    "\n",
    "old_telegram_times = pd.to_datetime(telegram_rt_ds['time']).to_pydatetime()\n",
    "new_times = old_telegram_times + GPS_offset\n",
    "telegram_rt_ds = telegram_rt_ds.assign_coords({'time': new_times})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, figure out what times are missing from the data for each source. Start with the one-sec data.\n",
    "# First find earliest start and latest end times\n",
    "onesec_card_starttime = onesec_card_ds['time'][0].values\n",
    "onesec_card_endtime = onesec_card_ds['time'][-1].values\n",
    "onesec_rt_starttime = onesec_rt_ds['time'][0].values\n",
    "onesec_rt_endtime = onesec_rt_ds['time'][-1].values\n",
    "\n",
    "starttime_onesec = min(onesec_card_starttime, onesec_rt_starttime)\n",
    "endtime_onesec = max(onesec_card_endtime, onesec_rt_endtime)\n",
    "\n",
    "print(starttime_onesec, endtime_onesec)\n",
    "\n",
    "# Then, create a new index of all times at 1-s intervals between the two\n",
    "all_onesec_times = xr.date_range(starttime_onesec, endtime_onesec, freq='1S')\n",
    "print(all_onesec_times)\n",
    "print(all_onesec_times[0], all_onesec_times[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(onesec_rt_ds.indexes['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_diffs_onesec_card = np.diff(onesec_ds['time'].values)\n",
    "# time_diffs_onesec_rt = np.diff(onesec_card_ds['time'].values)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "\n",
    "# ax.plot(time_diffs_onesec_card)\n",
    "# ax.plot(time_diffs_onesec_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [time for time in onesec_rt_ds.indexes['time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_times_rt = np.array([False if time in onesec_rt_ds.indexes['time'] \n",
    "                             else True for time in all_onesec_times])\n",
    "\n",
    "missing_times_card = np.array([False if time in onesec_card_ds.indexes['time'] \n",
    "                               else True for time in all_onesec_times])\n",
    "\n",
    "missing_times_both = missing_times_rt & missing_times_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(all_onesec_times, missing_times_rt, label='Real time data')\n",
    "ax.plot(all_onesec_times, missing_times_card, label='Card data')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(all_onesec_times, missing_times_both, label='Both datasets')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It turns out that the way the dewpoint is computed for the real-time data is wrong. It's using the fasttemp\n",
    "# when it should be using the slowtemp. Fix that here, and also rederive the RH and other thermo\n",
    "# parameters accordingly.\n",
    "\n",
    "# Note, this uses a different formula from the one in pyPIPS_merge.py that computes dewpoint for the card data\n",
    "# but it should be close enough. TODO: go back and make this consistent.\n",
    "dewpoint = (thermo.calTdfromRH(onesec_rt_ds['pressure'] * 100.,\n",
    "                               onesec_rt_ds['slowtemp'] + 273.15,\n",
    "                               onesec_rt_ds['RH'] / 100.) - 273.15)\n",
    "\n",
    "fasttemp = onesec_rt_ds['fasttemp']\n",
    "RH_derived = 100. * (np.exp((17.625 * dewpoint) / (243.04 + dewpoint)) /\n",
    "                     np.exp((17.625 * fasttemp) / (243.04 + fasttemp)))\n",
    "\n",
    "onesec_rt_ds['dewpoint'] = dewpoint\n",
    "onesec_rt_ds['RH_derived'] = RH_derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, reindex both one-sec datasets with the full set of times\n",
    "onesec_rt_full_ds = onesec_rt_ds.reindex({'time': all_onesec_times})\n",
    "onesec_card_full_ds = onesec_card_ds.reindex({'time': all_onesec_times})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now attempt to merge the data from the two sources to fill in the (non-mutual) gaps\n",
    "onesec_merged_ds = onesec_rt_ds.combine_first(onesec_card_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, reindex merged dataset with the full set of times\n",
    "onesec_merged_full_ds = onesec_merged_ds.reindex({'time': all_onesec_times})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute some thermodynamic parameters for the newly merged onesec data\n",
    "onesec_merged_full_ds = pips.calc_thermo(onesec_merged_full_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some plots of the one-sec data. Start with T/Td\n",
    "# Real-time data\n",
    "\n",
    "fig_t_td, ax_t_td = plt.subplots(figsize=(10, 6))\n",
    "plottimes_onesec = [all_onesec_times.to_pydatetime()]\n",
    "# Temperature and Dewpoint\n",
    "Tmin = np.nanmin(onesec_rt_full_ds['dewpoint'].values)\n",
    "Tmax = np.nanmax(onesec_rt_full_ds['slowtemp'].values)\n",
    "fields_to_plot_onesec = [onesec_rt_full_ds['slowtemp'].values, onesec_rt_full_ds['dewpoint'].values]\n",
    "temp_params = pm.temp_params.copy()\n",
    "dewpoint_params = pm.dewpoint_params.copy()\n",
    "temp_params['plotmin'] = Tmin - 5.0\n",
    "dewpoint_params['plotmin'] = Tmin - 5.0\n",
    "field_parameters_onesec = [temp_params, dewpoint_params]\n",
    "ax_t_td = pm.plotmeteogram(\n",
    "    ax_t_td,\n",
    "    plottimes_onesec,\n",
    "    fields_to_plot_onesec,\n",
    "    field_parameters_onesec)\n",
    "temp_dewp_ax_params['axeslimits'] = [[plottimes_onesec[0][0], plottimes_onesec[0][-1]],\n",
    "                                     [Tmin - 5.0, Tmax + 5.0]]\n",
    "ax_t_td, = pm.set_meteogram_axes([ax_t_td], [temp_dewp_ax_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some plots of the one-sec data. Start with T/Td\n",
    "# Card data\n",
    "\n",
    "fig_t_td, ax_t_td = plt.subplots(figsize=(10, 6))\n",
    "plottimes_onesec = [all_onesec_times.to_pydatetime()]\n",
    "# Temperature and Dewpoint\n",
    "Tmin = np.nanmin(onesec_card_full_ds['dewpoint'].values)\n",
    "Tmax = np.nanmax(onesec_card_full_ds['slowtemp'].values)\n",
    "fields_to_plot_onesec = [onesec_card_full_ds['slowtemp'].values, onesec_card_full_ds['dewpoint'].values]\n",
    "temp_params = pm.temp_params.copy()\n",
    "dewpoint_params = pm.dewpoint_params.copy()\n",
    "temp_params['plotmin'] = Tmin - 5.0\n",
    "dewpoint_params['plotmin'] = Tmin - 5.0\n",
    "field_parameters_onesec = [temp_params, dewpoint_params]\n",
    "ax_t_td = pm.plotmeteogram(\n",
    "    ax_t_td,\n",
    "    plottimes_onesec,\n",
    "    fields_to_plot_onesec,\n",
    "    field_parameters_onesec)\n",
    "\n",
    "# tmin = datetime(2023, 3, 3, 8, 40, 0)\n",
    "# tmax = datetime(2023, 3, 3, 8, 50, 0)\n",
    "tmin = plottimes_onesec[0][0]\n",
    "tmax = plottimes_onesec[0][-1]\n",
    "\n",
    "temp_dewp_ax_params['axeslimits'] = [[tmin, tmax],\n",
    "                                     [Tmin - 5.0, Tmax + 5.0]]\n",
    "ax_t_td, = pm.set_meteogram_axes([ax_t_td], [temp_dewp_ax_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Card data without the missing times (so data are interpolated between missing times)\n",
    "\n",
    "fig_t_td, ax_t_td = plt.subplots(figsize=(10, 6))\n",
    "plottimes_onesec = [onesec_card_ds['time'].to_index().to_pydatetime()]\n",
    "# Temperature and Dewpoint\n",
    "Tmin = np.nanmin(onesec_card_ds['dewpoint'].values)\n",
    "Tmax = np.nanmax(onesec_card_ds['slowtemp'].values)\n",
    "fields_to_plot_onesec = [onesec_card_ds['slowtemp'].values, onesec_card_ds['dewpoint'].values]\n",
    "temp_params = pm.temp_params.copy()\n",
    "dewpoint_params = pm.dewpoint_params.copy()\n",
    "temp_params['plotmin'] = Tmin - 5.0\n",
    "dewpoint_params['plotmin'] = Tmin - 5.0\n",
    "field_parameters_onesec = [temp_params, dewpoint_params]\n",
    "ax_t_td = pm.plotmeteogram(\n",
    "    ax_t_td,\n",
    "    plottimes_onesec,\n",
    "    fields_to_plot_onesec,\n",
    "    field_parameters_onesec)\n",
    "\n",
    "# tmin = datetime(2023, 3, 3, 8, 40, 0)\n",
    "# tmax = datetime(2023, 3, 3, 8, 50, 0)\n",
    "tmin = plottimes_onesec[0][0]\n",
    "tmax = plottimes_onesec[0][-1]\n",
    "\n",
    "temp_dewp_ax_params['axeslimits'] = [[tmin, tmax],\n",
    "                                     [Tmin - 5.0, Tmax + 5.0]]\n",
    "ax_t_td, = pm.set_meteogram_axes([ax_t_td], [temp_dewp_ax_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot T/Td for merged dataset\n",
    "\n",
    "fig_t_td, ax_t_td = plt.subplots(figsize=(10, 6))\n",
    "plottimes_onesec = [onesec_merged_ds['time'].to_index().to_pydatetime()]\n",
    "# Temperature and Dewpoint\n",
    "Tmin = np.nanmin(onesec_merged_ds['dewpoint'].values)\n",
    "Tmax = np.nanmax(onesec_merged_ds['slowtemp'].values)\n",
    "fields_to_plot_onesec = [onesec_merged_ds['slowtemp'].values, onesec_merged_ds['dewpoint'].values]\n",
    "temp_params = pm.temp_params.copy()\n",
    "dewpoint_params = pm.dewpoint_params.copy()\n",
    "temp_params['plotmin'] = Tmin - 5.0\n",
    "dewpoint_params['plotmin'] = Tmin - 5.0\n",
    "field_parameters_onesec = [temp_params, dewpoint_params]\n",
    "ax_t_td = pm.plotmeteogram(\n",
    "    ax_t_td,\n",
    "    plottimes_onesec,\n",
    "    fields_to_plot_onesec,\n",
    "    field_parameters_onesec)\n",
    "\n",
    "# tmin = datetime(2023, 3, 3, 8, 40, 0)\n",
    "# tmax = datetime(2023, 3, 3, 8, 50, 0)\n",
    "tmin = plottimes_onesec[0][0]\n",
    "tmax = plottimes_onesec[0][-1]\n",
    "\n",
    "temp_dewp_ax_params['axeslimits'] = [[tmin, tmax],\n",
    "                                     [Tmin - 5.0, Tmax + 5.0]]\n",
    "ax_t_td, = pm.set_meteogram_axes([ax_t_td], [temp_dewp_ax_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot T/Td for merged dataset (with full times)\n",
    "\n",
    "fig_t_td, ax_t_td = plt.subplots(figsize=(10, 6))\n",
    "plottimes_onesec = [onesec_merged_full_ds['time'].to_index().to_pydatetime()]\n",
    "# Temperature and Dewpoint\n",
    "Tmin = np.nanmin(onesec_merged_full_ds['dewpoint'].values)\n",
    "Tmax = np.nanmax(onesec_merged_full_ds['slowtemp'].values)\n",
    "fields_to_plot_onesec = [onesec_merged_full_ds['slowtemp'].values, onesec_merged_full_ds['dewpoint'].values]\n",
    "temp_params = pm.temp_params.copy()\n",
    "dewpoint_params = pm.dewpoint_params.copy()\n",
    "temp_params['plotmin'] = Tmin - 5.0\n",
    "dewpoint_params['plotmin'] = Tmin - 5.0\n",
    "field_parameters_onesec = [temp_params, dewpoint_params]\n",
    "ax_t_td = pm.plotmeteogram(\n",
    "    ax_t_td,\n",
    "    plottimes_onesec,\n",
    "    fields_to_plot_onesec,\n",
    "    field_parameters_onesec)\n",
    "\n",
    "# tmin = datetime(2023, 3, 3, 8, 40, 0)\n",
    "# tmax = datetime(2023, 3, 3, 8, 50, 0)\n",
    "tmin = plottimes_onesec[0][0]\n",
    "tmax = plottimes_onesec[0][-1]\n",
    "\n",
    "temp_dewp_ax_params['axeslimits'] = [[tmin, tmax],\n",
    "                                     [Tmin - 5.0, Tmax + 5.0]]\n",
    "ax_t_td, = pm.set_meteogram_axes([ax_t_td], [temp_dewp_ax_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, figure out what times are missing from the data for the ten-sec data.\n",
    "# First find earliest start and latest end times\n",
    "tensec_card_starttime = parsivel_combined_card_ds['time'][0].values\n",
    "tensec_card_endtime = parsivel_combined_card_ds['time'][-1].values\n",
    "spectrum_rt_starttime = spectrum_rt_ds['time'][0].values\n",
    "spectrum_rt_endtime = spectrum_rt_ds['time'][-1].values\n",
    "telegram_rt_starttime = telegram_rt_ds['time'][0].values\n",
    "telegram_rt_endtime = telegram_rt_ds['time'][-1].values\n",
    "ND_rt_starttime = ND_rt_ds['time'][0].values\n",
    "ND_rt_endtime = ND_rt_ds['time'][-1].values\n",
    "\n",
    "starttime_tensec = min(tensec_card_starttime, spectrum_rt_starttime, telegram_rt_starttime, ND_rt_starttime)\n",
    "endtime_tensec = max(tensec_card_endtime, spectrum_rt_endtime, telegram_rt_endtime, ND_rt_endtime)\n",
    "\n",
    "print(starttime_tensec, endtime_tensec)\n",
    "\n",
    "# Then, create a new index of all times at 10-s intervals between the two\n",
    "\n",
    "all_tensec_times = xr.date_range(starttime_tensec, endtime_tensec, freq='10S')\n",
    "print(all_tensec_times)\n",
    "print(all_tensec_times[0], all_tensec_times[-1])\n",
    "\n",
    "print(ND_rt_ds['time'])\n",
    "print(spectrum_rt_ds['time'])\n",
    "print(parsivel_combined_card_ds['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_times_spectrum_rt = np.array([False if time in spectrum_rt_ds.indexes['time'] \n",
    "                                      else True for time in all_tensec_times])\n",
    "\n",
    "missing_times_telegram_rt = np.array([False if time in telegram_rt_ds.indexes['time'] \n",
    "                                      else True for time in all_tensec_times])\n",
    "\n",
    "missing_times_ND_rt = np.array([False if time in ND_rt_ds.indexes['time'] \n",
    "                                else True for time in all_tensec_times])\n",
    "\n",
    "missing_times_tensec_card = np.array([False if time in parsivel_combined_card_ds.indexes['time'] \n",
    "                                      else True for time in all_tensec_times])\n",
    "\n",
    "missing_times_tensec_both = missing_times_spectrum_rt & missing_times_tensec_card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all(missing_times_spectrum_rt == missing_times_ND_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(all_tensec_times, missing_times_spectrum_rt, label='Real time data')\n",
    "ax.plot(all_tensec_times, missing_times_tensec_card, label='Card data')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(all_tensec_times, missing_times_tensec_both, label='Both datasets')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reindex all datasets with the full set of times\n",
    "\n",
    "ND_rt_ds_full = ND_rt_ds.reindex({'time': all_tensec_times})\n",
    "spectrum_rt_ds_full = spectrum_rt_ds.reindex({'time': all_tensec_times})\n",
    "telegram_rt_ds_full = telegram_rt_ds.reindex({'time': all_tensec_times})\n",
    "parsivel_combined_card_ds_full = parsivel_combined_card_ds.reindex({'time': all_tensec_times})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to merge the data to fill in gaps\n",
    "\n",
    "# Number concentration\n",
    "ND_rt_da = ND_rt_ds['ND']\n",
    "ND_card_da = parsivel_combined_card_ds['ND']\n",
    "\n",
    "# telegram stuff\n",
    "precipintensity_rt_da = telegram_rt_ds['rain rate (mm per hr)']\n",
    "precipaccum_rt_da = telegram_rt_ds['rain accumulation (mm)']\n",
    "parsivel_dBZ_rt_da = telegram_rt_ds['radar reflectivity (dBZ)']\n",
    "sample_interval_rt_da = telegram_rt_ds['sample interval']\n",
    "signal_amplitude_rt_da = telegram_rt_ds['signal amplitude']\n",
    "pcount_rt_da = telegram_rt_ds['particle count']\n",
    "sensor_temp_rt_da = telegram_rt_ds['sensor temp']\n",
    "pvoltage_rt_da = telegram_rt_ds['power supply voltage']\n",
    "\n",
    "precipintensity_card_da = parsivel_combined_card_ds['precipintensity']\n",
    "precipaccum_card_da = parsivel_combined_card_ds['precipaccum']\n",
    "parsivel_dBZ_card_da = parsivel_combined_card_ds['parsivel_dBZ']\n",
    "sample_interval_card_da = parsivel_combined_card_ds['sample_interval']\n",
    "signal_amplitude_card_da = parsivel_combined_card_ds['signal_amplitude']\n",
    "pcount_card_da = parsivel_combined_card_ds['pcount']\n",
    "sensor_temp_card_da = parsivel_combined_card_ds['sensor_temp']\n",
    "pvoltage_card_da = parsivel_combined_card_ds['pvoltage']\n",
    "\n",
    "# spectrum\n",
    "spectrum_rt_da = spectrum_rt_ds['spectrum']\n",
    "spectrum_card_da = parsivel_combined_card_ds['VD_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ND_da_merged = ND_rt_da.combine_first(ND_card_da)\n",
    "precipintensity_merged_da = precipintensity_rt_da.combine_first(precipintensity_card_da)\n",
    "precipaccum_merged_da = precipaccum_rt_da.combine_first(precipaccum_card_da)\n",
    "parsivel_dBZ_merged_da = parsivel_dBZ_rt_da.combine_first(parsivel_dBZ_card_da)\n",
    "sample_interval_merged_da = sample_interval_rt_da.combine_first(sample_interval_card_da)\n",
    "signal_amplitude_merged_da = signal_amplitude_rt_da.combine_first(signal_amplitude_card_da)\n",
    "pcount_merged_da = pcount_rt_da.combine_first(pcount_card_da)\n",
    "sensor_temp_merged_da = sensor_temp_rt_da.combine_first(sensor_temp_card_da)\n",
    "pvoltage_merged_da = pvoltage_rt_da.combine_first(pvoltage_card_da)\n",
    "spectrum_merged_da = spectrum_rt_da.combine_first(spectrum_card_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ND_da_merged_full = ND_da_merged.reindex({'time': all_tensec_times})\n",
    "precipintensity_merged_da_full = precipintensity_merged_da.reindex({'time': all_tensec_times})\n",
    "precipaccum_merged_da_full = precipaccum_merged_da.reindex({'time': all_tensec_times})\n",
    "parsivel_dBZ_merged_da_full = parsivel_dBZ_merged_da.reindex({'time': all_tensec_times})\n",
    "sample_interval_merged_da_full = sample_interval_merged_da.reindex({'time': all_tensec_times})\n",
    "signal_amplitude_merged_da_full = signal_amplitude_merged_da.reindex({'time': all_tensec_times})\n",
    "pcount_merged_da_full = pcount_merged_da.reindex({'time': all_tensec_times})\n",
    "sensor_temp_merged_da_full = sensor_temp_merged_da.reindex({'time': all_tensec_times})\n",
    "pvoltage_merged_da_full = pvoltage_merged_da.reindex({'time': all_tensec_times})\n",
    "spectrum_merged_da_full = spectrum_merged_da.reindex({'time': all_tensec_times})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have all the data merged that we can, we need to start putting it back together in preparation\n",
    "# for dumping back to disk\n",
    "\n",
    "parsivel_combined_merged_full_ds = parsivel_combined_card_ds_full.copy()\n",
    "parsivel_combined_merged_full_ds['ND'] = ND_da_merged_full\n",
    "parsivel_combined_merged_full_ds['precipintensity'] = precipintensity_merged_da_full\n",
    "parsivel_combined_merged_full_ds['precipaccum'] = precipaccum_merged_da_full\n",
    "parsivel_combined_merged_full_ds['parsivel_dBZ'] = parsivel_dBZ_merged_da_full\n",
    "parsivel_combined_merged_full_ds['sample_interval'] = sample_interval_merged_da_full\n",
    "parsivel_combined_merged_full_ds['signal_amplitude'] = signal_amplitude_merged_da_full\n",
    "parsivel_combined_merged_full_ds['pcount'] = pcount_merged_da_full\n",
    "parsivel_combined_merged_full_ds['sensor_temp'] = sensor_temp_merged_da_full\n",
    "parsivel_combined_merged_full_ds['pvoltage'] = pvoltage_merged_da_full\n",
    "parsivel_combined_merged_full_ds['VD_matrix'] = spectrum_merged_da_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now resample the PIPS onesec data to 10-sec intervals and replace the existing 10-sec resampled data\n",
    "# in the parsivel combined dataset\n",
    "\n",
    "# Resample conventional data to the parsivel times\n",
    "PSD_datetimes = pips.get_PSD_datetimes(parsivel_combined_merged_full_ds['VD_matrix'])\n",
    "sec_offset = PSD_datetimes[0].second\n",
    "offset_str = pips.get_interval_str(sec_offset)\n",
    "resample_interval = 10\n",
    "conv_resampled_ds = pips.resample_conv_da('PIPS', resample_interval, sec_offset, onesec_merged_full_ds, \n",
    "                                          gusts=True, gustintvstr='3S')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_resampled_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all original resampled conventional data variables in the original parsivel combined dataset with\n",
    "# the new ones\n",
    "\n",
    "for varname in conv_resampled_ds:\n",
    "    parsivel_combined_merged_full_ds[varname] = conv_resampled_ds[varname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick DSD meteogram for merged data\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plottimes_tmp = ND_da_merged_full.coords['time'].to_index().to_pydatetime()\n",
    "# Prepend an additional at the beginning of the array so that pcolor sees this as the\n",
    "# edges of the DSD intervals.\n",
    "plottimes = np.insert(plottimes_tmp, 0, plottimes_tmp[0] - timedelta(seconds=10))\n",
    "plottimes = [plottimes]\n",
    "\n",
    "ND_arr = ND_da_merged_full.values.T\n",
    "logND_arr = np.ma.log10(ND_arr)\n",
    "fields_to_plot = [logND_arr]\n",
    "field_parameters = [log_ND_params]\n",
    "ax = pm.plotmeteogram(ax, plottimes, fields_to_plot, field_parameters,\n",
    "                      yvals=[diameter_edges] * len(fields_to_plot))\n",
    "ax, = pm.set_meteogram_axes([ax], [log_ND_ax_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Quick DSD meteogram for real-time data\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plottimes_tmp = ND_rt_ds_full['time'].to_index().to_pydatetime()\n",
    "# Prepend an additional at the beginning of the array so that pcolor sees this as the\n",
    "# edges of the DSD intervals.\n",
    "plottimes = np.insert(plottimes_tmp, 0, plottimes_tmp[0] - timedelta(seconds=10))\n",
    "plottimes = [plottimes]\n",
    "\n",
    "ND_rt_da = ND_rt_ds_full['ND']\n",
    "\n",
    "ND_rt_arr = ND_rt_da.values.T\n",
    "logND_rt_arr = np.ma.log10(ND_rt_arr)\n",
    "fields_to_plot = [logND_rt_arr]\n",
    "field_parameters = [log_ND_params]\n",
    "ax = pm.plotmeteogram(ax, plottimes, fields_to_plot, field_parameters,\n",
    "                      yvals=[diameter_edges] * len(fields_to_plot))\n",
    "ax, = pm.set_meteogram_axes([ax], [log_ND_ax_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick DSD meteogram for card data\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "plottimes_tmp = parsivel_combined_card_ds_full['time'].to_index().to_pydatetime()\n",
    "# Prepend an additional at the beginning of the array so that pcolor sees this as the\n",
    "# edges of the DSD intervals.\n",
    "plottimes = np.insert(plottimes_tmp, 0, plottimes_tmp[0] - timedelta(seconds=10))\n",
    "plottimes = [plottimes]\n",
    "\n",
    "ND_card_da = parsivel_combined_card_ds_full['ND']\n",
    "\n",
    "ND_card_arr = ND_card_da.values.T\n",
    "logND_card_arr = np.ma.log10(ND_card_arr)\n",
    "fields_to_plot = [logND_card_arr]\n",
    "field_parameters = [log_ND_params]\n",
    "ax = pm.plotmeteogram(ax, plottimes, fields_to_plot, field_parameters,\n",
    "                      yvals=[diameter_edges] * len(fields_to_plot))\n",
    "ax, = pm.set_meteogram_axes([ax], [log_ND_ax_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test plot of resampled data to make sure it looks ok\n",
    "# Plot T/Td for merged dataset (with full times)\n",
    "\n",
    "fig_t_td, ax_t_td = plt.subplots(figsize=(10, 6))\n",
    "plottimes_tensec = [parsivel_combined_merged_full_ds['time'].to_index().to_pydatetime()]\n",
    "# Temperature and Dewpoint\n",
    "Tmin = np.nanmin(parsivel_combined_merged_full_ds['dewpoint'].values)\n",
    "Tmax = np.nanmax(parsivel_combined_merged_full_ds['slowtemp'].values)\n",
    "fields_to_plot_tensec = [parsivel_combined_merged_full_ds['slowtemp'].values, \n",
    "                         parsivel_combined_merged_full_ds['dewpoint'].values]\n",
    "temp_params = pm.temp_params.copy()\n",
    "dewpoint_params = pm.dewpoint_params.copy()\n",
    "temp_params['plotmin'] = Tmin - 5.0\n",
    "dewpoint_params['plotmin'] = Tmin - 5.0\n",
    "field_parameters_tensec = [temp_params, dewpoint_params]\n",
    "ax_t_td = pm.plotmeteogram(\n",
    "    ax_t_td,\n",
    "    plottimes_tensec,\n",
    "    fields_to_plot_tensec,\n",
    "    field_parameters_tensec)\n",
    "\n",
    "# tmin = datetime(2023, 3, 3, 8, 40, 0)\n",
    "# tmax = datetime(2023, 3, 3, 8, 50, 0)\n",
    "tmin = plottimes_tensec[0][0]\n",
    "tmax = plottimes_tensec[0][-1]\n",
    "\n",
    "temp_dewp_ax_params['axeslimits'] = [[tmin, tmax],\n",
    "                                     [Tmin - 5.0, Tmax + 5.0]]\n",
    "ax_t_td, = pm.set_meteogram_axes([ax_t_td], [temp_dewp_ax_params])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onesec_card_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onesec_merged_full_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsivel_combined_merged_full_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsivel_combined_card_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Almost done. Need to copy all attributes from the original datasets to the new ones. Sometimes they get\n",
    "# lost for some reason.\n",
    "\n",
    "# Global attributes\n",
    "onesec_merged_full_ds.attrs = onesec_card_ds.attrs\n",
    "parsivel_combined_merged_full_ds.attrs = parsivel_combined_card_ds.attrs\n",
    "\n",
    "# Variable attributes\n",
    "for varname in onesec_merged_full_ds:\n",
    "    onesec_merged_full_ds[varname].attrs = onesec_card_ds[varname].attrs\n",
    "\n",
    "for varname in parsivel_combined_merged_full_ds:\n",
    "    parsivel_combined_merged_full_ds[varname].attrs = parsivel_combined_card_ds[varname].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onesec_merged_full_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we are ready to dump everything back to disk\n",
    "\n",
    "parsivel_combined_output_filename = f'parsivel_combined_{deployment_name}_{PIPS_name}_10s.nc'\n",
    "parsivel_combined_output_path = os.path.join(card_netcdf_output_dir, parsivel_combined_output_filename)\n",
    "\n",
    "onesec_output_filename = f'conventional_raw_{deployment_name}_{PIPS_name}.nc'\n",
    "onesec_output_path = os.path.join(card_netcdf_output_dir, onesec_output_filename)\n",
    "\n",
    "print(\"Saving {}\".format(onesec_output_path))\n",
    "onesec_merged_full_ds.to_netcdf(onesec_output_path)\n",
    "print(\"Saving {}\".format(parsivel_combined_output_path))\n",
    "parsivel_combined_merged_full_ds.to_netcdf(parsivel_combined_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pyPIPS]",
   "language": "python",
   "name": "conda-env-pyPIPS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

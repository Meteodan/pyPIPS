{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T19:59:19.800280Z",
     "start_time": "2019-07-21T19:59:17.666463Z"
    }
   },
   "outputs": [],
   "source": [
    "#This notebook is for testing the download of PIPS data using the web API.\n",
    "#It uses urllib3 and BeautifulSoup4\n",
    "%matplotlib notebook\n",
    "import os\n",
    "import bs4\n",
    "import urllib3\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from pyPIPS.disdrometer_module import avg_diameter, fall_bins, eff_sensor_area, max_diameter, min_diameter, min_fall_bins\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pyPIPS import thermolib as thermo\n",
    "from pyPIPS import timemodule as tm\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid, make_axes_locatable, host_subplot\n",
    "import pyPIPS.plotmodule as pm\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T19:59:20.172584Z",
     "start_time": "2019-07-21T19:59:20.070157Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function definitions. These will eventually go into their own module\n",
    "def scrape_tripips_onesec_data(url, numrecords=3600):\n",
    "    \"\"\"Grabs one-second records from the TriPIPS http server. Uses urlib3 and beautifulsoup4\"\"\"\n",
    "    http = urllib3.PoolManager()\n",
    "    content = http.request('GET', url + '&records={:d}'.format(numrecords))\n",
    "    soup = bs4.BeautifulSoup(content.data, \"lxml\")\n",
    "    table = soup.find('table')\n",
    "    rows = table.find_all('tr')\n",
    "    headers = rows.pop(0).find_all('th')\n",
    "    headers.pop(0)\n",
    "    headers = [header.string for header in headers]\n",
    "    data = []\n",
    "    timestamps = []\n",
    "    for row in rows:\n",
    "        tokens = row.find_all('td')\n",
    "        tokens = [token.string.strip(' \"') for token in tokens]\n",
    "        timestamp = tokens.pop(0)\n",
    "        tokens = [np.float(token) if token not in ('' or 'NAN') else np.nan for token in tokens]\n",
    "        data.append(tokens)\n",
    "        timestamps.append(timestamp)\n",
    "    index = pd.to_datetime(timestamps, format='%Y-%m-%d %H:%M:%S')\n",
    "    df = pd.DataFrame(data, columns=headers, index=index)\n",
    "    return df\n",
    "\n",
    "def scrape_tripips_tensec_data(url, numrecords=360):\n",
    "    \"\"\"Grabs ten-second records from the TriPIPS http server. Uses urlib3 and beautifulsoup4\"\"\"\n",
    "    http = urllib3.PoolManager()\n",
    "    content = http.request('GET', url + '&records={:d}'.format(numrecords))\n",
    "    soup = bs4.BeautifulSoup(content.data, \"lxml\")\n",
    "    table = soup.find('table')\n",
    "    rows = table.find_all('tr')\n",
    "    headers = rows.pop(0).find_all('th')\n",
    "    headers.pop(0)\n",
    "    headers = [header.string for header in headers]\n",
    "    telegrams = []\n",
    "    spectrum_list = []\n",
    "    timestamps = []\n",
    "    for row in rows:\n",
    "        tokens = row.find_all('td')\n",
    "        tokens = [token.string.strip(' \"') for token in tokens]\n",
    "        timestamp = tokens.pop(0)\n",
    "        tokens.pop(0)\n",
    "        parsivel_string = tokens.pop(0)\n",
    "        telegram_dict = read_parsivel_telegram(parsivel_string)\n",
    "        telegrams.append(telegram_dict)\n",
    "        spectrum = read_parsivel_spectrum(parsivel_string)\n",
    "        spectrum_list.append(spectrum)\n",
    "        timestamps.append(timestamp)\n",
    "        \n",
    "    index = pd.to_datetime(timestamps, format='%Y-%m-%d %H:%M:%S')\n",
    "    df_telegram = pd.DataFrame(telegrams, index=index)\n",
    "    # print(np.array(spectrum_list).shape)\n",
    "    da_spectrum = xr.DataArray(spectrum_list, coords=[index, fall_bins,\n",
    "                                                     avg_diameter],\n",
    "                              dims=['time', 'velocity', 'diameter'])\n",
    "    return df_telegram, da_spectrum\n",
    "    \n",
    "def read_parsivel_telegram(parsivel_string):\n",
    "    \"\"\"\n",
    "    Reads the parsivel telegram and returns a dictionary for each component,\n",
    "    except for the spectrum, which is handled separately by read_spectrum.\n",
    "    \"\"\"\n",
    "    # print(parsivel_string)\n",
    "    parsivel_tokens = parsivel_string.strip(' \"').split(';')\n",
    "    # print(parsivel_tokens)\n",
    "    parsivel_tokens = parsivel_tokens[:11]\n",
    "    \n",
    "    \n",
    "    parsivel_telegram_dict = {\n",
    "        'parsivel_id': int(parsivel_tokens[0]),\n",
    "        'rain rate (mm/hr)': float(parsivel_tokens[1]),\n",
    "        'rain accumulation (mm)': float(parsivel_tokens[2]),\n",
    "        'radar reflectivity (dBZ)': float(parsivel_tokens[3]),\n",
    "        'sample interval': int(parsivel_tokens[4]),\n",
    "        'signal amplitude': int(parsivel_tokens[5]),\n",
    "        'particle count': int(parsivel_tokens[6]),\n",
    "        'sensor temp': int(parsivel_tokens[7]),\n",
    "        'power supply voltage': float(parsivel_tokens[8]),\n",
    "        'sensor time': parsivel_tokens[9],\n",
    "        'sensor date': parsivel_tokens[10]\n",
    "    }\n",
    "    \n",
    "    return parsivel_telegram_dict\n",
    "\n",
    "def read_parsivel_spectrum(parsivel_string):\n",
    "    \"\"\"Given a raw string of Parsivel data, extract the DSD spectrum from it.\"\"\"\n",
    "    parsivel_tokens = parsivel_string.strip(' \"').split(';')\n",
    "    #parsivel_tokens = parsivel_tokens.strip('\"')\n",
    "    spectrum = [float(x) if ('' or '\\n' or '\\r') not in x else 0 for x in parsivel_tokens[11:]]\n",
    "    try:\n",
    "        spectrum = [float(x) if ('' or '\\n' or '\\r') not in x else 0 for x in parsivel_tokens[11:]]\n",
    "    except ValueError:\n",
    "        spectrum = [-999 for i in range(1025)]\n",
    "    # Strip off bogus final value (why is it there?)\n",
    "    if len(spectrum) == 1025:\n",
    "        spectrum = spectrum [:-1]\n",
    "    # Reshape the spectrum to a 32x32 matrix of integers\n",
    "    spectrum = np.array(spectrum, dtype='int')\n",
    "    # Assert that the size of the array is what we expect\n",
    "    # Otherwise generate a spectrum of missing values (-999)\n",
    "    if(spectrum.size == 1024):\n",
    "        spectrum = spectrum.reshape((32, 32))\n",
    "    else:\n",
    "        spectrum = -999 * np.ones((32, 32), dtype='int')\n",
    "    return spectrum\n",
    "\n",
    "def timestamp2datetime(timestamp):\n",
    "    \"\"\"Construct a datetime object from a timestamp of the form YYYY-MM-DD HH:MM:SS.XXX\"\"\"\n",
    "    date, time = timestamp.strip().split()\n",
    "    year = np.int(date[:4])\n",
    "    month = np.int(date[5:7])\n",
    "    day = np.int(date[8:])\n",
    "    hour = np.int(time[:2])\n",
    "    min = np.int(time[3:5])\n",
    "    sec = np.int(time[6:8])\n",
    "    \n",
    "    return datetime(year, month, day, hour, min, sec)\n",
    "\n",
    "def calc_ND_da(spectrum_da, interval=10, use_measured_fs=True):\n",
    "    \"\"\"Computes the number concentration from the 32x32 spectrum\"\"\"\n",
    "    index = spectrum_da.coords['time'].values\n",
    "    if not use_measured_fs:\n",
    "        raise NotImplementedError('Not yet implemented: use measured fall speed for now!')\n",
    "    else:\n",
    "        ND_da = spectrum_da.groupby('time').apply(calc_ND)\n",
    "    \n",
    "    #ND_df = pd.DataFrame(ND_arr, columns=avg_diameter, index=index)\n",
    "    return ND_da \n",
    "\n",
    "def calc_ND_list(spectrum_list, interval=10, use_measured_fs=True):\n",
    "    ND_list = [calc_ND(spectrum, interval=DSD_interval) for spectrum in spectrum_list]\n",
    "    ND_arr = np.array(ND_list)\n",
    "    return ND_arr\n",
    "\n",
    "def calc_ND(spectrum, interval=10, use_measured_fs=True):\n",
    "    _, vspectrum = np.meshgrid(avg_diameter, fall_bins)\n",
    "    dspectrum = spectrum\n",
    "    if np.all(dspectrum == -999):\n",
    "        # print('Here!')\n",
    "        ND = -999. * np.ones_like(avg_diameter)\n",
    "        ND = np.ma.masked_where(ND == -999., ND)\n",
    "    else:\n",
    "        ND = dspectrum / (vspectrum * interval * eff_sensor_area * (max_diameter - min_diameter))\n",
    "        if use_measured_fs:\n",
    "            # ND = ND.sum(axis=0)\n",
    "            ND = ND.sum(dim='velocity')\n",
    "    return ND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T19:59:20.504031Z",
     "start_time": "2019-07-21T19:59:20.443348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up directories for output/plotting and URLs for grabbing the data\n",
    "# base_output_dir = '/Users/dawson29/sshfs_mounts/depot/data/Projects/TriPIPS/webdata/'\n",
    "base_output_dir = '/Users/dawson29/sshfs_mounts/stormlab_web/'\n",
    "image_output_dir = os.path.join(base_output_dir, 'images')\n",
    "base_url = \"http://10.163.29.26/?command=TableDisplay&table=\"\n",
    "onesec_table = \"One_Hz\"\n",
    "tensec_table = \"Ten_Hz\"\n",
    "url_onesec = base_url + onesec_table\n",
    "url_tensec = base_url + tensec_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T19:59:23.609057Z",
     "start_time": "2019-07-21T19:59:23.542975Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up dictionaries to control plotting parameters\n",
    "\n",
    "dateformat = '%H:%M'\n",
    "\n",
    "# Temperature and dewpoint\n",
    "temp_dewp_ax_params = {\n",
    "    'majorxlocator': dates.MinuteLocator(byminute=[0, 15, 30, 45], interval=1), \n",
    "    'majorxformatter': dates.DateFormatter(dateformat),\n",
    "    'minorxlocator': dates.MinuteLocator(byminute=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55], interval=1),\n",
    "    'axeslimits': [None, (-5., 35.)],\n",
    "    'axeslabels': ['Time (H:M) UTC', r'Temperature ($^{\\circ}$C)']\n",
    "}\n",
    "\n",
    "# Wind speed and direction\n",
    "windspd_ax_params = {\n",
    "    'majorxlocator': dates.MinuteLocator(byminute=[0, 15, 30, 45], interval=1), \n",
    "    'majorxformatter': dates.DateFormatter(dateformat),\n",
    "    'minorxlocator': dates.MinuteLocator(byminute=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55], interval=1),\n",
    "    'axeslimits': [None, [0.0, 25.0]],\n",
    "    'axeslabels': ['Time (H:M) UTC', r'wind speed (m s$^{-1}$)']\n",
    "}\n",
    "\n",
    "winddir_ax_params = {\n",
    "    'majorylocator': ticker.MultipleLocator(45.),\n",
    "    'axeslimits': [None, [0.0, 360.0]],\n",
    "    'axeslabels': [None, r'Wind direction ($^{\\circ}$C)']\n",
    "}\n",
    "\n",
    "pressure_ax_params = {\n",
    "    'majorylocator': ticker.MultipleLocator(5.),\n",
    "    'axeslimits': [None, [940., 980.]],\n",
    "    'axeslabels': [None, r'Pressure (hPa)']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Number concentration\n",
    "log_ND_params = {\n",
    "    'type': 'pcolor', \n",
    "    'vlimits': [-1.0, 3.0],\n",
    "    'clabel': r'log[N ($m^{-3} mm^{-1}$)]'\n",
    "}\n",
    "\n",
    "log_ND_ax_params = {\n",
    "    'majorxlocator': dates.MinuteLocator(byminute=[0, 15, 30, 45], interval=1), \n",
    "    'majorxformatter': dates.DateFormatter(dateformat),\n",
    "    'minorxlocator': dates.MinuteLocator(byminute=[0, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55], interval=1),\n",
    "    'axeslimits': [None, [0.0, 9.0]],\n",
    "    'majorylocator': ticker.MultipleLocator(base=1.0),\n",
    "    'axeslabels': [None, 'D (mm)']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-21T19:59:36.113493Z",
     "start_time": "2019-07-21T19:59:25.435247Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Testing real-time plotting loop\n",
    "from IPython import display\n",
    "\n",
    "interval_onesec = 1.\n",
    "interval_tensec = 10.\n",
    "\n",
    "plot_update_interval = 60 # seconds\n",
    "plot_update_interval_ts = pd.Timedelta(seconds=plot_update_interval)\n",
    "keep_data_for = 3600 # seconds\n",
    "keep_data_for_ts = pd.Timedelta(seconds=keep_data_for)\n",
    "numrecords_onesec = int(keep_data_for / interval_onesec)\n",
    "numrecords_tensec = int(keep_data_for / interval_tensec)\n",
    "\n",
    "# Grab and process the initial period of data\n",
    "onesec_df = scrape_tripips_onesec_data(url_onesec, numrecords=numrecords_onesec)\n",
    "print(onesec_df.keys())\n",
    "onesec_df['Dewpoint'] = thermo.calTdfromRH(onesec_df['Pressure'] * 100., onesec_df['SlowTemp'] + 273.15, \n",
    "                                     onesec_df['RH'] / 100.) - 273.15\n",
    "telegram_df, spectrum_da = scrape_tripips_tensec_data(url_tensec, numrecords=numrecords_tensec)\n",
    "ND_da = calc_ND_da(spectrum_da)\n",
    "\n",
    "# TODO: figure out an efficient way to dump data containing regular intervals (i.e. hourl) to netCDF files.\n",
    "# May eventually be able to replace current dumping of proprietary files to the flash drive on the CR6.\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# onesec_df.plot(ax=ax, y=['SlowTemp', 'Dewpoint'], ylim=(-5.,5.), color=['r', 'g'])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig_vd, ax_vd = plt.subplots()\n",
    "fig_t_td, ax_t_td = plt.subplots()\n",
    "fig_wind, ax_windspd = plt.subplots()\n",
    "ax_winddir = ax_windspd.twinx()\n",
    "fig_pressure, ax_pressure = plt.subplots()\n",
    "#plt.ion()\n",
    "#fig.show()\n",
    "#fig.canvas.draw()\n",
    "display.display(fig)\n",
    "display.display(fig_vd)\n",
    "display.display(fig_t_td)\n",
    "display.display(fig_wind)\n",
    "display.display(fig_pressure)\n",
    "display.clear_output(wait=True)\n",
    "numrecords_append_tensec=10\n",
    "numrecords_append_onesec=120\n",
    "numiter=1\n",
    "# onesec_new_df = scrape_tripips_onesec_data(url_onesec, numrecords=numrecords)\n",
    "# onesec_new_df['Dewpoint'] = thermo.calTdfromRH(onesec_new_df['Pressure'] * 100., onesec_new_df['SlowTemp'] + 273.15, \n",
    "#                                                onesec_new_df['RH'] / 100.) - 273.15\n",
    "# # Append new data onto onesec_df\n",
    "# onesec_df = onesec_df.append(onesec_new_df)\n",
    "# # Drop duplicate timestamps\n",
    "# onesec_df = onesec_df[~onesec_df.index.duplicated(keep='first')]\n",
    "# # Drop records older than specified time\n",
    "# last_timestamp = onesec_df.index[-1]\n",
    "# oldest_timestamp = last_timestamp-keep_data_for\n",
    "# onesec_df = onesec_df[oldest_timestamp:]\n",
    "# onesec_df.plot(ax=ax, y=['SlowTemp', 'Dewpoint'], ylim=(-5.,5.), colors=['r', 'g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-22T14:01:33.581228Z",
     "start_time": "2019-07-21T20:00:32.197740Z"
    }
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "#for i in range(numiter):\n",
    "while True:\n",
    "    ax.clear()\n",
    "    ax_vd.clear()\n",
    "    ax_t_td.clear()\n",
    "    ax_windspd.clear()\n",
    "    ax_winddir.clear()\n",
    "    ax_pressure.clear()\n",
    "    onesec_new_df = scrape_tripips_onesec_data(url_onesec, numrecords=numrecords_append_onesec)\n",
    "    onesec_new_df['Dewpoint'] = thermo.calTdfromRH(onesec_new_df['Pressure'] * 100., onesec_new_df['SlowTemp'] + 273.15, \n",
    "                                     onesec_new_df['RH'] / 100.) - 273.15\n",
    "    # Append new data onto onesec_df\n",
    "    onesec_df = onesec_df.append(onesec_new_df)\n",
    "    # Drop duplicate timestamps\n",
    "    onesec_df = onesec_df[~onesec_df.index.duplicated(keep='first')]\n",
    "    # Drop records older than desired interval\n",
    "    last_timestamp_onesec = onesec_df.index[-1]\n",
    "    oldest_timestamp_onesec = last_timestamp_onesec-keep_data_for_ts\n",
    "    onesec_df = onesec_df.loc[oldest_timestamp_onesec:]\n",
    "    plottimes_onesec = [onesec_df.index.to_pydatetime()]\n",
    "    # Temperature and Dewpoint\n",
    "    fields_to_plot_onesec = [onesec_df['SlowTemp'].values, onesec_df['Dewpoint'].values]\n",
    "    field_parameters_onesec = [pm.temp_params, pm.dewpoint_params]\n",
    "    ax_t_td = pm.plotmeteogram(ax_t_td, plottimes_onesec, fields_to_plot_onesec, field_parameters_onesec)\n",
    "    temp_dewp_ax_params['axeslimits'][0] = (plottimes_onesec[0][0], plottimes_onesec[0][-1]) \n",
    "    ax_t_td, = pm.set_meteogram_axes([ax_t_td], [temp_dewp_ax_params])\n",
    "    # Wind speed and direction\n",
    "    ax_windspd = pm.plotmeteogram(ax_windspd, plottimes_onesec, [onesec_df['WS_ms'].values], [pm.windspeed_params])\n",
    "    ax_winddir = pm.plotmeteogram(ax_winddir, plottimes_onesec, [onesec_df['WindDir'].values], [pm.winddir_params])\n",
    "    windspd_ax_params['axeslimits'][0] = (plottimes_onesec[0][0], plottimes_onesec[0][-1])\n",
    "    winddir_ax_params['axeslimits'][0] = (plottimes_onesec[0][0], plottimes_onesec[0][-1])\n",
    "    ax_windspd, ax_winddir = pm.set_meteogram_axes([ax_windspd, ax_winddir], [windspd_ax_params, winddir_ax_params])\n",
    "    # Pressure\n",
    "    pmin = np.nanmin(onesec_df['Pressure'].values)\n",
    "    pmax = np.nanmax(onesec_df['Pressure'].values)\n",
    "    pressure_ax_params['axeslimits'] = [None, [pmin - 2.5, pmax + 2.5]]\n",
    "    fields_to_plot_press = [onesec_df['Pressure'].values]\n",
    "    field_parameters_press = [pm.pressure_params]\n",
    "    ax_pressure = pm.plotmeteogram(ax_pressure, plottimes_onesec, fields_to_plot_press, field_parameters_press)\n",
    "    ax_pressure, = pm.set_meteogram_axes([ax_pressure], [pressure_ax_params])\n",
    "    \n",
    "\n",
    "    # DSD plots\n",
    "    telegram_new_df, spectrum_new_da = scrape_tripips_tensec_data(url_tensec, numrecords=numrecords_append_tensec)\n",
    "    ND_new_da = calc_ND_da(spectrum_new_da)\n",
    "    # Append new data onto the data array\n",
    "    ND_da = xr.concat([ND_da, ND_new_da], dim='time')\n",
    "    # Drop duplicate timestamps\n",
    "    ND_da = ND_da.groupby('time').first()\n",
    "    # onesec_df = onesec_df[~onesec_df.index.duplicated(keep='first')]\n",
    "    # Drop records older than desired interval\n",
    "    last_timestamp = ND_da['time'].to_index()[-1]\n",
    "    spectrum = spectrum_new_da.loc[last_timestamp]\n",
    "    # print(last_timestamp)\n",
    "    oldest_timestamp = last_timestamp-keep_data_for_ts\n",
    "    ND_da = ND_da.loc[oldest_timestamp:]\n",
    "    plottimes = [ND_da['time'].to_index().to_pydatetime()]\n",
    "    ND_arr = ND_da.values.T\n",
    "    logND_arr = np.ma.log10(ND_arr)\n",
    "    fields_to_plot = [logND_arr]\n",
    "    field_parameters = [log_ND_params]\n",
    "    ax = pm.plotmeteogram(ax, plottimes, fields_to_plot, field_parameters, \n",
    "                          yvals=[min_diameter] * len(fields_to_plot))\n",
    "    ax, = pm.set_meteogram_axes([ax], [log_ND_ax_params])\n",
    "    ax_vd.set_title('Fall speed vs. diameter for time {0}'.format(last_timestamp.strftime(tm.timefmt2)))\n",
    "    countsplot = np.ma.masked_where(spectrum.values <= 0, spectrum)\n",
    "    C = ax_vd.pcolor(min_diameter, min_fall_bins, countsplot, vmin=1, vmax=50, edgecolors='w')\n",
    "    divider = make_axes_locatable(ax_vd)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\")\n",
    "    cb = fig_vd.colorbar(C, cax=cax, orientation='vertical')\n",
    "    ax_vd.set_xlim(0.0, 10.0)\n",
    "    ax_vd.xaxis.set_major_locator(ticker.MultipleLocator(2.0))\n",
    "    ax_vd.set_xlabel('diameter (mm)')\n",
    "    ax_vd.set_ylim(0.0, 10.0)\n",
    "    ax_vd.yaxis.set_major_locator(ticker.MultipleLocator(1.0))\n",
    "    ax_vd.set_ylabel('fall speed (m/s)')\n",
    "    \n",
    "    display.display(fig)\n",
    "    display.display(fig_vd)\n",
    "    display.display(fig_t_td)\n",
    "    display.display(fig_wind)\n",
    "    display.display(fig_pressure)\n",
    "    display.clear_output(wait=True)\n",
    "    # fig.canvas.draw()\n",
    "    fig.savefig(os.path.join(image_output_dir, 'logND_current.png'), dpi=300)\n",
    "    fig_vd.savefig(os.path.join(image_output_dir, 'VD_current.png'), dpi=300)\n",
    "    fig_t_td.savefig(os.path.join(image_output_dir, 'T_Td_current.png'), dpi=300)\n",
    "    fig_wind.savefig(os.path.join(image_output_dir, 'wind_current.png'), dpi=300)\n",
    "    fig_pressure.savefig(os.path.join(image_output_dir, 'pressure.png'), dpi=300)\n",
    "    \n",
    "    # plt.pause(0.01)\n",
    "    # Sleep for the desired interval. This may not be perfectly accurate\n",
    "    time.sleep(plot_update_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A notebook for comparing PIPS and TTU StickNets and using StickNet data to bias-correct the PIPS for IOP2-2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T14:40:32.290220Z",
     "start_time": "2020-06-24T14:40:28.958219Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid,make_axes_locatable,host_subplot\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "#import pyPIPS.disdrometer_module as dis\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "#import pyPIPS.simulator as sim\n",
    "import pyPIPS.pips_io as pipsio\n",
    "import pyPIPS.PIPS as pips\n",
    "import pyPIPS.parsivel_params as pp\n",
    "import pyPIPS.parsivel_qc as pqc\n",
    "import pyPIPS.polarimetric as dualpol\n",
    "import pyPIPS.timemodule as ptime\n",
    "# from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "# from pyCRMtools.pycaps import arps_read\n",
    "# from pyCRMtools.pycaps import pycaps_fields\n",
    "# from pyCRMtools.pycaps import calvars_radar as radar\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy.random as random\n",
    "from scipy.stats import gamma, uniform\n",
    "from scipy.special import gamma as gammafunc\n",
    "from scipy import ndimage\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.calc import wind_components\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.plots.wx_symbols import current_weather, sky_cover\n",
    "from metpy.units import units\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as feature\n",
    "# from natsort import natsorted\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(matplotlib.style.available)\n",
    "\n",
    "matplotlib.style.use('seaborn-v0_8-bright')\n",
    "\n",
    "def comp_plot(PIPS_names, ds_dict, varname='fasttemp', alpha=1.0, mask_below=None, x='time'):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    for PIPS_name in PIPS_names:\n",
    "        plotvar = ds_dict[PIPS_name][varname]\n",
    "        if mask_below is not None:\n",
    "            plotvar = plotvar.where(plotvar > mask_below)\n",
    "        plotvar.plot(ax=ax, label=PIPS_name, alpha=alpha, x=x)\n",
    "    ax.legend(loc='best')\n",
    "    return fig, ax\n",
    "\n",
    "def comp_var_plot(ds, varnames=['pcount', 'pcount_derived'], alpha=1.0, mask_below=None):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    for varname in varnames:\n",
    "        plotvar = ds[varname]\n",
    "        if mask_below is not None:\n",
    "            plotvar = plotvar.where(plotvar > mask_below)\n",
    "        plotvar.plot(ax=ax, label=varname, alpha=alpha)\n",
    "    ax.legend(loc='best')\n",
    "    return fig, ax\n",
    "\n",
    "def comp_var_ds_plot(ds1, ds2, var1, var2, alpha=1.0, mask_below=None):\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    plotvar1 = ds1[var1]\n",
    "    plotvar2 = ds2[var2]\n",
    "    if mask_below is not None:\n",
    "        plotvar1 = plotvar1.where(plotvar1 > mask_below)\n",
    "        plotvar2 = plotvar2.where(plotvar2 > mask_below)\n",
    "    plotvar1.plot(ax=ax, label=f'{ds1.probe_name}: {var1}', alpha=alpha)\n",
    "    plotvar2.plot(ax=ax, label=f'{ds2.probe_name}: {var2}', alpha=alpha)\n",
    "    ax.legend(loc='best')\n",
    "    return fig, ax\n",
    "\n",
    "# Define a formatter function to format the x-axis labels for timedeltas\n",
    "def time_formatter(x, pos):\n",
    "    td = pd.to_timedelta(x, unit='s')\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    if total_seconds < 0:\n",
    "        total_seconds = abs(total_seconds)\n",
    "        sign = \"-\"\n",
    "    else:\n",
    "        sign = \"\"\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f'{sign}{hours:02}:{minutes:02}:{seconds:02}'\n",
    "\n",
    "\n",
    "def adjust_time_coordinate(ds, gust_front_time, dim='time'):\n",
    "    # Calculate the relative time\n",
    "    relative_time = ds[dim] - gust_front_time\n",
    "    relative_time = relative_time.dt.total_seconds()\n",
    "    \n",
    "    # Assign the new coordinate\n",
    "    ds = ds.assign_coords(relative_time=relative_time)\n",
    "    \n",
    "    # Set the new time coordinate\n",
    "    ds = ds.swap_dims({dim: 'relative_time'})\n",
    "    \n",
    "    # Drop the old time coordinate if desired\n",
    "    # ds = ds.drop_vars('time')\n",
    "    \n",
    "    return ds\n",
    "\n",
    "\n",
    "def read_StickNet_locs_to_xarray(filepath):\n",
    "    \"\"\"Given the path to the StickNet locations file, read it into an xarray Dataset\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    ds = df.to_xarray()\n",
    "    ds = ds.assign_coords(ID=('index', ds['ID'].to_numpy()))\n",
    "    ds = ds.swap_dims({'index': 'ID'})\n",
    "\n",
    "    return ds\n",
    "\n",
    "def read_StickNet_level3_to_xarray(dir, deployment_name, probe_id, loc_ds):\n",
    "    \"\"\"Given the directory containing the level3 files and an xarray Dataset containing the location information,\n",
    "       read the data into an xarray Dataset\"\"\"\n",
    "    probe_filename = f\"0{probe_id}_{deployment_name}_level3.txt\"\n",
    "    probe_filepath = os.path.join(dir, probe_filename)\n",
    "    probe_df = pd.read_csv(probe_filepath)\n",
    "    # Set the time index\n",
    "    probe_df['Time'] = pd.DatetimeIndex(probe_df['Time'])\n",
    "    probe_df.set_index(\"Time\", inplace=True)\n",
    "    probe_ds = probe_df.to_xarray()\n",
    "\n",
    "    # Set location, probe id, start and end times, etc., as attributes\n",
    "    probe_ds.attrs['probe_name'] = probe_id\n",
    "    lat = loc_ds.sel(ID=probe_id)['Latitude'].to_numpy().item()\n",
    "    lon = loc_ds.sel(ID=probe_id)['Longitude'].to_numpy().item()\n",
    "    elev = loc_ds.sel(ID=probe_id)['Elevation'].to_numpy().item()\n",
    "    location_tuple = (lat, lon, elev)\n",
    "    probe_ds.attrs['location'] = str(location_tuple)\n",
    "    probe_ds.attrs['Array_Type'] = \"Fine\"\n",
    "    starting_time = probe_ds['Time'][0].dt.strftime(\"%Y%m%d%H%M%S\").item()\n",
    "    ending_time = probe_ds['Time'][-1].dt.strftime(\"%Y%m%d%H%M%S\").item()\n",
    "    probe_ds.attrs['starting_time'] = starting_time\n",
    "    probe_ds.attrs['ending_time'] = ending_time\n",
    "\n",
    "    return probe_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T14:40:48.238022Z",
     "start_time": "2020-06-24T14:40:47.848609Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# date = '052516' # '053122' # '030622' # '061416'\n",
    "\n",
    "PIPS_base_dir = \"/Users/dawson29/Projects/PERiLS/obsdata/2022/PIPS_data/\"\n",
    "deployment_name = \"IOP2_033022\"\n",
    "PIPS_dir = os.path.join(PIPS_base_dir, deployment_name, 'netcdf')\n",
    "PIPS_output_dir = os.path.join(PIPS_base_dir, deployment_name, 'netcdf_bias_corrected')\n",
    "if not os.path.exists(PIPS_output_dir):\n",
    "    os.makedirs(PIPS_output_dir)\n",
    "\n",
    "PIPS_names = ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS3B']\n",
    "parsivel_interval = 10\n",
    "intervalstr = f'{parsivel_interval:d}S'\n",
    "parsivel_filenames = ['parsivel_combined_{}_{}_{:d}s.nc'.format(deployment_name, PIPS_name, parsivel_interval)\n",
    "                      for PIPS_name in PIPS_names]\n",
    "parsivel_filepaths = [os.path.join(PIPS_dir, parsivel_filename) for parsivel_filename in parsivel_filenames]\n",
    "output_parsivel_filepaths = [os.path.join(PIPS_output_dir, parsivel_filename) for parsivel_filename in parsivel_filenames]\n",
    "\n",
    "conv_filenames = ['conventional_raw_{}_{}.nc'.format(deployment_name, PIPS_name) for PIPS_name in PIPS_names]\n",
    "conv_filepaths = [os.path.join(PIPS_dir, conv_filename) for conv_filename in conv_filenames]\n",
    "output_conv_filepaths = [os.path.join(PIPS_output_dir, conv_filename) for conv_filename in conv_filenames]\n",
    "\n",
    "parsivel_ds_read_dict = {}\n",
    "conv_ds_read_dict = {}\n",
    "for PIPS_name, parsivel_filepath, conv_filepath in zip(PIPS_names, parsivel_filepaths, conv_filepaths):\n",
    "    parsivel_ds_read_dict[PIPS_name] = xr.load_dataset(parsivel_filepath)\n",
    "    conv_ds_read_dict[PIPS_name] = xr.load_dataset(conv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for PIPS_name in PIPS_names:\n",
    "    parsivel_ds = parsivel_ds_read_dict[PIPS_name]\n",
    "    print(parsivel_ds['time'][0], parsivel_ds['time'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to certain time range\n",
    "# start_time = '2022-05-31T23:00' # '2022-03-07T00:00'\n",
    "# end_time = '2022-06-01T00:05' # '2022-03-08T00:00'\n",
    "# start_time = '2022-03-30T23:40'\n",
    "# end_time = '2022-03-31T01:30'\n",
    "# start_time = '2023-03-12T00:15'\n",
    "# end_time = '2023-03-12T14:00'\n",
    "# start_time = '2023-02-22T16:00'\n",
    "# end_time = '2023-02-23T01:00'\n",
    "start_time = '2023-03-16T17:45'\n",
    "end_time = '2023-03-17T15:05'\n",
    "\n",
    "if False:\n",
    "    parsivel_ds_dict = {}\n",
    "    conv_ds_dict = {}\n",
    "    for PIPS_name in PIPS_names:\n",
    "        parsivel_ds_dict[PIPS_name] = parsivel_ds_read_dict[PIPS_name].sel(time=slice(start_time, end_time))\n",
    "        conv_ds_dict[PIPS_name] = conv_ds_read_dict[PIPS_name].sel(time=slice(start_time, end_time))\n",
    "else:\n",
    "    parsivel_ds_dict = parsivel_ds_read_dict\n",
    "    conv_ds_dict = conv_ds_read_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsivel_ds_dict['PIPS1A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in StickNet data (level 3)\n",
    "\n",
    "stick_dir = \"/Users/dawson29/Projects/PERiLS/obsdata/2022/TTU_StickNet\"\n",
    "IOP_name = \"IOP2\"\n",
    "\n",
    "location_file = f\"{IOP_name}_StickNet_Locations.csv\"\n",
    "location_path = os.path.join(stick_dir, location_file)\n",
    "\n",
    "sticknet_locs_ds = read_StickNet_locs_to_xarray(location_path)\n",
    "sticknet_fine_locs_ds = sticknet_locs_ds.where(sticknet_locs_ds['Array_Type'] == 'Fine', drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticknet_fine_locs_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticknet_fine_ids = sticknet_fine_locs_ds['ID'].to_numpy()\n",
    "\n",
    "sticknet_ds_list = [read_StickNet_level3_to_xarray(stick_dir, IOP_name, probe_id, sticknet_fine_locs_ds) for probe_id in sticknet_fine_ids]\n",
    "sticknet_ds_dict = {stick_id: stick_ds for stick_id, stick_ds in zip(sticknet_fine_ids, sticknet_ds_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sticknet_ds_dict['103A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ds_dict['PIPS1A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature for PIPS1A and 110A (collocated)\n",
    "fig, ax = comp_var_ds_plot(conv_ds_dict['PIPS1A'], sticknet_ds_dict['110A'], 'fasttemp', 'T', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature for PIPS1B and 103A (collocated)\n",
    "fig, ax = comp_var_ds_plot(conv_ds_dict['PIPS1B'], sticknet_ds_dict['103A'], 'fasttemp', 'T', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RH for PIPS1A and 110A (collocated)\n",
    "fig, ax = comp_var_ds_plot(conv_ds_dict['PIPS1A'], sticknet_ds_dict['110A'], 'RH_derived', 'RH', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RH for PIPS1B and 103A (collocated)\n",
    "fig, ax = comp_var_ds_plot(conv_ds_dict['PIPS1B'], sticknet_ds_dict['103A'], 'RH_derived', 'RH', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pressure for PIPS1A and 110A (collocated)\n",
    "fig, ax = comp_var_ds_plot(conv_ds_dict['PIPS1A'], sticknet_ds_dict['110A'], 'pressure', 'P', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pressure for PIPS1B and 103A (collocated)\n",
    "fig, ax = comp_var_ds_plot(conv_ds_dict['PIPS1B'], sticknet_ds_dict['103A'], 'pressure', 'P', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wind direction for PIPS1A and 110A (collocated)\n",
    "fig, ax = comp_var_ds_plot(conv_ds_dict['PIPS1A'], sticknet_ds_dict['110A'], 'winddirabs', 'WD', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wind direction for PIPS1B and 103A (collocated)\n",
    "fig, ax = comp_var_ds_plot(conv_ds_dict['PIPS1B'], sticknet_ds_dict['103A'], 'winddirabs', 'WD', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wind speed for PIPS1A and 110A (collocated)\n",
    "fig, ax = comp_var_ds_plot(conv_ds_dict['PIPS1A'], sticknet_ds_dict['110A'], 'windspd', 'WS', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wind speed for PIPS1B and 103A (collocated)\n",
    "fig, ax = comp_var_ds_plot(conv_ds_dict['PIPS1B'], sticknet_ds_dict['103A'], 'windspd', 'WS', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature for PIPS2A and PIPS3B (collocated)\n",
    "fig, ax = comp_plot(['PIPS2A', 'PIPS3B'], conv_ds_dict, 'slowtemp', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot pressure for PIPS2A and PIPS3B (collocated)\n",
    "fig, ax = comp_plot(['PIPS2A', 'PIPS3B'], conv_ds_dict, 'pressure', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wind direction for PIPS2A and PIPS3B (collocated)\n",
    "fig, ax = comp_plot(['PIPS2A', 'PIPS3B'], conv_ds_dict, 'winddirabs', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot wind speed for PIPS2A and PIPS3B (collocated)\n",
    "fig, ax = comp_plot(['PIPS2A', 'PIPS3B'], conv_ds_dict, 'windspd', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the following cells we will be doing the following:\n",
    "1. Filter the noisy slowtemp and RH data for the PIPS (using same procedure as was done for the Sticknets)\n",
    "2. Compute the gust front passage times for the Sticknet probes and realign data\n",
    "3. Compute the gust front passage times for the PIPS (1-s data) and realign data\n",
    "4. Use the closest Sticknet station to each of the PIPS to calculate biases in the various conventional data using the gust-front-relative data and correct the PIPS data accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter the noisy slowtemp and RH data for the PIPS (using same procedure as was done for the Sticknets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.signal as signal\n",
    "\n",
    "def filter_data(var_da, fs=1, order=28, cutoff_frequency=0.1):\n",
    "    # fs = 1  # Sampling frequency in Hz\n",
    "\n",
    "    # # Design the 28th order Blackman-Harris filter\n",
    "    # order = 28\n",
    "    # cutoff_frequency = 0.1  # Cutoff frequency in Hz\n",
    "    \n",
    "    # Normalize the cutoff frequency with respect to Nyquist frequency\n",
    "    normalized_cutoff = cutoff_frequency / (0.5 * fs)\n",
    "    \n",
    "    # Design the filter using firwin with a Blackman-Harris window\n",
    "    b = signal.firwin(order + 1, normalized_cutoff, window='blackmanharris', pass_zero=True)\n",
    "\n",
    "    var_da_filt = signal.filtfilt(b, 1, var_da)\n",
    "\n",
    "    return var_da_filt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the filter to the slow-temperature and relative humidity data\n",
    "\n",
    "for name in PIPS_names:\n",
    "    slowtemp = conv_ds_dict[name]['slowtemp']\n",
    "    RH = conv_ds_dict[name]['RH']\n",
    "    slowtemp_filt = filter_data(slowtemp, cutoff_frequency=0.1)\n",
    "    RH_filt = filter_data(RH, cutoff_frequency=0.1)\n",
    "\n",
    "    conv_ds_dict[name]['slowtemp'].data = slowtemp_filt\n",
    "    conv_ds_dict[name]['slowtemp'].attrs['filtered'] = 'yes'\n",
    "    conv_ds_dict[name]['RH'].data = RH_filt\n",
    "    conv_ds_dict[name]['RH'].attrs['filtered'] = 'yes'\n",
    "    \n",
    "    # conv_ds_dict[name]['slowtemp_filt'] = signal.lfilter(b, 1, temperature)\n",
    "    # conv_ds_dict[name]['RH_derived_filt'] = signal.lfilter(b, 1, RH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperature for PIPS2A and PIPS3B (collocated)\n",
    "fig, ax = comp_plot(['PIPS2A', 'PIPS3B'], conv_ds_dict, 'slowtemp', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the gust front passage times for the Sticknet probes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperatures for sticknet probes\n",
    "fig, ax = comp_plot(sticknet_fine_ids, sticknet_ds_dict, 'T', alpha=0.5, x='Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the data a bit to remove short-range fluctuations\n",
    "window_size = 120 # Corresponds to 2 min for the 1-s data\n",
    "min_periods = 1\n",
    "\n",
    "for name in sticknet_fine_ids:\n",
    "    stick_ds = sticknet_ds_dict[name]\n",
    "    T_smooth = stick_ds['T'].rolling(Time=window_size, center=True, min_periods=min_periods).mean()\n",
    "    stick_ds['T_smooth'] = T_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = comp_plot(sticknet_fine_ids, sticknet_ds_dict, 'T_smooth', alpha=0.5, x='Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the 1st-order difference of the smoothed temperature field\n",
    "for name in sticknet_fine_ids:\n",
    "    stick_ds = sticknet_ds_dict[name]\n",
    "    diff_T = stick_ds['T_smooth'].diff(dim='Time', label='upper')\n",
    "    # diff_T = diff_T.where(diff_T < -0.03, drop=True)\n",
    "    stick_ds['diff_T'] = diff_T\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the temperature difference in adjacent times\n",
    "fig, ax = comp_plot(sticknet_fine_ids, sticknet_ds_dict, 'diff_T', alpha=0.5, x='Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plot, we see we can take the time of the *minimum* signed temp difference (the time where the temp is dropping the fastest)\n",
    "# as the reference time for the along line average\n",
    "# EDIT: It looks like a better criterion is for when the temperature drop rate first exceeds a certain threshold -0.0075 deg C per s (for the smoothed data)\n",
    "temp_drop_threshold = -0.0075\n",
    "\n",
    "stick_gust_front_times = {}\n",
    "for name in sticknet_fine_ids:\n",
    "    # tindex = parsivel_ds_dict[PIPS_name]['diff_fasttemp'].argmin()\n",
    "    diff_T = sticknet_ds_dict[name]['diff_T']\n",
    "    tindex = xr.where(diff_T < temp_drop_threshold, True, False).argmax(dim='Time').item()\n",
    "    gust_front_time = sticknet_ds_dict[name]['Time'].isel(Time=tindex).values\n",
    "    stick_gust_front_times[name] = gust_front_time\n",
    "\n",
    "stick_gust_front_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new time coordinate as time since gust front passage\n",
    "new_sticknet_ds_dict = {}\n",
    "for name, stick_ds in sticknet_ds_dict.items():\n",
    "    gust_front_time = stick_gust_front_times[name]\n",
    "    new_sticknet_ds_dict[name] = adjust_time_coordinate(stick_ds, gust_front_time, dim='Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = comp_plot(sticknet_fine_ids, new_sticknet_ds_dict, 'T', alpha=0.5, x='relative_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align datasets to common times\n",
    "aligned_sticknet_datasets = xr.align(*new_sticknet_ds_dict.values(), join='inner')\n",
    "\n",
    "# Combine datasets into a new Dataset with a new dimension 'PIPS'\n",
    "# combined_sticknet_ds = xr.concat(aligned_sticknet_datasets, dim='probe_name')\n",
    "# combined_sticknet_ds['probe_name'] = list(sticknet_ds_dict.keys())\n",
    "\n",
    "# Convert TimeDelta objects to seconds for plotting\n",
    "# combined_parsivel_ds = combined_parsivel_ds.assign_coords(\n",
    "#     seconds_since_gust_front=combined_parsivel_ds['relative_time'].dt.total_seconds()\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the gust front passage times for the PIPS (1-s data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot temperatures\n",
    "fig, ax = comp_plot(PIPS_names, parsivel_ds_dict, 'fasttemp', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smooth the data a bit to remove short-range fluctuations\n",
    "window_size = 120 # Corresponds to 2 min for the 1-s data\n",
    "min_periods = 1\n",
    "\n",
    "for PIPS_name in PIPS_names:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    fasttemp_smooth = conv_ds['fasttemp'].rolling(time=window_size, center=True, min_periods=min_periods).mean()\n",
    "    conv_ds['fasttemp_smooth'] = fasttemp_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = comp_plot(PIPS_names, conv_ds_dict, 'fasttemp_smooth', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the 1st-order difference of the smoothed temperature field\n",
    "for PIPS_name in PIPS_names:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    diff_T = conv_ds['fasttemp_smooth'].diff(dim='time', label='upper')\n",
    "    # diff_T = diff_T.where(diff_T < -0.03, drop=True)\n",
    "    conv_ds['diff_fasttemp'] = diff_T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the temperature difference in adjacent times\n",
    "fig, ax = comp_plot(PIPS_names, conv_ds_dict, 'diff_fasttemp', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the above plot, we see we can take the time of the *minimum* signed temp difference (the time where the temp is dropping the fastest)\n",
    "# as the reference time for the along line average\n",
    "# EDIT: It looks like a better criterion is for when the temperature drop rate first exceeds -0.0075 deg C per 1 s (for the smoothed data)\n",
    "temp_drop_threshold = -0.0075\n",
    "\n",
    "PIPS_gust_front_times = {}\n",
    "for PIPS_name in PIPS_names:\n",
    "    # tindex = parsivel_ds_dict[PIPS_name]['diff_fasttemp'].argmin()\n",
    "    diff_T = conv_ds_dict[PIPS_name]['diff_fasttemp']\n",
    "    tindex = xr.where(diff_T < temp_drop_threshold, True, False).argmax(dim='time').item()\n",
    "    gust_front_time = conv_ds_dict[PIPS_name]['time'].isel(time=tindex).values\n",
    "    # For the collocated probes, we assume that the gust front passes them at the exact same time, even if the above calculation is \n",
    "    # a bit different from that. It really shouldn't matter too much, but we'll use the collocated sticknet time of passage\n",
    "    if PIPS_name == 'PIPS1A':\n",
    "        PIPS_gust_front_times[PIPS_name] = stick_gust_front_times['110A']\n",
    "    elif PIPS_name == 'PIPS1B':\n",
    "        PIPS_gust_front_times[PIPS_name] = stick_gust_front_times['103A']\n",
    "    else:\n",
    "        PIPS_gust_front_times[PIPS_name] = gust_front_time\n",
    "\n",
    "PIPS_gust_front_times['PIPS3B'] = PIPS_gust_front_times['PIPS2A']\n",
    "\n",
    "PIPS_gust_front_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for PIPS_name in PIPS_names:\n",
    "    # I hate these datetime to datetime64 and vice-versa shenanigans :(\n",
    "    time_dt = pd.to_datetime(str(PIPS_gust_front_times[PIPS_name])) \n",
    "    timestring = time_dt.strftime(\"%Y%m%d%H%M%S\")\n",
    "    print(f\"{PIPS_name}: {timestring}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new time coordinate as time since gust front passage\n",
    "new_conv_ds_dict = {}\n",
    "for PIPS_name, conv_ds in conv_ds_dict.items():\n",
    "    gust_front_time = PIPS_gust_front_times[PIPS_name]\n",
    "    new_conv_ds_dict[PIPS_name] = adjust_time_coordinate(conv_ds, gust_front_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = comp_plot(PIPS_names, new_conv_ds_dict, 'fasttemp', alpha=0.5, x='relative_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Align datasets to common times\n",
    "aligned_PIPS_datasets = xr.align(*new_conv_ds_dict.values(), join='inner')\n",
    "\n",
    "# Combine datasets into a new Dataset with a new dimension 'PIPS'\n",
    "# combined_PIPS_ds = xr.concat(aligned_PIPS_datasets, dim='probe_name')\n",
    "# combined_PIPS_ds['probe_name'] = list(conv_ds_dict.keys())\n",
    "\n",
    "# Convert TimeDelta objects to seconds for plotting\n",
    "# combined_parsivel_ds = combined_parsivel_ds.assign_coords(\n",
    "#     seconds_since_gust_front=combined_parsivel_ds['relative_time'].dt.total_seconds()\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the closest Sticknet station to each of the PIPS to calculate biases in the various conventional data using the gust-front-relative data and correct the PIPS data accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_correct_vars(aligned_datasets_dict, conv_ds_dict, PIPS_name, stick_name, vars):\n",
    "    for var_group in vars:\n",
    "        diff_var = aligned_datasets_dict[PIPS_name][var_group[0]] - aligned_datasets_dict[stick_name][var_group[1]]\n",
    "        mean_diff_var = diff_var.mean().values\n",
    "        # Note that we also correct the *original* PIPS dataset variables, *not* just the new aligned ones, \n",
    "        # since those cut off data on either side. We want to save back to the original files with the corrected variables.\n",
    "\n",
    "        if 'bias_subtracted' not in conv_ds_dict[PIPS_name][f'{var_group[0]}'].attrs:\n",
    "            conv_ds_dict[PIPS_name][f'{var_group[0]}'] = conv_ds_dict[PIPS_name][var_group[0]] - mean_diff_var\n",
    "            # Add the value subtracted to the attributes so we know that we modified it\n",
    "            conv_ds_dict[PIPS_name][f'{var_group[0]}'].attrs['bias_subtracted'] = mean_diff_var\n",
    "            aligned_datasets_dict[PIPS_name][f'{var_group[0]}'] = aligned_datasets_dict[PIPS_name][var_group[0]] - mean_diff_var\n",
    "            # Add the value subtracted to the attributes so we know that we modified it\n",
    "            aligned_datasets_dict[PIPS_name][f'{var_group[0]}'].attrs['bias_subtracted'] = mean_diff_var\n",
    "        else:\n",
    "            print(f\"Already bias-corrected {var_group[0]} for {PIPS_name}, silly!\")\n",
    "    \n",
    "    return aligned_datasets_dict, conv_ds_dict\n",
    "\n",
    "def bias_correct_wind_dir(aligned_datasets_dict, conv_ds_dict, PIPS_name, stick_name, winddir_name_PIPS, winddir_name_stick):\n",
    "    # Wind direction\n",
    "\n",
    "    # # First compute the u and v wind components\n",
    "    # u_PIPS = aligned_datasets_dict['PIPS1A']['windspd'] * np.cos(np.deg2rad(-aligned_datasets_dict['PIPS1A']['winddirabs'] + 270.))\n",
    "    # v_PIPS = aligned_datasets_dict['PIPS1A']['windspd'] * np.sin(np.deg2rad(-aligned_datasets_dict['PIPS1A']['winddirabs'] + 270.))\n",
    "    \n",
    "    # u_stick = aligned_datasets_dict['110A']['WS'] * np.cos(np.deg2rad(-aligned_datasets_dict['110A']['WD'] + 270.))\n",
    "    # v_stick = aligned_datasets_dict['110A']['WS'] * np.sin(np.deg2rad(-aligned_datasets_dict['110A']['WD'] + 270.))\n",
    "    \n",
    "    # diff_u = u_PIPS - u_stick\n",
    "    # diff_v = v_PIPS - v_stick\n",
    "    \n",
    "    diff_winddir = aligned_datasets_dict[PIPS_name][winddir_name_PIPS] - aligned_datasets_dict[stick_name][winddir_name_stick]\n",
    "    diff_winddir = xr.where(diff_winddir > 180., diff_winddir - 360., diff_winddir)\n",
    "    diff_winddir = xr.where(diff_winddir < -180., diff_winddir + 360., diff_winddir)\n",
    "    mean_diff_winddir = diff_winddir.mean().values\n",
    "\n",
    "    if 'bias_subtracted' not in conv_ds_dict[PIPS_name][winddir_name_PIPS].attrs:\n",
    "        # Note that we also correct the *original* PIPS dataset variables, *not* just the new aligned ones, \n",
    "        # since those cut off data on either side. We want to save back to the original files with the corrected variables.\n",
    "        conv_ds_dict[PIPS_name][winddir_name_PIPS] = (conv_ds_dict[PIPS_name][winddir_name_PIPS] - mean_diff_winddir) % 360\n",
    "        # Add the value subtracted to the attributes so we know that we modified it\n",
    "        conv_ds_dict[PIPS_name][winddir_name_PIPS].attrs['bias_subtracted'] = mean_diff_winddir\n",
    "        \n",
    "        aligned_datasets_dict[PIPS_name][winddir_name_PIPS] = (aligned_datasets_dict[PIPS_name][winddir_name_PIPS] - mean_diff_winddir) % 360\n",
    "        # Add the value subtracted to the attributes so we know that we modified it\n",
    "        aligned_datasets_dict[PIPS_name][winddir_name_PIPS].attrs['bias_subtracted'] = mean_diff_winddir\n",
    "    else:\n",
    "        print(f\"Already bias-corrected {winddir_name_PIPS} for {PIPS_name}, silly!\")\n",
    "\n",
    "    return aligned_datasets_dict, conv_ds_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First align all the PIPS and Sticknet probes by gust-front-relative time\n",
    "all_probe_names = list(sticknet_ds_dict.keys()) + list(conv_ds_dict.keys())\n",
    "all_datasets = list(new_sticknet_ds_dict.values()) + list(new_conv_ds_dict.values())\n",
    "aligned_datasets = xr.align(*all_datasets, join='inner')\n",
    "aligned_datasets_dict = {probe_name: ds for probe_name, ds in zip(all_probe_names, aligned_datasets)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_datasets_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check!\n",
    "fig, ax = comp_var_ds_plot(aligned_datasets_dict['PIPS1A'], aligned_datasets_dict['110A'], 'pressure', 'P', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables to correct (except for wind direction, which is done a bit differently, and wind speed, which arguably should be a bit\n",
    "# lower for the PIPS since they are shorter...)\n",
    "vars = [['fasttemp', 'T'], ['slowtemp', 'T'], ['RH', 'RH'], ['pressure', 'P']]\n",
    "\n",
    "winddir_name_PIPS = 'winddirabs'\n",
    "winddir_name_stick = 'WD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPS1A and 110A\n",
    "PIPS_name = 'PIPS1A'\n",
    "stick_name = '110A'\n",
    "\n",
    "aligned_datasets_dict, conv_ds_dict = bias_correct_vars(aligned_datasets_dict, conv_ds_dict, PIPS_name, stick_name, vars)\n",
    "aligned_datasets_dict, conv_ds_dict = bias_correct_wind_dir(aligned_datasets_dict, conv_ds_dict, PIPS_name, stick_name, winddir_name_PIPS, \n",
    "                                                            winddir_name_stick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check!\n",
    "fig, ax = comp_var_ds_plot(aligned_datasets_dict['PIPS1A'], aligned_datasets_dict['110A'], 'fasttemp', 'T', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aligned_datasets_dict['PIPS1A']['fasttemp'].attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPS1B and 103A\n",
    "PIPS_name = 'PIPS1B'\n",
    "stick_name = '103A'\n",
    "\n",
    "aligned_datasets_dict, conv_ds_dict = bias_correct_vars(aligned_datasets_dict, conv_ds_dict, PIPS_name, stick_name, vars)\n",
    "aligned_datasets_dict, conv_ds_dict = bias_correct_wind_dir(aligned_datasets_dict, conv_ds_dict, PIPS_name, stick_name, winddir_name_PIPS, \n",
    "                                                            winddir_name_stick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check!\n",
    "fig, ax = comp_var_ds_plot(aligned_datasets_dict[PIPS_name], aligned_datasets_dict[stick_name], 'fasttemp', 'T', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(aligned_datasets_dict['PIPS1B']['fasttemp'].attrs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPS2A and 104A\n",
    "PIPS_name = 'PIPS2A'\n",
    "stick_name = '104A'\n",
    "\n",
    "aligned_datasets_dict, conv_ds_dict = bias_correct_vars(aligned_datasets_dict, conv_ds_dict, PIPS_name, stick_name, vars)\n",
    "aligned_datasets_dict, conv_ds_dict = bias_correct_wind_dir(aligned_datasets_dict, conv_ds_dict, PIPS_name, stick_name, winddir_name_PIPS, \n",
    "                                                            winddir_name_stick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check!\n",
    "fig, ax = comp_var_ds_plot(aligned_datasets_dict[PIPS_name], aligned_datasets_dict[stick_name], 'slowtemp', 'T', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPS3B and 104A\n",
    "\n",
    "PIPS_name = 'PIPS3B'\n",
    "stick_name = '104A'\n",
    "\n",
    "aligned_datasets_dict, conv_ds_dict = bias_correct_vars(aligned_datasets_dict, conv_ds_dict, PIPS_name, stick_name, vars)\n",
    "aligned_datasets_dict, conv_ds_dict = bias_correct_wind_dir(aligned_datasets_dict, conv_ds_dict, PIPS_name, stick_name, winddir_name_PIPS, \n",
    "                                                            winddir_name_stick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check!\n",
    "fig, ax = comp_var_ds_plot(aligned_datasets_dict[PIPS_name], aligned_datasets_dict[stick_name], 'slowtemp', 'T', alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we need to recompute the dewpoint and RH_derived using the bias-corrected quantites from above\n",
    "# Do this just for the original conventional PIPS datasets\n",
    "\n",
    "for PIPS_name in PIPS_names:\n",
    "    pressure = conv_ds_dict[PIPS_name]['pressure']\n",
    "    slowtemp = conv_ds_dict[PIPS_name]['slowtemp']\n",
    "    fasttemp = conv_ds_dict[PIPS_name]['fasttemp']\n",
    "    RH = conv_ds_dict[PIPS_name]['RH']\n",
    "    dewpoint = thermo.calTdfromRH(pressure * 100., slowtemp + 273.15, RH / 100.) - 273.15\n",
    "#     dewpoint.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_dewpoint', \n",
    "#                                                          ls='None', marker='o', ms=1., alpha=0.5)\n",
    "    RH_derived = thermo.calRH(pressure * 100., fasttemp + 273.15, dewpoint + 273.15) * 100.\n",
    "    \n",
    "    conv_ds_dict[PIPS_name]['dewpoint'].data = dewpoint\n",
    "    conv_ds_dict[PIPS_name]['RH_derived'].data = RH_derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check!\n",
    "\n",
    "PIPS_name = 'PIPS3B'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "conv_ds_dict[PIPS_name]['dewpoint'].plot(ax=ax, label='dewpoint')\n",
    "ax.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check!\n",
    "\n",
    "PIPS_name = 'PIPS3B'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "conv_ds_dict[PIPS_name]['RH_derived'].plot(ax=ax, label='RH (derived)')\n",
    "ax.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute some of the derived thermodynamic parameters (pt, qv, rho) using the new corrected vars\n",
    "\n",
    "for PIPS_name in PIPS_names:\n",
    "    conv_ds_dict[PIPS_name] = pips.calc_thermo(conv_ds_dict[PIPS_name], p_var='pressure', \n",
    "                                               T_var='fasttemp', RH_var='RH_derived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now resample the corrected timeseries to the parsivel times. Technically, we could just apply the bias correction\n",
    "# directly and should get the same result.\n",
    "\n",
    "corrected_varnames = ['pressure', 'fasttemp', 'slowtemp', 'dewpoint', 'RH', 'RH_derived', 'pt', 'qv', 'rho']\n",
    "\n",
    "for PIPS_name in PIPS_names:\n",
    "    # try:\n",
    "    PSD_datetimes = pips.get_PSD_datetimes(parsivel_ds_dict[PIPS_name]['VD_matrix'])\n",
    "    sec_offset = PSD_datetimes[0].second\n",
    "    print(sec_offset)\n",
    "    offset_str = pips.get_interval_str(sec_offset)\n",
    "    \n",
    "    for corrected_varname in corrected_varnames:\n",
    "        corrected_var = conv_ds_dict[PIPS_name][corrected_varname]\n",
    "        new_var = corrected_var.resample(time=intervalstr, label='right', closed='right', \n",
    "                                         offset=offset_str).mean()\n",
    "        \n",
    "        parsivel_ds_dict[PIPS_name][corrected_varname] = new_var\n",
    "        parsivel_ds_dict[PIPS_name][corrected_varname].attrs = conv_ds_dict[PIPS_name][corrected_varname].attrs\n",
    "    # except:\n",
    "    #     print(f\"No Parsivel data for {PIPS_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the same for the winds\n",
    "\n",
    "for PIPS_name in PIPS_names:\n",
    "    # Resample the winds to the parsivel times and replace the old ones\n",
    "    try:\n",
    "        conv_ds = conv_ds_dict[PIPS_name]\n",
    "        PSD_datetimes = pips.get_PSD_datetimes(parsivel_ds['VD_matrix'])\n",
    "        sec_offset = PSD_datetimes[0].second\n",
    "        \n",
    "        new_wind_dict = pips.resample_wind_da(conv_ds['winddirabs'], conv_ds['windspd'], intervalstr, \n",
    "                                              sec_offset, gusts=True, gustintvstr='3S')\n",
    "\n",
    "        for key, val in new_wind_dict.items():\n",
    "            parsivel_ds_dict[PIPS_name][key] = val\n",
    "    except:\n",
    "        sec_offset = None\n",
    "        new_wind_dict = None\n",
    "        print(f\"No Parsivel data for {PIPS_to_check}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check!\n",
    "fig, ax = comp_var_plot(parsivel_ds_dict['PIPS3B'], varnames=['uavg'], alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save to new output directory\n",
    "for PIPS_name, output_parsivel_filepath, output_conv_filepath in zip(PIPS_names, \n",
    "                                                                     output_parsivel_filepaths, \n",
    "                                                                     output_conv_filepaths):\n",
    "    print(PIPS_name)\n",
    "    \n",
    "    try:\n",
    "        print(\"Saving {}\".format(output_parsivel_filepath))\n",
    "        parsivel_ds_dict[PIPS_name].to_netcdf(output_parsivel_filepath)\n",
    "    except:\n",
    "        print(f\"No Parsivel data for {PIPS_name}\")\n",
    "    print(\"Saving {}\".format(output_conv_filepath))\n",
    "    conv_ds_dict[PIPS_name].to_netcdf(output_conv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CELLS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure out how to average winds. We can just take the direct average of the wind speeds, gust speeds, and u and v components\n",
    "# The rest we re-compute from the averaged u and v components\n",
    "var_da_dict = {}\n",
    "for var in ['windspd', 'windgust', 'uavg', 'vavg']:\n",
    "    var_da_dict[var] = combined_parsivel_ds[var].mean(dim='PIPS', skipna=True)\n",
    "\n",
    "# Compute vector average wind speed\n",
    "var_da_dict['windspdavgvec'] = np.sqrt(var_da_dict['uavg']**2. + var_da_dict['vavg']**2.)\n",
    "# Compute vector average wind direction\n",
    "var_da_dict['winddirabs'] = (270.0 - (180. / np.pi) * np.arctan2(var_da_dict['vavg'], var_da_dict['uavg'])) % 360.\n",
    "\n",
    "# Compute unit average wind speed/direction\n",
    "unit_u = combined_parsivel_ds['uavg'] / combined_parsivel_ds['windspd']\n",
    "unit_v = combined_parsivel_ds['vavg'] / combined_parsivel_ds['windspd']\n",
    "unit_u_avg = unit_u.mean(dim='PIPS', skipna=True)\n",
    "unit_v_avg = unit_v.mean(dim='PIPS', skipna=True)\n",
    "\n",
    "wind_dir_unit_vec_avg = (270.0 - (180. / np.pi) * np.arctan2(unit_v_avg, unit_u_avg)) % 360.\n",
    "wind_dir_unit_vec_avg = xr.where((unit_u_avg == 0.) & (unit_v_avg == 0.), np.nan, wind_dir_unit_vec_avg)\n",
    "\n",
    "var_da_dict['unit_uavg'] = unit_u_avg\n",
    "var_da_dict['unit_vavg'] = unit_v_avg\n",
    "var_da_dict['winddirunitavgvec'] = wind_dir_unit_vec_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'winddirunitavgvec'\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "var_da_dict[var].plot(ax=ax, label='avg')\n",
    "combined_parsivel_ds.sel(PIPS='PIPS1A')[var].plot(ax=ax, label='PIPS1A')\n",
    "combined_parsivel_ds.sel(PIPS='PIPS1B')[var].plot(ax=ax, label='PIPS1B')\n",
    "combined_parsivel_ds.sel(PIPS='PIPS2A')[var].plot(ax=ax, label='PIPS2A')\n",
    "combined_parsivel_ds.sel(PIPS='PIPS3B')[var].plot(ax=ax, label='PIPS3B')\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "spd = np.sqrt(var_da_dict['unit_uavg']**2. + var_da_dict['unit_vavg']**2.)\n",
    "spd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spd = np.sqrt(combined_parsivel_ds.sel(PIPS='PIPS1A')['unit_uavg']**2. + combined_parsivel_ds.sel(PIPS='PIPS1A')['unit_vavg']**2.)\n",
    "spd.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute the average across the 'PIPS' dimension\n",
    "parsivel_average_ds = combined_parsivel_ds.mean(dim='PIPS')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_parsivel_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_new_parsivel_dict = {}\n",
    "for PIPS_name in PIPS_names:\n",
    "    new_new_parsivel_dict[PIPS_name] = combined_parsivel_ds.sel(PIPS=PIPS_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = comp_plot(PIPS_names, new_new_parsivel_dict, 'fasttemp', alpha=0.5, x='relative_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "parsivel_average_ds['fasttemp'].plot(ax=ax, x='relative_time')\n",
    "\n",
    "# Format the x-axis\n",
    "# ax.xaxis.set_major_formatter(ticker.FuncFormatter(time_formatter))\n",
    "ax.set_xlabel('Time since gust front passage (s)')\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(900.))\n",
    "ax.xaxis.set_minor_locator(ticker.MultipleLocator(300.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSD_times = parsivel_average_ds['relative_time']\n",
    "PSD_times_dict = pips.get_PSD_time_bins(PSD_times)\n",
    "\n",
    "\n",
    "PSD_times_dict['PSD_datetimes_edges'].astype('timedelta64[s]').astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute polarimetric fields from PIPS DSDs\n",
    "dD = parsivel_average_ds['max_diameter'] - parsivel_average_ds['min_diameter']\n",
    "dualpol_dict_PIPS_avg = dualpol.calpolrain_bulk_xr(10.7, \n",
    "                                                   '/Users/dawson29/Projects/pyPIPS/tmatrix/S-Band/SCTT_RAIN_fw100.dat',\n",
    "                                                   parsivel_average_ds['ND_roqc'], dD, diameter_bin_name='diameter_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dualpol_dict_PIPS_avg.keys()\n",
    "\n",
    "dualpol_dict_PIPS_avg['REF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot observed DSD meteograms\n",
    "\n",
    "ND_PIPS = parsivel_average_ds['ND_roqc']\n",
    "# ND_PIPS = combined_parsivel_ds.sel(PIPS='PIPS3B')['ND_roqc']\n",
    "ZH_PIPS = dualpol_dict_PIPS_avg['REF']\n",
    "ZH_rad = parsivel_average_ds['KGWX_at_PIPS'].loc[{'fields_KGWX': 'REF_filtered'}]\n",
    "\n",
    "# Truncate diameter range to less than 9 mm\n",
    "D_max = 9.\n",
    "D_range_full = ND_PIPS['diameter'].values\n",
    "D_max_ind = np.searchsorted(D_range_full, D_max)\n",
    "D_range = D_range_full[:D_max_ind]\n",
    "print(D_max_ind, D_range)\n",
    "ND_trunc = ND_PIPS.isel(diameter_bin=slice(0, D_max_ind))\n",
    "\n",
    "PSD_datetimes_PIPS = parsivel_average_ds['relative_time']  # pips.get_PSD_datetimes(ND_PIPS)\n",
    "PSD_datetimes_PIPS_dict = pips.get_PSD_time_bins(PSD_datetimes_PIPS)\n",
    "# PSDstarttimes = dates.date2num(PSD_datetimes_PIPS_dict['PSD_datetimes_edges'])\n",
    "# PSDmidtimes = dates.date2num(PSD_datetimes_PIPS_dict['PSD_datetimes_centers'])\n",
    "\n",
    "# Gotcha! For some reason the following only works because the dictionary entries are numpy arrays, not xarray DataArrays.\n",
    "# If they are the latter, I suppose we would have to extract the underlying numpy array, recast it, and then save the data back\n",
    "# to the original DataArray\n",
    "PSDstarttimes = PSD_datetimes_PIPS_dict['PSD_datetimes_edges'].astype('timedelta64[s]').astype('int')\n",
    "PSDmidtimes = PSD_datetimes_PIPS_dict['PSD_datetimes_centers'].astype('timedelta64[s]').astype('int')\n",
    "\n",
    "plot_start_datetime = PSDstarttimes[0]\n",
    "plot_end_datetime = PSDstarttimes[-1]\n",
    "\n",
    "# Prepare axis parameters\n",
    "timelimits = [plot_start_datetime, plot_end_datetime]\n",
    "diamlimits = [0.0, 9.0]\n",
    "diamytick = 1.0\n",
    "DSDtype = 'observed'\n",
    "locator = ticker.MultipleLocator(900) # dates.MinuteLocator(byminute=[0,15,30,45])\n",
    "minorlocator = ticker.MultipleLocator(300) # dates.MinuteLocator(byminute=range(0,60,5))\n",
    "dateformat = '%H:%M'\n",
    "formatter = None #  dates.DateFormatter(dateformat)\n",
    "\n",
    "axparams = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "            'minorxlocator': minorlocator,\n",
    "            'axeslimits': [timelimits, diamlimits],\n",
    "            'majorylocator': ticker.MultipleLocator(base=diamytick),\n",
    "            'axeslabels': [None, 'D (mm)']}\n",
    "\n",
    "logND = np.log10(ND_trunc)\n",
    "logND = logND.where(logND > -1.0)\n",
    "\n",
    "# Ok, now we should have everything ready to go to plot the meteograms.\n",
    "# Let'er rip!\n",
    "\n",
    "# D0 = D0_PIPS_interp_to_model_times_dict[dis_name] * 1000. # Get to mm again\n",
    "# dBZ = dBZ_PIPS_interp_to_model_times_dict[dis_name]\n",
    "# ZDR = dualpol_PIPS_interp_to_model_times_dict[dis_name]['ZDR']\n",
    "\n",
    "diameter_bin_edges = pp.parsivel_parameters['diameter_bin_edges_mm']\n",
    "diameter_bin_edges = diameter_bin_edges[:D_max_ind+1]\n",
    "\n",
    "disvars = {'diameter_bin_edges': diameter_bin_edges, 'PSDstarttimes': PSDstarttimes,\n",
    "           'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'REF': ZH_PIPS} # , 'D_m': Dm_sorted_PIPS_da, 'dBZ': ZH_sorted_PIPS_da, \n",
    "           # 'ZDR': ZDR_sorted_PIPS_da}\n",
    "\n",
    "# radvars = None\n",
    "radvars = {'radmidtimes': PSDmidtimes, 'REF': ZH_rad}\n",
    "\n",
    "plot_dir = './'\n",
    "dis_plot_name = 'PIPSAVG_' + DSDtype\n",
    "PIPSplot.plotDSDmeteograms(dis_plot_name, plot_dir, axparams, disvars, radvars=radvars, close_fig=False, use_plot_date=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsivel_average_ds"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pyPIPS]",
   "language": "python",
   "name": "conda-env-pyPIPS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

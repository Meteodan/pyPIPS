{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:24:46.960939Z",
     "start_time": "2020-05-12T18:24:43.306782Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "# %set_env PROJ_LIB=/depot/dawson29/apps/condaenv/envs/cent7/5.1.0-py27/pyPIPS/share/proj\n",
    "# %set_env LD_LIBRARY_PATH=/apps/cent7/intel/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64\n",
    "# %set_env LIBRARY_PATH=/apps/cent7/intel/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64\n",
    "print(os.environ)\n",
    "import pyPIPS.dualpara as dualpol\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid,make_axes_locatable,host_subplot\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import pytz as pytz\n",
    "import sys\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "import pyPIPS.disdrometer_module as dis\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "import pyPIPS.simulator as sim\n",
    "import pyPIPS.radarmodule as pyPIPSradar\n",
    "import pyPIPS.PIPS as pips\n",
    "import pyPIPS.pips_io as pips_io\n",
    "import pyPIPS.parsivel_qc as pqc\n",
    "import pyPIPS.parsivel_params as pp\n",
    "from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "from pyCRMtools.pycaps import arps_read\n",
    "from pyCRMtools.pycaps import pycaps_fields\n",
    "from pyCRMtools.pycaps import calvars_radar as radar\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy.random as random\n",
    "from scipy.stats import gamma, uniform\n",
    "from scipy.special import gamma as gammafunc\n",
    "from scipy import ndimage\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.calc import get_wind_components\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.plots.wx_symbols import current_weather, sky_cover\n",
    "from metpy.units import units\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-12T18:24:46.967227Z",
     "start_time": "2020-05-12T18:24:45.059Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define dictionaries, keyed by case date (i.e. '060509', '060709', '060909', '033116'), to store parameters related\n",
    "# to NEXRAD radar data, disdrometer data, and model output, respectively\n",
    "\n",
    "# Case we are looking at right now. Should only have to change this up here and then execute all the cells below\n",
    "# to generate the appropriate analysis\n",
    "casedate = '033116'\n",
    "\n",
    "# Import the file containing the dictionaries needed to gather the radar, disdrometer, and model data.\n",
    "sys.path.append('/depot/dawson29/data/Projects/VORTEXSE/vortexse_enkf_dsd_study/configs/2016_IOP3')\n",
    "\n",
    "from PIPSsim_1km_dicts_rice import *\n",
    "\n",
    "init_radar_dict = init_radar_dict[casedate]\n",
    "init_dis_dict = init_dis_dict[casedate]\n",
    "init_model_dict = init_model_dict[casedate]\n",
    "\n",
    "load_pkl = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T15:59:21.896684Z",
     "start_time": "2019-09-07T15:57:51.150350Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_dir = '/depot/dawson29/data/Projects/VORTEXSE/vortexse_enkf_dsd_study/data/radar_data/pkl'\n",
    "pkl_file = '{}_KGWX.pkl'.format(casedate)\n",
    "pkl_path = os.path.join(pkl_dir, pkl_file)\n",
    "\n",
    "# Now go ahead and read in the sweeps for the desired case\n",
    "if not load_pkl:\n",
    "    radar_dict = sim.read_sweeps(init_radar_dict)\n",
    "    # Dump radar dictonary to pickle file\n",
    "    with open(pkl_path, 'wb') as pkl_file_obj:\n",
    "        pickle.dump(radar_dict, pkl_file_obj)\n",
    "else:\n",
    "    with open(pkl_path, 'rb') as pkl_file_obj:\n",
    "        radar_dict = pickle.load(pkl_file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T00:15:14.191065Z",
     "start_time": "2019-09-10T00:15:14.118869Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Now do the same for the model output\n",
    "# First set up some stuff\n",
    "\n",
    "def get_ARPS_member_dir_and_prefix(member, cycle):\n",
    "    \"\"\"\n",
    "    Gets the proper form for the subdirectory and file prefix name given a member number\n",
    "    and cycle type (either 'posterior' or 'prior'). member number 0 is interpreted as the mean. \n",
    "    \"\"\"\n",
    "    if member == 0:\n",
    "        if cycle in 'posterior':\n",
    "            member_dir = 'ENamean'\n",
    "            member_prefix = 'enmean'\n",
    "        elif cycle in 'prior':\n",
    "            member_dir = 'ENfmean'\n",
    "            member_prefix = 'efmean'\n",
    "    else:\n",
    "        if cycle in 'posterior':\n",
    "            member_dir = 'EN{:03d}'.format(int(member))\n",
    "            member_prefix = 'ena{:03d}'.format(int(member))\n",
    "        elif cycle in 'prior':\n",
    "            member_dir = 'ENF{:03d}'.format(int(member))\n",
    "            member_prefix = 'enf{:03d}'.format(int(member))\n",
    "    \n",
    "    return member_dir, member_prefix\n",
    "\n",
    "modelname = 'ARPS'\n",
    "microphys = 'ZVD'\n",
    "\n",
    "# From desired start and end times (UTC) get a range of datetimes and corresponding range of times in\n",
    "# seconds since model initial time\n",
    "timestamp_model_init = init_model_dict['timestamp_model_init']  # Start time of model corresponding to 0 s\n",
    "datetime_model_init = datetime.strptime(timestamp_model_init, '%Y%m%d%H%M%S')\n",
    "\n",
    "timestamp_start = init_model_dict['timestamp_model_start']  # Start time of desired time window\n",
    "timestamp_stop = init_model_dict['timestamp_model_stop']  # Stop time of desired time window\n",
    "datetime_start = datetime.strptime(timestamp_start, '%Y%m%d%H%M%S')\n",
    "datetime_stop = datetime.strptime(timestamp_stop, '%Y%m%d%H%M%S')\n",
    "tintv = init_model_dict['model_dt']  # Interval in seconds for model output\n",
    "tintv_mean = init_model_dict['model_dt_mean'] # Interval in seconds for ensemble mean analysis\n",
    "\n",
    "datetime_range = CRMutils.get_datetime_range(datetime_start, datetime_stop, tintv)\n",
    "trange = CRMutils.modeltimes_from_datetimes(datetime_range, datetime_start=datetime_model_init)\n",
    "\n",
    "datetime_range_mean = CRMutils.get_datetime_range(datetime_start, datetime_stop, tintv_mean)\n",
    "trange_mean = CRMutils.modeltimes_from_datetimes(datetime_range_mean, datetime_start=datetime_model_init)\n",
    "\n",
    "#basedir = '/Volumes/scr_fast/Projects/VORTEXSE/simulations/ARPS/2016_IOP3/3DVAR/1km0331163DVARCA00005min180_3km030015min540'\n",
    "fileformat = init_model_dict['fileformat']\n",
    "expname = '1km453x453_033116_newse'\n",
    "basedir = init_model_dict['basedirname']\n",
    "member = 1 # 0 is for ensemble mean\n",
    "cycle = 'posterior'\n",
    "member_dir, member_prefix = get_ARPS_member_dir_and_prefix(member, cycle)\n",
    "member_absdir = os.path.join(basedir, expname, member_dir)\n",
    "trailer = ''\n",
    "nproc_x = 15\n",
    "nproc_y = 6\n",
    "\n",
    "if member == 0:\n",
    "    model_trange_sec = trange_mean\n",
    "    model_datetime_range = datetime_range_mean\n",
    "else:\n",
    "    model_trange_sec = trange\n",
    "    model_datetime_range = datetime_range\n",
    "    \n",
    "model_dict = init_model_dict.copy()\n",
    "\n",
    "model_dict['trange_member'] = trange\n",
    "model_dict['trange_mean'] = trange_mean\n",
    "model_dict['datetime_range_member'] = datetime_range\n",
    "model_dict['datetime_range_mean'] = datetime_range_mean\n",
    "\n",
    "\n",
    "if member == 0:\n",
    "    model_dict['trange'] = trange_mean\n",
    "    model_dict['datetime_range'] = datetime_range_mean\n",
    "else:\n",
    "    model_dict['trange'] = trange\n",
    "    model_dict['datetime_range'] = datetime_range\n",
    "    \n",
    "print(model_datetime_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ARPS grid\n",
    "# Get file path for grdbas file (note that call to read_grid handles the reading of the individual patches)\n",
    "# If the grdbas file doesn't exist, fall back to a history file\n",
    "load_pkl = True\n",
    "pkl_dir = '/depot/dawson29/data/Projects/VORTEXSE/vortexse_enkf_dsd_study/data/model_data/pkl'\n",
    "pkl_file = '{}_grid_dict.pkl'.format(casedate)\n",
    "pkl_path = os.path.join(pkl_dir, pkl_file)\n",
    "\n",
    "grdbas_path = arps_read.get_file_path(member_absdir, member_prefix, fileformat, filetype='grdbas')\n",
    "patch_x = 1\n",
    "patch_y = 1\n",
    "grdbas_path_test = arps_read.add_patch_number(grdbas_path, patch_x, patch_y)\n",
    "\n",
    "if not os.path.exists(grdbas_path_test):\n",
    "    print(\"grdbas file doesn't exist, trying a history file!\")\n",
    "    grdbas_path = arps_read.get_file_path(member_absdir, member_prefix, fileformat, time=model_trange_sec[0], \n",
    "                                          filetype='history')\n",
    "    grdbas_path_test = arps_read.add_patch_number(grdbas_path, patch_x, patch_y)\n",
    "\n",
    "    print(grdbas_path_test)\n",
    "    print(os.path.exists(grdbas_path_test))\n",
    "\n",
    "if not load_pkl:\n",
    "    # Read in grid information\n",
    "    grid_dict = arps_read.readarpsgrid(grdbas_path, nproc_x=nproc_x, nproc_y=nproc_y)\n",
    "    # Get map projection information\n",
    "\n",
    "    ctrlat, ctrlon, trulat1, trulat2, trulon = arps_read.readarpsmap(grdbas_path, nproc_x=nproc_x, nproc_y=nproc_y)\n",
    "    grid_dict['ctrlat'] = ctrlat\n",
    "    grid_dict['ctrlon'] = ctrlon\n",
    "    grid_dict['trulat1'] = trulat1\n",
    "    grid_dict['trulat2'] = trulat2\n",
    "    grid_dict['trulon'] = trulon\n",
    "    # Dump grid dictonary to pickle file\n",
    "    with open(pkl_path, 'wb') as pkl_file_obj:\n",
    "        pickle.dump(grid_dict, pkl_file_obj)\n",
    "else:\n",
    "    with open(pkl_path, 'rb') as pkl_file_obj:\n",
    "        grid_dict = pickle.load(pkl_file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T00:15:51.301538Z",
     "start_time": "2019-09-10T00:15:51.240282Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get map projection information and create a Basemap instance\n",
    "# TODO: convert to use cartopy!\n",
    "dx = grid_dict['dx']\n",
    "dy = grid_dict['dy']\n",
    "nx = grid_dict['nx']\n",
    "ny = grid_dict['ny']\n",
    "trulat1 = grid_dict['trulat1']\n",
    "trulat2 = grid_dict['trulat2']\n",
    "ctrlat = grid_dict['ctrlat']\n",
    "ctrlon = grid_dict['ctrlon']\n",
    "\n",
    "\n",
    "mapwidth = nx * dx\n",
    "mapheight = ny * dy\n",
    "\n",
    "bgmap = Basemap(projection='lcc', width=mapwidth, height=mapheight, lat_1=trulat1,\n",
    "                lat_2=trulat2, lat_0=ctrlat, lon_0=ctrlon, resolution='h',\n",
    "                area_thresh=10., suppress_ticks=False)\n",
    "\n",
    "# Put the basemap instance into the grid_dict\n",
    "grid_dict['bgmap'] = bgmap\n",
    "\n",
    "dis_dict = sim.get_dis_locs_relative_to_radar(init_dis_dict, radar_dict)\n",
    "# Find coordinates of PIPS stations in the model\n",
    "dis_dict = sim.get_dis_locs_arps_real_grid(dis_dict, grid_dict)\n",
    "\n",
    "\n",
    "coord_array = np.array(dis_dict['dmodcrdlist'])\n",
    "\n",
    "print(coord_array) \n",
    "print(coord_array.shape) \n",
    "print(coord_array[0]) \n",
    "# coord_array = coord_array.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the model fields from previously generated netCDF files\n",
    "num_members = 36\n",
    "member_range = range(1, num_members+1)\n",
    "\n",
    "var_ds_list = []\n",
    "for member in member_range:\n",
    "    member_dir, member_prefix = get_ARPS_member_dir_and_prefix(member, cycle)\n",
    "    ncfilename = member_prefix + '_fields.nc'\n",
    "    ncdir = '/depot/dawson29/data/Projects/VORTEXSE/vortexse_enkf_dsd_study/data/model_data/nc'\n",
    "    ncfilepath = os.path.join(ncdir, ncfilename)\n",
    "\n",
    "    # Open the Dataset\n",
    "    var_ds = xr.open_dataset(ncfilepath)\n",
    "    var_ds_list.append(var_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T00:21:21.292004Z",
     "start_time": "2019-09-10T00:21:18.969687Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in PIPS data\n",
    "\n",
    "print(dis_dict.keys())\n",
    "\n",
    "dis_dir = dis_dict['dis_dir']\n",
    "dis_filenames = dis_dict['disfilenames']\n",
    "dis_names = dis_dict['dis_names']\n",
    "\n",
    "conv_df_dict = {}\n",
    "parsivel_df_dict = {}\n",
    "vd_matrix_da_dict = {}\n",
    "\n",
    "for dis_filename, dis_name in zip(dis_filenames, dis_names):\n",
    "    dis_filepath = os.path.join(dis_dir, dis_filename)\n",
    "    print(\"Reading {}\".format(dis_filepath))\n",
    "    conv_df, parsivel_df, vd_matrix_da = pips_io.read_PIPS(dis_filepath, starttimestamp=timestamp_start,\n",
    "                                                           stoptimestamp=timestamp_stop)\n",
    "    # Calculate some additional thermodynamic quantities and add to the conventional data DataFrame\n",
    "    conv_df = pips.calc_thermo(conv_df)\n",
    "    conv_df_dict[dis_name] = conv_df\n",
    "    parsivel_df_dict[dis_name] = parsivel_df\n",
    "    vd_matrix_da_dict[dis_name] = vd_matrix_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T00:21:31.319214Z",
     "start_time": "2019-09-10T00:21:30.987804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resample PIPS data to a 60-s interval\n",
    "conv_rs_df_dict = {}\n",
    "parsivel_rs_df_dict = {}\n",
    "vd_matrix_rs_da_dict = {}\n",
    "for dis_name in dis_names:\n",
    "    # Conventional data\n",
    "    conv_df = conv_df_dict[dis_name]\n",
    "    datetime_range_onesec = conv_df.index.to_pydatetime()\n",
    "    sec_offset = pips.get_offset_seconds(datetime_range_onesec)\n",
    "    conv_rs_df_dict[dis_name] = pips.resample_conv('PIPS', 60., sec_offset, conv_df, gusts=True)\n",
    "    \n",
    "    # Parsivel 10-s derived fields\n",
    "    parsivel_df = parsivel_df_dict[dis_name]\n",
    "    datetime_range_tensec = parsivel_df.index.to_pydatetime()\n",
    "    sec_offset = pips.get_offset_seconds(datetime_range_tensec)\n",
    "    print(sec_offset)\n",
    "    parsivel_rs_df_dict[dis_name] = pips.resample_parsivel(60., parsivel_df)\n",
    "    \n",
    "    # Parsivel V-D matrix\n",
    "    vd_matrix_da = vd_matrix_da_dict[dis_name]\n",
    "    vd_matrix_rs_da_dict[dis_name] = pips.resample_vd_matrix(60., vd_matrix_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T00:54:30.465142Z",
     "start_time": "2019-09-10T00:54:30.032651Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute N(D) for the observed PIPS DSDs after some QC\n",
    "min_diameters = pp.parsivel_parameters['min_diameter_bins_mm']\n",
    "mid_diameters = pp.parsivel_parameters['avg_diameter_bins_mm']\n",
    "max_diameters = pp.parsivel_parameters['max_diameter_bins_mm']\n",
    "mid_fallspeeds = pp.parsivel_parameters['avg_fallspeed_bins_mps']\n",
    "empirical_fallspeed = pips.calc_empirical_fallspeed(mid_diameters)\n",
    "fallspeed_spectrum = pips.calc_fallspeed_spectrum(mid_diameters, mid_fallspeeds, use_measured_fallspeed=True)\n",
    "\n",
    "ND_PIPS_dict = {}\n",
    "logND_PIPS_dict = {}\n",
    "PSD_datetimes_rs_PIPS_dict = {}\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    vd_matrix_rs_da = vd_matrix_rs_da_dict[dis_name]\n",
    "    vd_matrix_rs_QC = pqc.strongwindQC(vd_matrix_rs_da)\n",
    "    vd_matrix_rs_QC = pqc.rainonlyQC(vd_matrix_rs_QC)\n",
    "    # Calculate ND and log10(ND)\n",
    "    ND = pips.calc_ND(vd_matrix_rs_QC.where(vd_matrix_rs_QC > 0.0), fallspeed_spectrum, 60.)\n",
    "    logND = np.log10(ND)\n",
    "    logND = logND.where(logND > -1.0)\n",
    "    \n",
    "    ND_PIPS_dict[dis_name] = ND\n",
    "    logND_PIPS_dict[dis_name] = logND\n",
    "    # Get times for PIPS transects as numpy arrays of python datetime objects\n",
    "    PSD_datetimes_rs = pips.get_PSD_datetimes(vd_matrix_rs_da)\n",
    "    PSD_datetimes_rs_dict = pips.get_PSD_time_bins(PSD_datetimes_rs)\n",
    "    PSD_datetimes_rs_PIPS_dict[dis_name] = PSD_datetimes_rs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T01:00:30.231851Z",
     "start_time": "2019-09-10T01:00:30.031516Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute some radar and DSD parameters from DSD\n",
    "import pyPIPS.polarimetric as pol\n",
    "wavelength = 10.7\n",
    "scatt_file = '/home/dawson29/Projects/pyPIPS/tmatrix/S-Band/SCTT_RAIN_fw100.dat'\n",
    "bin_width = pp.parsivel_parameters['max_diameter_bins_mm'] - pp.parsivel_parameters['min_diameter_bins_mm']\n",
    "dualpol_PIPS_dict = {}\n",
    "ZDR_PIPS_dict = {}\n",
    "dBZ_PIPS_dict = {}\n",
    "D0_PIPS_dict = {}\n",
    "for dis_name in dis_names:\n",
    "    dBZ_PIPS = dsd.calc_dBZ_from_bins(ND_PIPS_dict[dis_name])\n",
    "    dBZ_PIPS = dBZ_PIPS.where(dBZ_PIPS > -np.inf)\n",
    "    dBZ_PIPS_dict[dis_name] = dBZ_PIPS\n",
    "    D0_PIPS = dsd.calc_D0_bin(ND_PIPS_dict[dis_name])\n",
    "    D0_PIPS_dict[dis_name] = D0_PIPS\n",
    "    pol_PIPS_dict = pol.calpolrain(wavelength, scatt_file, ND_PIPS_dict[dis_name], bin_width)\n",
    "    dualpol_PIPS_dict[dis_name] = pol_PIPS_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate the model variables to the PIPS locations\n",
    "x_coords = [a[0] for a in dis_dict['dmodloclist']]\n",
    "y_coords = [a[1] for a in dis_dict['dmodloclist']]\n",
    "\n",
    "x_coords_da = xr.DataArray(x_coords, coords=[dis_names], dims=['PIPS'])\n",
    "y_coords_da = xr.DataArray(y_coords, coords=[dis_names], dims=['PIPS'])\n",
    "\n",
    "var_ds_interp_list = []\n",
    "for i, member in enumerate(member_range):\n",
    "    var_ds = var_ds_list[i]\n",
    "    var_ds_interp = var_ds.interp(xc=x_coords_da, yc=y_coords_da)\n",
    "    var_ds_interp_list.append(var_ds_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:31:24.697885Z",
     "start_time": "2019-09-10T03:31:24.611392Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute raw model DSD at PIPS locations\n",
    "rhor = 1000.\n",
    "cr = np.pi / 6. * rhor\n",
    "\n",
    "qr_model_PIPS_list = []\n",
    "nr_model_PIPS_list = []\n",
    "zr_model_PIPS_list = []\n",
    "rho_model_PIPS_list = []\n",
    "alphar_model_PIPS_list = []\n",
    "N0r_model_PIPS_list = []\n",
    "lamdar_model_PIPS_list = []\n",
    "\n",
    "for var_ds_interp in var_ds_interp_list:\n",
    "    p_interp = var_ds_interp['p']\n",
    "    pt_interp = var_ds_interp['pt']\n",
    "    qv_interp = var_ds_interp['qv']\n",
    "    qr_model_PIPS = var_ds_interp['qr']\n",
    "    nr_model_PIPS = var_ds_interp['nr']\n",
    "    zr_model_PIPS = var_ds_interp['zr']\n",
    "    rho_model_PIPS = thermo.calrho(p_interp, pt_interp, qv_interp)\n",
    "\n",
    "    # Shape parameter\n",
    "    # alphar_atPIPS = dualpol.solve_alpha_iter(rhoa_atPIPS, mu, qr_atPIPS, nr_atPIPS, zr_atPIPS, rhor)\n",
    "    alphar_model_PIPS = dsd.solve_alpha(rho_model_PIPS, cr, qr_model_PIPS, nr_model_PIPS, zr_model_PIPS)\n",
    "    # Intercept parameter\n",
    "    N0r_model_PIPS = dsd.calc_N0_gamma(rho_model_PIPS, qr_model_PIPS, nr_model_PIPS, cr, alphar_model_PIPS)\n",
    "    # Slope parameter\n",
    "    lamdar_model_PIPS = dsd.calc_lamda_gamma(rho_model_PIPS, qr_model_PIPS, nr_model_PIPS, cr, alphar_model_PIPS)\n",
    "    \n",
    "    qr_model_PIPS_list.append(qr_model_PIPS)\n",
    "    nr_model_PIPS_list.append(nr_model_PIPS)\n",
    "    zr_model_PIPS_list.append(zr_model_PIPS)\n",
    "    rho_model_PIPS_list.append(rho_model_PIPS)\n",
    "    alphar_model_PIPS_list.append(alphar_model_PIPS)\n",
    "    N0r_model_PIPS_list.append(N0r_model_PIPS)\n",
    "    lamdar_model_PIPS_list.append(lamdar_model_PIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:31:28.342918Z",
     "start_time": "2019-09-10T03:31:28.278823Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save for posterity, now part of var_ds dataset above\n",
    "\n",
    "# EDIT: Temp fix until I get the above functions to work properly with xarray\n",
    "# convert alphar, N0r, lamdar back to DataArrays\n",
    "\n",
    "alphar_model_allPIPS_da_list = []\n",
    "N0r_model_allPIPS_da_list = []\n",
    "lamdar_model_allPIPS_da_list = []\n",
    "\n",
    "for alphar_model_PIPS, qr_model_PIPS, N0r_model_PIPS, lamdar_model_PIPS in \\\n",
    "    zip(alphar_model_PIPS_list, qr_model_PIPS_list, N0r_model_PIPS_list, lamdar_model_PIPS_list):\n",
    "\n",
    "    alphar_model_allPIPS_da = xr.DataArray(alphar_model_PIPS,\n",
    "                                        coords={\n",
    "                                            'time': qr_model_PIPS['time'],\n",
    "                                            'PIPS': ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B']\n",
    "                                        },\n",
    "                                        dims=['time', 'PIPS'])\n",
    "    N0r_model_allPIPS_da = xr.DataArray(N0r_model_PIPS,\n",
    "                                        coords={\n",
    "                                            'time': qr_model_PIPS['time'],\n",
    "                                            'PIPS': ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B']\n",
    "                                        },\n",
    "                                        dims=['time', 'PIPS'])\n",
    "    lamdar_model_allPIPS_da = xr.DataArray(lamdar_model_PIPS,\n",
    "                                        coords={\n",
    "                                            'time': qr_model_PIPS['time'],\n",
    "                                            'PIPS': ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B']\n",
    "                                        },\n",
    "                                        dims=['time', 'PIPS'])\n",
    "    \n",
    "    alphar_model_allPIPS_da_list.append(alphar_model_allPIPS_da)\n",
    "    N0r_model_allPIPS_da_list.append(N0r_model_allPIPS_da)\n",
    "    lamdar_model_allPIPS_da_list.append(lamdar_model_allPIPS_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate the PIPS DSD to the model times\n",
    "\n",
    "ND_interp_to_model_times_dict = {}\n",
    "logND_interp_to_model_times_dict = {}\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    \n",
    "    ND = ND_PIPS_dict[dis_name]\n",
    "    # Rename time dimension to match\n",
    "    ND = ND.rename({'time': 'time'})\n",
    "    ND_interp_model = ND.interp_like(var_ds_interp['ND'])\n",
    "    \n",
    "    # Now recompute logND from new interpolated ND\n",
    "    logND_interp_model = np.log10(ND_interp_model)\n",
    "    logND_interp_model = logND_interp_model.where(logND_interp_model > -np.inf)\n",
    "    \n",
    "    ND_interp_to_model_times_dict[dis_name] = ND_interp_model\n",
    "    logND_interp_to_model_times_dict[dis_name] = logND_interp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some radar and DSD parameters from observed DSD that was just interpolated to model times\n",
    "wavelength = 10.7\n",
    "scatt_file = '/home/dawson29/Projects/pyPIPS/tmatrix/S-Band/SCTT_RAIN_fw100.dat'\n",
    "bin_width = pp.parsivel_parameters['max_diameter_bins_mm'] - pp.parsivel_parameters['min_diameter_bins_mm']\n",
    "dBZ_PIPS_interp_to_model_times_dict = {}\n",
    "D0_PIPS_interp_to_model_times_dict = {}\n",
    "ZDR_PIPS_interp_to_model_times_dict = {}\n",
    "dualpol_PIPS_interp_to_model_times_dict = {}\n",
    "for dis_name in dis_names:\n",
    "    dBZ_PIPS_interp = dsd.calc_dBZ_from_bins(ND_interp_to_model_times_dict[dis_name])\n",
    "    dBZ_PIPS_interp = dBZ_PIPS_interp.where(dBZ_PIPS_interp > -np.inf)\n",
    "    dBZ_PIPS_interp_to_model_times_dict[dis_name] = dBZ_PIPS_interp\n",
    "    D0_PIPS_interp = dsd.calc_D0_bin(ND_interp_to_model_times_dict[dis_name])\n",
    "    D0_PIPS_interp_to_model_times_dict[dis_name] = D0_PIPS_interp\n",
    "    print(ND_interp_to_model_times_dict[dis_name].values.shape)\n",
    "    pol_PIPS_dict = pol.calpolrain(wavelength, scatt_file, ND_interp_to_model_times_dict[dis_name], bin_width)\n",
    "    dualpol_PIPS_interp_to_model_times_dict[dis_name] = pol_PIPS_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot observed DSD meteograms interpolated to model times\n",
    "# Get PSD times valid at the model times\n",
    "PSD_datetimes_model = pips.get_PSD_datetimes(var_ds, dim_name='time')\n",
    "PSD_datetimes_model_dict = pips.get_PSD_time_bins(PSD_datetimes_model)\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "# Prepare axis parameters\n",
    "# We'll use the model times for the boundaries of the x-axis\n",
    "timelimits = [datetime_range[0], datetime_range[-1]]\n",
    "diamlimits = [0.0, 9.0]\n",
    "diamytick = 1.0\n",
    "DSDtype = 'observed'\n",
    "locator = dates.MinuteLocator(byminute=[0,15,30,45])\n",
    "minorlocator = dates.MinuteLocator(byminute=range(0,60,5))\n",
    "dateformat = '%H:%M'\n",
    "formatter = dates.DateFormatter(dateformat)\n",
    "\n",
    "axparams = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "            'minorxlocator': minorlocator,\n",
    "            'axeslimits': [timelimits, diamlimits],\n",
    "            'majorylocator': ticker.MultipleLocator(base=diamytick),\n",
    "            'axeslabels': [None, 'D (mm)']}\n",
    "\n",
    "# Ok, now we should have everything ready to go to plot the meteograms.\n",
    "# Let'er rip!\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND = logND_interp_to_model_times_dict[dis_name]\n",
    "    D0 = D0_PIPS_interp_to_model_times_dict[dis_name] * 1000. # Get to mm again\n",
    "    dBZ = dBZ_PIPS_interp_to_model_times_dict[dis_name]\n",
    "    ZDR = dualpol_PIPS_interp_to_model_times_dict[dis_name]['ZDR']\n",
    "    \n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'D_0': D0, 'dBZ': dBZ, 'ZDR': ZDR}\n",
    "    \n",
    "    dis_plot_name = dis_name + '_interp_to_model_' + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_plotdir, axparams, disvars, close_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute N(D) from the raw model parameters at original model times\n",
    "\n",
    "ND_model_raw_PIPS_dict_list = []\n",
    "ND_model_raw_combined_list = []\n",
    "logND_model_raw_PIPS_dict_list = []\n",
    "\n",
    "for alphar_model_allPIPS_da, lamdar_model_allPIPS_da, N0r_model_allPIPS_da in \\\n",
    "        zip(alphar_model_allPIPS_da_list, lamdar_model_allPIPS_da_list, N0r_model_allPIPS_da_list):\n",
    "\n",
    "    ND_model_raw_PIPS_dict = {}\n",
    "    logND_model_raw_PIPS_dict = {}\n",
    "    for i, dis_name in enumerate(dis_names):\n",
    "        mid_diameters_da = vd_matrix_da_dict[dis_name]['diameter']\n",
    "        alphar_model_PIPS_da = alphar_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "        N0r_model_PIPS_da = N0r_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "        lamdar_model_PIPS_da = lamdar_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "#         if i == 0:\n",
    "#             print(mid_diameters_da, alphar_model_PIPS_da)\n",
    "        # Broadcast DSD parameter DataArrays to get everyone on the same dimensional page\n",
    "        mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da = \\\n",
    "            xr.broadcast(mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da)\n",
    "#         if i == 0:\n",
    "#             print(mid_diameters_da, alphar_model_PIPS_da)\n",
    "        # Transpose these DataArrays to get time as the first dimension\n",
    "        mid_diameters_da = mid_diameters_da.T\n",
    "        N0r_model_PIPS_da = N0r_model_PIPS_da.T\n",
    "        lamdar_model_PIPS_da = lamdar_model_PIPS_da.T\n",
    "        alphar_model_PIPS_da = alphar_model_PIPS_da.T\n",
    "\n",
    "        ND_model_raw_PIPS = dsd.calc_binned_DSD_from_params(N0r_model_PIPS_da, lamdar_model_PIPS_da, \n",
    "                                                            alphar_model_PIPS_da, mid_diameters_da)\n",
    "        logND_model_raw_PIPS = np.log10(ND_model_raw_PIPS)\n",
    "        logND_model_raw_PIPS = logND_model_raw_PIPS.where(logND_model_raw_PIPS > -np.inf)\n",
    "\n",
    "        ND_model_raw_PIPS_dict[dis_name] = ND_model_raw_PIPS\n",
    "        logND_model_raw_PIPS_dict[dis_name] = logND_model_raw_PIPS\n",
    "    \n",
    "    # Concat along PIPS dimension\n",
    "    ND_model_raw_list = [ND_model_raw_PIPS_dict[dis_name].reset_coords(drop=True) \n",
    "                         for dis_name in dis_names]\n",
    "    ND_model_raw_combined = xr.concat(ND_model_raw_list, dim='PIPS')\n",
    "        \n",
    "    ND_model_raw_PIPS_dict_list.append(ND_model_raw_PIPS_dict)\n",
    "    logND_model_raw_PIPS_dict_list.append(logND_model_raw_PIPS_dict)\n",
    "    ND_model_raw_combined_list.append(ND_model_raw_combined)\n",
    "\n",
    "# Combine ND dataarrays along member dimension\n",
    "\n",
    "ND_model_raw_combined_da = xr.concat(ND_model_raw_combined_list, dim='member')\n",
    "\n",
    "print(ND_model_raw_combined_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logND_model_raw_combined_da = np.log10(ND_model_raw_combined_da)\n",
    "logND_model_raw_combined_da = logND_model_raw_combined_da.where(logND_model_raw_combined_da > -np.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute some radar and DSD parameters from the raw model DSDs (interpolated to PIPS locations but not times)\n",
    "dBZ_raw_model_dict_list = []\n",
    "D0_raw_model_dict_list = []\n",
    "ZDR_raw_model_dict_list = []\n",
    "dualpol_raw_model_dict_list = []\n",
    "\n",
    "for ND_model_raw_PIPS_dict in ND_model_raw_PIPS_dict_list:\n",
    "    dBZ_raw_model_dict = {}\n",
    "    D0_raw_model_dict = {}\n",
    "    ZDR_raw_model_dict = {}\n",
    "    dualpol_raw_model_dict = {}\n",
    "    for dis_name in dis_names:\n",
    "        dBZ_raw_model = dsd.calc_dBZ_from_bins(ND_model_raw_PIPS_dict[dis_name])\n",
    "        dBZ_raw_model = dBZ_raw_model.where(dBZ_raw_model > -np.inf)\n",
    "        dBZ_raw_model_dict[dis_name] = dBZ_raw_model\n",
    "        D0_raw_model = dsd.calc_D0_bin(ND_model_raw_PIPS_dict[dis_name])\n",
    "        D0_raw_model_dict[dis_name] = D0_raw_model\n",
    "        pol_raw_model_dict = pol.calpolrain(wavelength, scatt_file, ND_model_raw_PIPS_dict[dis_name], bin_width)\n",
    "        dualpol_raw_model_dict[dis_name] = pol_raw_model_dict\n",
    "    \n",
    "    dBZ_raw_model_dict_list.append(dBZ_raw_model_dict)\n",
    "    D0_raw_model_dict_list.append(D0_raw_model_dict)\n",
    "    ZDR_raw_model_dict_list.append(ZDR_raw_model_dict)\n",
    "    dualpol_raw_model_dict_list.append(dualpol_raw_model_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined DataArray for all the ensemble members and then convert to a DataFrame for use in seaborn\n",
    "PIPS_time_range = {\n",
    "    'PIPS1A': [datetime(2016, 3, 31, 22, 5), datetime(2016, 3, 31, 23, 20)],\n",
    "    'PIPS1B': [datetime(2016, 3, 31, 22, 0), datetime(2016, 3, 31, 23, 25)],\n",
    "    'PIPS2A': [datetime(2016, 3, 31, 22, 20), datetime(2016, 3, 31, 23, 10)],\n",
    "    'PIPS2B': [datetime(2016, 3, 31, 21, 45), datetime(2016, 3, 31, 23, 35)]\n",
    "}\n",
    "\n",
    "\n",
    "PIPS_to_plot = 'PIPS2B'\n",
    "\n",
    "\n",
    "# D0\n",
    "D0_raw_model_list = [D0_raw_model_dict[PIPS_to_plot].reset_coords(drop=True) \n",
    "                            for D0_raw_model_dict in D0_raw_model_dict_list]\n",
    "D0_raw_model_combined = xr.concat(D0_raw_model_list, dim='member')\n",
    "D0_raw_model_combined_df = D0_raw_model_combined.to_dataframe(name='D0')\n",
    "\n",
    "# Reflectivity\n",
    "\n",
    "dBZ_raw_model_list = [dBZ_raw_model_dict[PIPS_to_plot].reset_coords(drop=True) \n",
    "                            for dBZ_raw_model_dict in dBZ_raw_model_dict_list]\n",
    "dBZ_raw_model_combined = xr.concat(dBZ_raw_model_list, dim='member')\n",
    "dBZ_raw_model_combined_df = dBZ_raw_model_combined.to_dataframe(name='dBZ')\n",
    "\n",
    "# ZDR\n",
    "\n",
    "ZDR_raw_model_list = [dualpol_raw_model_dict[PIPS_to_plot]['ZDR'].reset_coords(drop=True) \n",
    "                            for dualpol_raw_model_dict in dualpol_raw_model_dict_list]\n",
    "ZDR_raw_model_combined = xr.concat(ZDR_raw_model_list, dim='member')\n",
    "ZDR_raw_model_combined_df = ZDR_raw_model_combined.to_dataframe(name='ZDR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a timeseries of D0 with confidence intervals from the model ensemble\n",
    "import seaborn as sns\n",
    "plotdir = '/depot/dawson29/data/Projects/VORTEXSE/vortexse_enkf_dsd_study/plots'\n",
    "meteogram_plotdir = os.path.join(plotdir, 'meteograms')\n",
    "if not os.path.exists(meteogram_plotdir):\n",
    "    os.makedirs(meteogram_plotdir)\n",
    "\n",
    "PSD_datetimes_model = pips.get_PSD_datetimes(var_ds, dim_name='time')\n",
    "PSD_datetimes_model_dict = pips.get_PSD_time_bins(PSD_datetimes_model)\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "D0_obs = D0_PIPS_interp_to_model_times_dict[PIPS_to_plot] * 1000. # Get to mm again\n",
    "D0_raw_model_combined_df_test = D0_raw_model_combined_df.copy() * 1000.\n",
    "D0_raw_model_combined_df_test.reset_index(inplace=True)\n",
    "g = sns.relplot(x=\"time\", y=\"D0\", kind=\"line\", ci=\"sd\", data=D0_raw_model_combined_df_test, label='Model')\n",
    "g.fig.set_size_inches(8., 3., forward = True)\n",
    "g.fig.autofmt_xdate()\n",
    "g.set_ylabels(r'$D_0$ (mm)')\n",
    "g.ax.plot(PSDmidtimes, D0_obs, 'r', label='Obs')\n",
    "plt.legend(loc='best')\n",
    "g.ax.set_xlim(PIPS_time_range[PIPS_to_plot])\n",
    "\n",
    "figname = '{}_model_obs_D0.png'.format(PIPS_to_plot)\n",
    "figpath = os.path.join(meteogram_plotdir, figname)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reflectivity\n",
    "dBZ_obs = dBZ_PIPS_interp_to_model_times_dict[PIPS_to_plot]\n",
    "dBZ_raw_model_combined_df_test = dBZ_raw_model_combined_df.copy()\n",
    "dBZ_raw_model_combined_df_test.reset_index(inplace=True)\n",
    "g = sns.relplot(x=\"time\", y=\"dBZ\", kind=\"line\", ci=\"sd\", data=dBZ_raw_model_combined_df_test, label='Model')\n",
    "g.fig.set_size_inches(8., 3., forward = True)\n",
    "g.fig.autofmt_xdate()\n",
    "g.set_ylabels(r'Reflectivity (dBZ)')\n",
    "g.ax.plot(PSDmidtimes, dBZ_obs, 'r', label='Obs')\n",
    "plt.legend(loc='best')\n",
    "g.ax.set_xlim(PIPS_time_range[PIPS_to_plot])\n",
    "\n",
    "figname = '{}_model_obs_dBZ.png'.format(PIPS_to_plot)\n",
    "figpath = os.path.join(meteogram_plotdir, figname)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZDR\n",
    "ZDR_obs = dualpol_PIPS_interp_to_model_times_dict[PIPS_to_plot]['ZDR']\n",
    "ZDR_raw_model_combined_df_test = ZDR_raw_model_combined_df.copy()\n",
    "ZDR_raw_model_combined_df_test.reset_index(inplace=True)\n",
    "g = sns.relplot(x=\"time\", y=\"ZDR\", kind=\"line\", ci=\"sd\", data=ZDR_raw_model_combined_df_test, label='Model')\n",
    "g.fig.set_size_inches(8., 3., forward = True)\n",
    "g.fig.autofmt_xdate()\n",
    "g.set_ylabels(r'$Z_{DR}$ (dB)')\n",
    "g.ax.plot(PSDmidtimes, ZDR_obs, 'r', label='Obs')\n",
    "plt.legend(loc='best')\n",
    "g.ax.set_xlim(PIPS_time_range[PIPS_to_plot])\n",
    "\n",
    "figname = '{}_model_obs_ZDR.png'.format(PIPS_to_plot)\n",
    "figpath = os.path.join(meteogram_plotdir, figname)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the raw model DSDs (interpolated to PIPS locations but not the times)\n",
    "\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "for member, logND_model_raw_PIPS_dict in enumerate(logND_model_raw_PIPS_dict_list):\n",
    "    for i, dis_name in enumerate(dis_names):\n",
    "        logND = logND_model_raw_PIPS_dict[dis_name]\n",
    "        logND = logND.where(logND > -1.0)\n",
    "        D0 = D0_raw_model_dict[dis_name] * 1000. # Get to mm again\n",
    "        dBZ = dBZ_raw_model_dict[dis_name]\n",
    "        ZDR = dualpol_raw_model_dict[dis_name]['ZDR']\n",
    "        disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "                   'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'D_0': D0, 'dBZ': dBZ, 'ZDR': ZDR}\n",
    "        dis_plot_name = dis_name + '_raw_model_member_{:02d}_'.format(member+1) + DSDtype\n",
    "        PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_plotdir, axparams, disvars, close_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the mean raw model DSDs (interpolated to PIPS locations but not the times)\n",
    "\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND_all = logND_model_raw_combined_da.isel(PIPS=i)\n",
    "    logND_mean = logND_all.mean(dim='member')\n",
    "    logND_mean = logND_mean.where(logND_mean > -1.0)\n",
    "#     D0 = D0_raw_model_dict[dis_name] * 1000. # Get to mm again\n",
    "#     dBZ = dBZ_raw_model_dict[dis_name]\n",
    "#     ZDR = dualpol_raw_model_dict[dis_name]['ZDR']\n",
    "#     disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "#                'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'D_0': D0, 'dBZ': dBZ, 'ZDR': ZDR}\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND_mean.T}\n",
    "    dis_plot_name = dis_name + '_raw_model_member_mean_' + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_plotdir, axparams, disvars, close_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compute sampled PSDs from the model\n",
    "DSDtype = 'observed'\n",
    "# Now plot the sampled model DSD\n",
    "\n",
    "sampling_interval = 60.\n",
    "sampling_length = pp.parsivel_parameters['sensor_length_mm'] / 1000. # To m\n",
    "sampling_width = pp.parsivel_parameters['sensor_width_mm'] / 1000. # To m\n",
    "\n",
    "Dmax = 9.\n",
    "Dmax_index = np.searchsorted(mid_diameters, Dmax, side='right')\n",
    "# print(Dmax_index)\n",
    "mid_diameters_trunc = np.array(mid_diameters[:Dmax_index+1]) / 1000.\n",
    "min_diameters_trunc = np.array(min_diameters[:Dmax_index+1]) / 1000.\n",
    "max_diameters_trunc = np.array(max_diameters[:Dmax_index+1]) / 1000.\n",
    "\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "D0_sample_dict_list = []\n",
    "ND_sample_dict_list = []\n",
    "dBZ_sample_dict_list = []\n",
    "dualpol_sample_dict_list = []\n",
    "\n",
    "for member, var_ds_interp in enumerate(var_ds_interp_list):\n",
    "\n",
    "    D0_sample_dict = {}\n",
    "    ND_sample_dict = {}\n",
    "    dBZ_sample_dict = {}\n",
    "    dualpol_sample_dict = {}\n",
    "\n",
    "    for dis_name in dis_names:\n",
    "        nr_model = var_ds_interp['nr'].loc[dict(PIPS=dis_name)].values\n",
    "        lamdar_model = var_ds_interp['lamdar'].loc[dict(PIPS=dis_name)].values\n",
    "        alphar_model = var_ds_interp['alphar'].loc[dict(PIPS=dis_name)].values\n",
    "        rho_model = var_ds_interp['rho'].loc[dict(PIPS=dis_name)].values\n",
    "\n",
    "        # print(mid_diameters_trunc.shape)\n",
    "        Vtr = pips.calc_empirical_fallspeed(mid_diameters_trunc * 1000., correct_rho=True, rho=rho_model)\n",
    "\n",
    "        Vtr = Vtr.T\n",
    "    #     print(Vtr[0])\n",
    "    #     print(Vtr.shape)\n",
    "    #     print(mid_diameters_trunc.shape)\n",
    "        ND_samp_series = np.zeros((np.size(PSDmidtimes), np.size(mid_diameters_trunc)))\n",
    "\n",
    "    #     print(ND_samp_series.shape)\n",
    "    #     print(nr_model[0])\n",
    "        # Nc_bin_tmp2 = np.zeros((np.size(N0r), np.size(D[:Dmax_index+1])))\n",
    "        # Nc_bin2 = np.zeros((np.size(np.array(sampling_times)), np.size(D[:Dmax_index+1])))\n",
    "\n",
    "        all_valid = (not np.isnan(lamdar_model[0]) and (not np.isnan(alphar_model[0])) and (not np.isnan(nr_model[0])))\n",
    "        if all_valid:\n",
    "            # Special treatment for first sampling time. Just assume DSD valid at that time was constant for the previous \n",
    "            # sampling interval\n",
    "            sample_dict = sim.create_random_gamma_DSD(nr_model[0], lamdar_model[0], \n",
    "                                                      alphar_model[0], Vtr[0], sampling_length, \n",
    "                                                      sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                                      max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                                      remove_margins=True, rhocorrect=True, rho=rho_model[0], verbose=False)\n",
    "\n",
    "\n",
    "            ND_sample = sample_dict['ND']\n",
    "            pcount_binned_sample = sample_dict['pcount_binned']\n",
    "        #     print(ND_sample.shape)\n",
    "        #     print(ND_samp_series.shape)\n",
    "            ND_samp_series[0, :] = 1.e-3*ND_sample\n",
    "            # Nc_bin_tmp2[0, :] = 1.e-3*ND_sample\n",
    "            # Nc_bin2[0, :] = Nc_bin_tmp2[0, :]\n",
    "\n",
    "\n",
    "        pcount_binned_samples = []\n",
    "        for index in range(np.size(PSDmidtimes[1:])):\n",
    "            all_valid = (not np.isnan(lamdar_model[index]) \n",
    "                         and (not np.isnan(alphar_model[index]))\n",
    "                         and (not np.isnan(nr_model[index])))\n",
    "            # print('nr = ', nr_model[index], 'lamdar = ', lamdar_model[index], 'alphar = ', alphar_model[index])\n",
    "            if all_valid:\n",
    "                sample_dict = sim.create_random_gamma_DSD(nr_model[index], lamdar_model[index], \n",
    "                                                          alphar_model[index], Vtr[index], sampling_length, \n",
    "                                                          sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                                          max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                                          remove_margins=True, rhocorrect=True, rho=rho_model[index], verbose=False)\n",
    "                ND_sample = sample_dict['ND']\n",
    "                pcount_binned_samples.append(sample_dict['pcount_binned'])\n",
    "                ND_samp_series[index, :] = 1.e-3*ND_sample\n",
    "            else:\n",
    "                pcount_binned_samples.append(np.zeros(np.size(mid_diameters_trunc)+1))\n",
    "                #pcount_binned_samples.append(np.zeros_like(sample_dict['pcount_binned']))\n",
    "\n",
    "        pcount_binned_samples = np.array(pcount_binned_samples)\n",
    "\n",
    "        ND_samp_da = xr.DataArray(ND_samp_series,\n",
    "                                         coords={'time': PSD_datetimes_model_dict['PSD_datetimes_edges'][:-1],\n",
    "                                                 'diameter': ('diameter_bin', mid_diameters_trunc * 1000.),\n",
    "                                                 'max_diameter': ('diameter_bin', max_diameters_trunc * 1000.),\n",
    "                                                 'min_diameter': ('diameter_bin', min_diameters_trunc * 1000.)\n",
    "                                                },\n",
    "                                         dims=['time', 'diameter_bin'])\n",
    "\n",
    "        ND_samp_da = ND_samp_da.fillna(0.0)\n",
    "\n",
    "        # sampling_volumes_D = sim.calc_sampling_volumes_D(Vtr, Dr, Dmax, sampling_interval, sampling_area)\n",
    "        # for s, sample_index in enumerate(sample_indices[:-1]):\n",
    "        #     sample_index_end = sample_indices[s+1]\n",
    "        #     current_sample_indices = slice(sample_index, sample_index_end, None)\n",
    "        #     pcount_binned = np.sum(pcount_binned_samples[current_sample_indices], axis=0)\n",
    "        #     Nc_bin2[s+1, :] = 1.e-3*sim.calc_ND(pcount_binned, sampling_volumes_D, Dr, Dl, Dmax)\n",
    "        # #     Nc_bin2[s+1, :] = np.sum(Nc_bin_tmp2[current_sample_indices, :]*dt[current_sample_indices, None], axis = 0)/sampling_interval\n",
    "        # #     print \"s = \", s\n",
    "        # #     print \"sample time (beginning) = \", sampling_times[s]\n",
    "        # #     print \"sample time (end) = \", sampling_times[s+1]\n",
    "        # #     print \"dt[current_sample_indices] = \", dt[current_sample_indices]\n",
    "        # #     print \"Nc_bin_tmp = \", Nc_bin_tmp[current_sample_indices, :], dt[current_sample_indices]\n",
    "        # #     print \"Nc_bin = \", Nc_bin[s+1, :]\n",
    "\n",
    "        logND_samp_da = np.log10(ND_samp_da)\n",
    "        logND_samp_da = logND_samp_da.where(logND_samp_da > -1.0)\n",
    "\n",
    "        # Compute dBZ and D0 from the sampled DSD\n",
    "        dBZ_samp_model = dsd.calc_dBZ_from_bins(ND_samp_da)\n",
    "        dBZ_samp_model = dBZ_samp_model.where(dBZ_samp_model > -np.inf)\n",
    "        D0_samp_model = dsd.calc_D0_bin(ND_samp_da) * 1000. # Get to mm again\n",
    "        pol_samp_model_dict = pol.calpolrain(wavelength, scatt_file, ND_samp_da, bin_width)\n",
    "\n",
    "        dBZ_sample_dict[dis_name] = dBZ_samp_model\n",
    "        D0_sample_dict[dis_name] = D0_samp_model\n",
    "        dualpol_sample_dict[dis_name] = pol_samp_model_dict\n",
    "        ND_sample_dict[dis_name] = ND_samp_da\n",
    "\n",
    "        disvars = {'min_diameter': min_diameters[:Dmax_index+1], 'PSDstarttimes': PSDstarttimes,\n",
    "                   'PSDmidtimes': PSDmidtimes, 'logND': logND_samp_da.T, 'D_0': D0_samp_model, \n",
    "                   'dBZ': dBZ_samp_model, 'ZDR': pol_samp_model_dict['ZDR']}\n",
    "        dis_plot_name = dis_name + '_sampled_model_member_{:02d}_'.format(member+1) + DSDtype\n",
    "        PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_plotdir, axparams, disvars, close_fig=True)\n",
    "    \n",
    "    D0_sample_dict_list.append(D0_sample_dict)\n",
    "    ND_sample_dict_list.append(ND_sample_dict)\n",
    "    dBZ_sample_dict_list.append(dBZ_sample_dict)\n",
    "    dualpol_sample_dict_list.append(dualpol_sample_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some statistical comparison plots\n",
    "\n",
    "# Make some one-to-one plots of D0 (model) vs. D0 (disdrometer)\n",
    "\n",
    "yvals = pp.parsivel_parameters['avg_diameter_bins_mm']\n",
    "xvals = yvals\n",
    "\n",
    "color_list = ['r', 'orange', 'g', 'b']\n",
    "\n",
    "fig_all, ax_all = plt.subplots(figsize=(8,8))\n",
    "\n",
    "for d, dis_name in enumerate(dis_names):\n",
    "    obs = D0_PIPS_interp_to_model_times_dict[dis_name] * 1000.\n",
    "    mod = D0_raw_model_dict[dis_name] * 1000.\n",
    "    mod_sampled = D0_sample_dict[dis_name]\n",
    "    bias_mod = ((np.nansum(mod - obs)) / np.nansum(obs))\n",
    "    bias_mod_sampled = ((np.nansum(mod_sampled - obs)) / np.nansum(obs))\n",
    "    cc_mod = pd.DataFrame({'obs': obs, 'mod': mod}).corr().iloc[0, 1]\n",
    "    cc_mod_sampled = pd.DataFrame({'obs': obs, 'mod': mod_sampled}).corr().iloc[0, 1]\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.scatter(obs, mod, c=color_list[d], marker='*', label=dis_name+'_gamma')\n",
    "    plt.scatter(obs, mod_sampled, c=color_list[d], marker='+', alpha=0.75, label=dis_name+'_sampled')\n",
    "    ax_all.scatter(obs, mod, c=color_list[d], marker='*', label=dis_name+'_gamma')\n",
    "    ax_all.scatter(obs, mod_sampled, c=color_list[d], marker='+', alpha=0.75, label=dis_name+'_sampled')\n",
    "    ax.plot(xvals, yvals, lw=2, color='k')\n",
    "    ax.set_xlim(0.0, 6.0)\n",
    "    ax.set_ylim(0.0, 6.0)\n",
    "    ax.set_xlabel('Observed')\n",
    "    ax.set_ylabel('Model')\n",
    "    ax.text(0.6, 0.20, 'Bias (model): {:2.2f}'.format(bias_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.15, 'Cor. Coef. (model) {:2.3f}'.format(cc_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.10, 'Bias (model sampled): {:2.2f}'.format(bias_mod_sampled), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.05, 'Cor. Coef. (model sampled) {:2.3f}'.format(cc_mod_sampled), transform=ax.transAxes)\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "D0_raw_model_list = [v for k, v in D0_raw_model_dict.items()]\n",
    "D0_PIPS_list = [v for k, v in D0_PIPS_interp_to_model_times_dict.items()]\n",
    "D0_samp_model_list = [v for k, v in D0_sample_dict.items()]\n",
    "\n",
    "D0r_mod = xr.concat(D0_raw_model_list, dim='PIPS') * 1000.\n",
    "D0r_obs = xr.concat(D0_PIPS_list, dim='PIPS') * 1000.  \n",
    "D0r_mod_samp = xr.concat(D0_samp_model_list, dim='PIPS')\n",
    "\n",
    "bias_mod_all = ((np.nansum(D0r_mod - D0r_obs)) / np.nansum(D0r_obs))\n",
    "bias_mod_samp_all = ((np.nansum(D0r_mod_samp - D0r_obs)) / np.nansum(D0r_obs))\n",
    "cc_mod_all = pd.DataFrame({'obs': D0r_obs.stack(points=['PIPS', 'time']), \n",
    "                           'mod': D0r_mod.stack(points=['PIPS', 'time'])}).corr().iloc[0, 1]\n",
    "cc_mod_samp_all = pd.DataFrame({'obs': D0r_obs.stack(points=['PIPS', 'time']),\n",
    "                                'mod': D0r_mod_samp.stack(points=['PIPS', 'time'])}).corr().iloc[0, 1]\n",
    "\n",
    "ax_all.plot(xvals, yvals, lw=2, color='k')\n",
    "ax_all.set_xlim(0.0, 6.0)\n",
    "ax_all.set_ylim(0.0, 6.0)\n",
    "ax_all.set_xlabel('Observed')\n",
    "ax_all.set_ylabel('Model')\n",
    "ax_all.text(0.6, 0.20, 'Bias (model): {:2.2f}'.format(bias_mod_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.15, 'Cor. Coef. (model) {:2.3f}'.format(cc_mod_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.10, 'Bias (model sampled): {:2.2f}'.format(bias_mod_samp_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.05, 'Cor. Coef. (model sampled) {:2.3f}'.format(cc_mod_samp_all), transform=ax_all.transAxes)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some statistical comparison plots\n",
    "\n",
    "# Make some one-to-one plots of ZDR (model) vs. ZDR (disdrometer)\n",
    "\n",
    "yvals = pp.parsivel_parameters['avg_diameter_bins_mm']\n",
    "xvals = yvals\n",
    "\n",
    "color_list = ['r', 'orange', 'g', 'b']\n",
    "\n",
    "fig_all, ax_all = plt.subplots(figsize=(8,8))\n",
    "\n",
    "for d, dis_name in enumerate(dis_names):\n",
    "    obs = dualpol_PIPS_interp_to_model_times_dict[dis_name]['ZDR']\n",
    "    mod = dualpol_raw_model_dict[dis_name]['ZDR']\n",
    "    mod_sampled = dualpol_sample_dict[dis_name]['ZDR']\n",
    "    bias_mod = ((np.nansum(mod - obs)) / np.nansum(obs))\n",
    "    bias_mod_sampled = ((np.nansum(mod_sampled - obs)) / np.nansum(obs))\n",
    "    cc_mod = pd.DataFrame({'obs': obs, 'mod': mod}).corr().iloc[0, 1]\n",
    "    cc_mod_sampled = pd.DataFrame({'obs': obs, 'mod': mod_sampled}).corr().iloc[0, 1]\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.scatter(obs, mod, c=color_list[d], marker='*', label=dis_name+'_gamma')\n",
    "    plt.scatter(obs, mod_sampled, c=color_list[d], marker='+', alpha=0.75, label=dis_name+'_sampled')\n",
    "    ax_all.scatter(obs, mod, c=color_list[d], marker='*', label=dis_name+'_gamma')\n",
    "    ax_all.scatter(obs, mod_sampled, c=color_list[d], marker='+', alpha=0.75, label=dis_name+'_sampled')\n",
    "    ax.plot(xvals, yvals, lw=2, color='k')\n",
    "    ax.set_xlim(0.0, 6.0)\n",
    "    ax.set_ylim(0.0, 6.0)\n",
    "    ax.set_xlabel('Observed')\n",
    "    ax.set_ylabel('Model')\n",
    "    ax.text(0.6, 0.20, 'Bias (model): {:2.2f}'.format(bias_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.15, 'Cor. Coef. (model) {:2.3f}'.format(cc_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.10, 'Bias (model sampled): {:2.2f}'.format(bias_mod_sampled), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.05, 'Cor. Coef. (model sampled) {:2.3f}'.format(cc_mod_sampled), transform=ax.transAxes)\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "ZDR_raw_model_list = [v['ZDR'] for k, v in dualpol_raw_model_dict.items()]\n",
    "ZDR_PIPS_list = [v['ZDR'] for k, v in dualpol_PIPS_interp_to_model_times_dict.items()]\n",
    "ZDR_samp_model_list = [v['ZDR'] for k, v in dualpol_sample_dict.items()]\n",
    "\n",
    "ZDR_mod = xr.concat(ZDR_raw_model_list, dim='PIPS')\n",
    "ZDR_obs = xr.concat(ZDR_PIPS_list, dim='PIPS') \n",
    "ZDR_mod_samp = xr.concat(ZDR_samp_model_list, dim='PIPS')\n",
    "\n",
    "bias_mod_all = ((np.nansum(ZDR_mod - ZDR_obs)) / np.nansum(ZDR_obs))\n",
    "bias_mod_samp_all = ((np.nansum(ZDR_mod_samp - ZDR_obs)) / np.nansum(ZDR_obs))\n",
    "cc_mod_all = pd.DataFrame({'obs': ZDR_obs.stack(points=['PIPS', 'time']), \n",
    "                           'mod': ZDR_mod.stack(points=['PIPS', 'time'])}).corr().iloc[0, 1]\n",
    "cc_mod_samp_all = pd.DataFrame({'obs': ZDR_obs.stack(points=['PIPS', 'time']),\n",
    "                                'mod': ZDR_mod_samp.stack(points=['PIPS', 'time'])}).corr().iloc[0, 1]\n",
    "\n",
    "ax_all.plot(xvals, yvals, lw=2, color='k')\n",
    "ax_all.set_xlim(0.0, 6.0)\n",
    "ax_all.set_ylim(0.0, 6.0)\n",
    "ax_all.set_xlabel('Observed')\n",
    "ax_all.set_ylabel('Model')\n",
    "ax_all.text(0.6, 0.20, 'Bias (model): {:2.2f}'.format(bias_mod_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.15, 'Cor. Coef. (model) {:2.3f}'.format(cc_mod_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.10, 'Bias (model sampled): {:2.2f}'.format(bias_mod_samp_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.05, 'Cor. Coef. (model sampled) {:2.3f}'.format(cc_mod_samp_all), transform=ax_all.transAxes)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dual-pol variables for both the model and observations and make scatterplots of Z vs. ZDR\n",
    "# Z, ZDR relation from Cao et al. (2008)\n",
    "Zh_Cao = np.arange(10, 61, 0.1)\n",
    "Zdr_Cao = 10**((-2.6857 * 10**-4 * Zh_Cao**2) + 0.04892 * Zh_Cao - 1.4287)\n",
    "color_list = ['r', 'orange', 'g', 'b']\n",
    "\n",
    "for d, dis_name in enumerate(dis_names):\n",
    "    \n",
    "    \n",
    "    dualpol_mod = dualpol_sample_dict[dis_name]\n",
    "    dualpol_mod_raw = dualpol_raw_model_dict[dis_name]\n",
    "    dualpol_obs = dualpol_PIPS_interp_to_model_times_dict[dis_name]\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    sc = plt.scatter(dualpol_mod['dBZ'], dualpol_mod['ZDR'], c=color_list[d], marker='*', label=dis_name+'_mod',\n",
    "                     vmin=-15000., vmax=15000.)\n",
    "    sc = plt.scatter(dualpol_mod_raw['dBZ'], dualpol_mod_raw['ZDR'], c=color_list[d], marker='+', label=dis_name+'_mod_raw',\n",
    "                     vmin=-15000., vmax=15000.)\n",
    "    plt.scatter(dualpol_obs['dBZ'], dualpol_obs['ZDR'], c=color_list[d], marker='o', label=dis_name+'_obs', vmin=-15000., vmax=15000.)\n",
    "    plt.plot(Zh_Cao, Zdr_Cao, c='k', ls='-', lw=1.0)\n",
    "    #plt.colorbar(sc)\n",
    "    ax.set_xlabel('dBZ')\n",
    "    ax.set_ylabel(r'Z$_DR$')\n",
    "    ax.set_xlim(10.0, 60.0)\n",
    "    ax.set_ylim(-2.0, 6.0)\n",
    "    plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(D0_PIPS_interp_to_model_times_dict['PIPS2B'] * 1000).plot.hist()\n",
    "(D0_raw_model_dict['PIPS2B'] * 1000.).plot.hist(alpha=0.5)\n",
    "D0_sample_dict['PIPS2B'].plot.hist(alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old cells below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:31:30.133150Z",
     "start_time": "2019-09-10T03:31:29.930465Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: maybe it's better to try to do this the other direction: namely interpolate the ND values at the PIPS\n",
    "# times, which are different for each PIPS, to the common model times.\n",
    "\n",
    "# Now, interpolate these values at the model times to the PIPS DSD times, one PIPS at a time.\n",
    "# Also get the PSD time bin edges and centers as a numpy array of python datetime objects\n",
    "model_vars_PIPS_dict = {}\n",
    "model_gamma_DSD_params_PIPS_modeltimes_dict = {}\n",
    "model_gamma_DSD_PIPS_modeltimes_dict = {}\n",
    "model_gamma_DSD_params_PIPS_dict = {}\n",
    "model_gamma_DSD_PIPS_dict = {}\n",
    "\n",
    "# Get PSD times valid at the model times\n",
    "PSD_datetimes_model = pips.get_PSD_datetimes(var_ds, dim_name='time')\n",
    "PSD_datetimes_model_dict = pips.get_PSD_time_bins(PSD_datetimes_model)\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    \n",
    "    # Get the DataArrays for individual PIPS\n",
    "    \n",
    "    # Velocity-diameter matrix\n",
    "    vd_matrix_rs_da = vd_matrix_rs_da_dict[dis_name]\n",
    "    \n",
    "    # Rename \"time\" to \"time\" so that we have the same dimension name as the model\n",
    "    vd_matrix_rs_da = vd_matrix_rs_da.rename({'time': 'time'})\n",
    "    \n",
    "    # Shape, intercept, and slope parameters for model DSD, already interpolated in space to each\n",
    "    # PIPS location\n",
    "    # New way\n",
    "    \n",
    "    \n",
    "#     alphar_model_PIPS_da = var_ds_interp['alphar'].loc[dict(PIPS=dis_name)]\n",
    "#     N0r_model_PIPS_da = var_ds_interp['N0r'].loc[dict(PIPS=dis_name)]\n",
    "#     lamdar_model_PIPS_da = var_ds_interp['lamdar'].loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    # Do the same for ND and logND\n",
    "    ND_model_PIPS_da = var_ds_interp['ND'].loc[dict(PIPS=dis_name)]\n",
    "    logND_model_PIPS_da = var_ds_interp['logND'].loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    # Old way\n",
    "    alphar_model_PIPS_da = alphar_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    N0r_model_PIPS_da = N0r_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    lamdar_model_PIPS_da = lamdar_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    # Get the values of some needed variables from the model dataset, already interpolated in space to each\n",
    "    # PIPS location\n",
    "    \n",
    "    # We just need rho and nr\n",
    "    rho_model_pips_da = var_ds_interp['rho'].loc[dict(PIPS=dis_name)]\n",
    "    nr_model_pips_da = var_ds_interp['nr'].loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    # Now interpolate the DSD parameters in time to the PIPS times, which are different for each PIPS\n",
    "    \n",
    "    alphar_model_PIPS_da_interp = alphar_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    N0r_model_PIPS_da_interp = N0r_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    lamdar_model_PIPS_da_interp = lamdar_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    \n",
    "    # Do the same for ND and logND\n",
    "    ND_model_PIPS_da_interp = ND_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    logND_model_PIPS_da_interp = logND_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    \n",
    "    # Do the same for rho and nr\n",
    "    rho_model_pips_da_interp = rho_model_pips_da.interp_like(vd_matrix_rs_da)\n",
    "    nr_model_pips_da = nr_model_pips_da.interpolate_na(dim='time')\n",
    "    nr_model_pips_da_interp = nr_model_pips_da.interp_like(vd_matrix_rs_da)\n",
    "    \n",
    "    # Stuff them into a dict of dicts (gahhh!)\n",
    "    model_gamma_DSD_params_modeltimes_dict = {'alphar': alphar_model_PIPS_da,\n",
    "                                              'N0r': N0r_model_PIPS_da,\n",
    "                                              'lamdar': lamdar_model_PIPS_da}\n",
    "    model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name] = model_gamma_DSD_params_modeltimes_dict\n",
    "    model_gamma_DSD_params_dict = {'alphar': alphar_model_PIPS_da_interp,\n",
    "                                   'N0r': N0r_model_PIPS_da_interp,\n",
    "                                   'lamdar': lamdar_model_PIPS_da_interp}\n",
    "    model_gamma_DSD_params_PIPS_dict[dis_name] = model_gamma_DSD_params_dict\n",
    "    \n",
    "    model_gamma_DSD_modeltimes_dict = {'ND': ND_model_PIPS_da, \n",
    "                                       'logND': logND_model_PIPS_da}\n",
    "    model_gamma_DSD_PIPS_modeltimes_dict[dis_name] = model_gamma_DSD_modeltimes_dict\n",
    "    \n",
    "    model_gamma_DSD_dict = {'ND': ND_model_PIPS_da_interp,\n",
    "                            'logND': logND_model_PIPS_da_interp}\n",
    "    model_gamma_DSD_PIPS_dict[dis_name] = model_gamma_DSD_dict\n",
    "    \n",
    "    model_vars_PIPS_dict[dis_name] = {'rho': rho_model_pips_da_interp, 'nr': nr_model_pips_da_interp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:09:53.421810Z",
     "start_time": "2019-09-10T03:09:53.316079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute N(D) from the raw model parameters at original model times\n",
    "import pyPIPS.parsivel_params as pp\n",
    "\n",
    "ND_model_raw_PIPS_modeltimes_dict = {}\n",
    "logND_model_raw_PIPS_modeltimes_dict = {}\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    mid_diameters_da = vd_matrix_da_dict[dis_name]['diameter']\n",
    "    alphar_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['alphar']\n",
    "    N0r_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['N0r']\n",
    "    lamdar_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['lamdar']\n",
    "    print(alphar_model_PIPS_da)\n",
    "    # Broadcast DSD parameter DataArrays to get everyone on the same dimensional page\n",
    "    mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da = \\\n",
    "        xr.broadcast(mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da)\n",
    "    # Transpose these DataArrays to get time as the first dimension\n",
    "    mid_diameters_da = mid_diameters_da.T\n",
    "    N0r_model_PIPS_da = N0r_model_PIPS_da.T\n",
    "    lamdar_model_PIPS_da = lamdar_model_PIPS_da.T\n",
    "    alphar_model_PIPS_da = alphar_model_PIPS_da.T\n",
    "    \n",
    "    ND_model_raw_PIPS = dsd.calc_binned_DSD_from_params(N0r_model_PIPS_da, lamdar_model_PIPS_da, \n",
    "                                                        alphar_model_PIPS_da, mid_diameters_da)\n",
    "    logND_model_raw_PIPS = np.log10(ND_model_raw_PIPS)\n",
    "    logND_model_raw_PIPS = logND_model_raw_PIPS.where(logND_model_raw_PIPS > -1.0)\n",
    "    \n",
    "    ND_model_raw_PIPS_modeltimes_dict[dis_name] = ND_model_raw_PIPS\n",
    "    logND_model_raw_PIPS_modeltimes_dict[dis_name] = logND_model_raw_PIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:32:04.112418Z",
     "start_time": "2019-09-10T03:32:04.022606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute N(D) from the raw model parameters (interpolated to the PIPS times and locations)\n",
    "import pyPIPS.parsivel_params as pp\n",
    "\n",
    "ND_model_raw_PIPS_dict = {}\n",
    "logND_model_raw_PIPS_dict = {}\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    mid_diameters_da = vd_matrix_da_dict[dis_name]['diameter']\n",
    "    alphar_model_PIPS_da = model_gamma_DSD_params_PIPS_dict[dis_name]['alphar']\n",
    "    N0r_model_PIPS_da = model_gamma_DSD_params_PIPS_dict[dis_name]['N0r']\n",
    "    lamdar_model_PIPS_da = model_gamma_DSD_params_PIPS_dict[dis_name]['lamdar']\n",
    "    # Broadcast DSD parameter DataArrays to get everyone on the same dimensional page\n",
    "    mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da = \\\n",
    "        xr.broadcast(mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da)\n",
    "    # Transpose these DataArrays to get time as the first dimension\n",
    "    mid_diameters_da = mid_diameters_da.T\n",
    "    N0r_model_PIPS_da = N0r_model_PIPS_da.T\n",
    "    lamdar_model_PIPS_da = lamdar_model_PIPS_da.T\n",
    "    alphar_model_PIPS_da = alphar_model_PIPS_da.T\n",
    "    \n",
    "    ND_model_raw_PIPS = dsd.calc_binned_DSD_from_params(N0r_model_PIPS_da, lamdar_model_PIPS_da, \n",
    "                                                        alphar_model_PIPS_da, mid_diameters_da)\n",
    "    logND_model_raw_PIPS = np.log10(ND_model_raw_PIPS)\n",
    "    logND_model_raw_PIPS = logND_model_raw_PIPS.where(logND_model_raw_PIPS > -1.0)\n",
    "    \n",
    "    ND_model_raw_PIPS_dict[dis_name] = ND_model_raw_PIPS\n",
    "    logND_model_raw_PIPS_dict[dis_name] = logND_model_raw_PIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:32:05.856524Z",
     "start_time": "2019-09-10T03:32:05.648931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute some radar and DSD parameters from the raw model DSDs (interpolated to PIPS times and locations)\n",
    "dBZ_raw_model_dict = {}\n",
    "D0_raw_model_dict = {}\n",
    "for dis_name in dis_names:\n",
    "    dBZ_raw_model = dsd.calc_dBZ_from_bins(model_gamma_DSD_PIPS_dict[dis_name]['ND'])\n",
    "    dBZ_raw_model = dBZ_raw_model.where(dBZ_raw_model > -np.inf)\n",
    "    dBZ_raw_model_dict[dis_name] = dBZ_raw_model\n",
    "    D0_raw_model = dsd.calc_D0_bin(model_gamma_DSD_PIPS_dict[dis_name]['ND'])\n",
    "    D0_raw_model_dict[dis_name] = D0_raw_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T01:42:40.236360Z",
     "start_time": "2019-09-10T01:42:38.255873Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Now plot the raw model DSDs (interpolated to PIPS locations but not the times)\n",
    "\n",
    "# PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "# PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "# for i, dis_name in enumerate(dis_names):\n",
    "#     logND = model_gamma_DSD_PIPS_modeltimes_dict[dis_name]['logND']\n",
    "#     logND = logND.where(logND > -1.0)\n",
    "#     disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "#                'PSDmidtimes': PSDmidtimes, 'logND': logND.T}\n",
    "#     dis_plot_name = dis_name + '_raw_model_modeltimes_' + DSDtype\n",
    "#     PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:04:24.928139Z",
     "start_time": "2019-09-08T23:04:22.881514Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Now plot the raw model DSDs (interpolated to PIPS locations but not the times) - version 2 with logND computed\n",
    "# # from interpolated alpha, lamda, N0\n",
    "\n",
    "# PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "# PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "# for i, dis_name in enumerate(dis_names):\n",
    "#     logND = logND_model_raw_PIPS_modeltimes_dict[dis_name]\n",
    "#     logND = logND.where(logND > -1.0)\n",
    "#     print(logND)\n",
    "#     print(PSDstarttimes)\n",
    "#     disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "#                'PSDmidtimes': PSDmidtimes, 'logND': logND.T}\n",
    "#     dis_plot_name = dis_name + '_raw_model_modeltimes_v2_' + DSDtype\n",
    "#     PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:32:13.477374Z",
     "start_time": "2019-09-10T03:32:11.095613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now plot the raw model DSDs (interpolated to PIPS times and locations)\n",
    "\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND = model_gamma_DSD_PIPS_dict[dis_name]['logND']\n",
    "    logND = logND.where(logND > -1.0)\n",
    "    D0 = D0_raw_model_dict[dis_name] * 1000. # Get to mm again\n",
    "    dBZ = dBZ_raw_model_dict[dis_name]\n",
    "    PSDstarttimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_edges'])\n",
    "    PSDmidtimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_centers'])\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'D_0': D0, 'dBZ': dBZ}\n",
    "    dis_plot_name = dis_name + '_raw_model_{:d}'.format(member) + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:04:57.995119Z",
     "start_time": "2019-09-08T23:04:55.982881Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Now plot the raw model DSDs (interpolated to PIPS times and locations) - version 2 with logND computed\n",
    "# # from interpolated alpha, lamda, N0\n",
    "\n",
    "# for i, dis_name in enumerate(dis_names):\n",
    "#     logND = logND_model_raw_PIPS_dict[dis_name]\n",
    "#     logND = logND.where(logND > -1.0)\n",
    "#     PSDstarttimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_edges'])\n",
    "#     PSDmidtimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_centers'])\n",
    "#     print(logND)\n",
    "#     print(PSDstarttimes)\n",
    "#     disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "#                'PSDmidtimes': PSDmidtimes, 'logND': logND.T}\n",
    "#     dis_plot_name = dis_name + '_raw_model_v2_' + DSDtype\n",
    "#     PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:32:20.701802Z",
     "start_time": "2019-09-10T03:32:16.011139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now compute sampled PSDs from the model\n",
    "\n",
    "# Now plot the sampled model DSD\n",
    "\n",
    "sampling_interval = 60.\n",
    "sampling_length = pp.parsivel_parameters['sensor_length_mm'] / 1000. # To m\n",
    "sampling_width = pp.parsivel_parameters['sensor_width_mm'] / 1000. # To m\n",
    "\n",
    "Dmax = 9.\n",
    "Dmax_index = np.searchsorted(mid_diameters, Dmax, side='right')\n",
    "# print(Dmax_index)\n",
    "mid_diameters_trunc = np.array(mid_diameters[:Dmax_index+1]) / 1000.\n",
    "min_diameters_trunc = np.array(min_diameters[:Dmax_index+1]) / 1000.\n",
    "max_diameters_trunc = np.array(max_diameters[:Dmax_index+1]) / 1000.\n",
    "\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    PSDstarttimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_edges'])\n",
    "    PSDmidtimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_centers'])\n",
    "    ND_raw = model_gamma_DSD_PIPS_dict[dis_name]['ND']\n",
    "    # print(ND_raw)\n",
    "    nr_model = model_vars_PIPS_dict[dis_name]['nr'].values\n",
    "    lamdar_model = model_gamma_DSD_params_PIPS_dict[dis_name]['lamdar'].values\n",
    "    alphar_model = model_gamma_DSD_params_PIPS_dict[dis_name]['alphar'].values\n",
    "    rho_model = model_vars_PIPS_dict[dis_name]['rho'].values\n",
    "\n",
    "    # print(mid_diameters_trunc.shape)\n",
    "    Vtr = pips.calc_empirical_fallspeed(mid_diameters_trunc * 1000., correct_rho=True, rho=rho_model)\n",
    "\n",
    "    Vtr = Vtr.T\n",
    "#     print(Vtr[0])\n",
    "#     print(Vtr.shape)\n",
    "#     print(mid_diameters_trunc.shape)\n",
    "    ND_samp_series = np.zeros((np.size(PSDmidtimes), np.size(mid_diameters_trunc)))\n",
    "\n",
    "#     print(ND_samp_series.shape)\n",
    "#     print(nr_model[0])\n",
    "    # Nc_bin_tmp2 = np.zeros((np.size(N0r), np.size(D[:Dmax_index+1])))\n",
    "    # Nc_bin2 = np.zeros((np.size(np.array(sampling_times)), np.size(D[:Dmax_index+1])))\n",
    "\n",
    "    all_valid = (not np.isnan(lamdar_model[0]) and (not np.isnan(alphar_model[0])) and (not np.isnan(nr_model[0])))\n",
    "    if all_valid:\n",
    "        # Special treatment for first sampling time. Just assume DSD valid at that time was constant for the previous \n",
    "        # sampling interval\n",
    "        sample_dict = sim.create_random_gamma_DSD(nr_model[0], lamdar_model[0], \n",
    "                                                  alphar_model[0], Vtr[0], sampling_length, \n",
    "                                                  sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                                  max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                                  remove_margins=True, rhocorrect=True, rho=rho_model[0], verbose=True)\n",
    "\n",
    "\n",
    "        ND_sample = sample_dict['ND']\n",
    "        pcount_binned_sample = sample_dict['pcount_binned']\n",
    "    #     print(ND_sample.shape)\n",
    "    #     print(ND_samp_series.shape)\n",
    "        ND_samp_series[0, :] = 1.e-3*ND_sample\n",
    "        # Nc_bin_tmp2[0, :] = 1.e-3*ND_sample\n",
    "        # Nc_bin2[0, :] = Nc_bin_tmp2[0, :]\n",
    "\n",
    "    \n",
    "    pcount_binned_samples = []\n",
    "    for index in range(np.size(PSDmidtimes[1:-1])):\n",
    "        all_valid = (not np.isnan(lamdar_model[index]) \n",
    "                     and (not np.isnan(alphar_model[index]))\n",
    "                     and (not np.isnan(nr_model[index])))\n",
    "        print('nr = ', nr_model[index], 'lamdar = ', lamdar_model[index], 'alphar = ', alphar_model[index])\n",
    "        if all_valid:\n",
    "            sample_dict = sim.create_random_gamma_DSD(nr_model[index], lamdar_model[index], \n",
    "                                                      alphar_model[index], Vtr[index], sampling_length, \n",
    "                                                      sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                                      max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                                      remove_margins=True, rhocorrect=True, rho=rho_model[index], verbose=True)\n",
    "            ND_sample = sample_dict['ND']\n",
    "            pcount_binned_samples.append(sample_dict['pcount_binned'])\n",
    "            ND_samp_series[index, :] = 1.e-3*ND_sample\n",
    "        else:\n",
    "            pcount_binned_samples.append(np.zeros_like(sample_dict['pcount_binned']))\n",
    "\n",
    "    pcount_binned_samples = np.array(pcount_binned_samples)\n",
    "    \n",
    "    ND_samp_da = xr.DataArray(ND_samp_series,\n",
    "                                     coords={'time': PSDmidtimes,\n",
    "                                             'diameter': ('diameter_bin', mid_diameters_trunc * 1000.),\n",
    "                                             'max_diameter': ('diameter_bin', max_diameters_trunc * 1000.),\n",
    "                                             'min_diameter': ('diameter_bin', min_diameters_trunc * 1000.)\n",
    "                                            },\n",
    "                                     dims=['time', 'diameter_bin'])\n",
    "    \n",
    "    ND_samp_da = ND_samp_da.fillna(0.0)\n",
    "\n",
    "    # sampling_volumes_D = sim.calc_sampling_volumes_D(Vtr, Dr, Dmax, sampling_interval, sampling_area)\n",
    "    # for s, sample_index in enumerate(sample_indices[:-1]):\n",
    "    #     sample_index_end = sample_indices[s+1]\n",
    "    #     current_sample_indices = slice(sample_index, sample_index_end, None)\n",
    "    #     pcount_binned = np.sum(pcount_binned_samples[current_sample_indices], axis=0)\n",
    "    #     Nc_bin2[s+1, :] = 1.e-3*sim.calc_ND(pcount_binned, sampling_volumes_D, Dr, Dl, Dmax)\n",
    "    # #     Nc_bin2[s+1, :] = np.sum(Nc_bin_tmp2[current_sample_indices, :]*dt[current_sample_indices, None], axis = 0)/sampling_interval\n",
    "    # #     print \"s = \", s\n",
    "    # #     print \"sample time (beginning) = \", sampling_times[s]\n",
    "    # #     print \"sample time (end) = \", sampling_times[s+1]\n",
    "    # #     print \"dt[current_sample_indices] = \", dt[current_sample_indices]\n",
    "    # #     print \"Nc_bin_tmp = \", Nc_bin_tmp[current_sample_indices, :], dt[current_sample_indices]\n",
    "    # #     print \"Nc_bin = \", Nc_bin[s+1, :]\n",
    "\n",
    "    logND_samp_da = np.log10(ND_samp_da)\n",
    "    logND_samp_da = logND_samp_da.where(logND_samp_da > -1.0)\n",
    "\n",
    "    # Compute dBZ and D0 from the sampled DSD\n",
    "    dBZ_samp_model = dsd.calc_dBZ_from_bins(ND_samp_da)\n",
    "    dBZ_samp_model = dBZ_samp_model.where(dBZ_samp_model > -np.inf)\n",
    "    D0_samp_model = dsd.calc_D0_bin(ND_samp_da) * 1000. # Get to mm again\n",
    "    \n",
    "    disvars = {'min_diameter': min_diameters[:Dmax_index+1], 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND_samp_da.T, 'D_0': D0_samp_model, \n",
    "               'dBZ': dBZ_samp_model}\n",
    "    dis_plot_name = dis_name + '_sampled_model_{:d}'.format(member) + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:32:22.342960Z",
     "start_time": "2019-09-10T03:32:22.267770Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model_vars_PIPS_dict['PIPS1B']['nr'].loc['2016-03-31T22:25':'2016-03-31T22:30'])\n",
    "print(model_gamma_DSD_params_PIPS_dict['PIPS1B']['lamdar'].loc['2016-03-31T22:25':'2016-03-31T22:30'])\n",
    "print(model_gamma_DSD_params_PIPS_dict['PIPS1B']['alphar'].loc['2016-03-31T22:25':'2016-03-31T22:30'])\n",
    "print(model_gamma_DSD_params_PIPS_modeltimes_dict['PIPS1B']['alphar'].loc['2016-03-31T22:25':'2016-03-31T22:30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pyPIPS]",
   "language": "python",
   "name": "conda-env-pyPIPS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A notebook to perform QC on the PIPS T and RH/Td observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T14:33:57.347909Z",
     "start_time": "2020-06-23T14:33:52.438729Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid,make_axes_locatable,host_subplot\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "#import pyPIPS.disdrometer_module as dis\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "#import pyPIPS.simulator as sim\n",
    "import pyPIPS.pips_io as pipsio\n",
    "import pyPIPS.PIPS as pips\n",
    "import pyPIPS.parsivel_params as pp\n",
    "import pyPIPS.parsivel_qc as pqc\n",
    "import pyPIPS.polarimetric as dualpol\n",
    "#from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "# from pyCRMtools.pycaps import arps_read\n",
    "# from pyCRMtools.pycaps import pycaps_fields\n",
    "# from pyCRMtools.pycaps import calvars_radar as radar\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy.random as random\n",
    "from scipy.stats import gamma, uniform\n",
    "from scipy.stats.mstats import zscore\n",
    "from scipy.special import gamma as gammafunc\n",
    "from scipy import ndimage\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.calc import wind_components\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.plots.wx_symbols import current_weather, sky_cover\n",
    "from metpy.units import units\n",
    "from cycler import cycler\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.style.use('seaborn-v0_8-bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the original PIPS netcdf files\n",
    "\n",
    "# PIPS_input_base_dir = '/Users/dawson29/Projects/PERiLS/obsdata/2022/PIPS_data/'\n",
    "# PIPS_output_base_dir = '/Users/dawson29/Projects/PERiLS/obsdata/2022/PIPS_data_for_EOL/'\n",
    "\n",
    "PIPS_base_dir = '/Users/dawson29/Dropbox/Projects/PERiLS/obsdata/2023/'\n",
    "# PIPS_base_dir = '/Users/dawson29/Dropbox/Projects/PERiLS/obsdata/2023/'\n",
    "# PIPS_base_dir = '/Users/dawson29/Projects/PERiLS/obsdata/2023/PIPS_data/'\n",
    "# PIPS_base_dir = '/Users/dawson29/Projects/PERiLS/obsdata/2022/PIPS_data/'\n",
    "\n",
    "# deployment_name = 'IOP2_030323' # '031623_mass_test' # 'IOP2_030323' # 'IOP5_040523' # 'IOP4_033123' # 'IOP3_032423' # 'IOP3_040522'\n",
    "# PIPS_input_dir = os.path.join(PIPS_base_dir, deployment_name, 'netcdf_v110823')\n",
    "# PIPS_output_dir = os.path.join(PIPS_base_dir, deployment_name, 'netcdf_T_Td_QC_v110823')\n",
    "\n",
    "deployment_name = '022723_mass_test'\n",
    "PIPS_input_dir = os.path.join(PIPS_base_dir, deployment_name, 'netcdf')\n",
    "PIPS_output_dir = os.path.join(PIPS_base_dir, deployment_name, 'netcdf_thermoQC')\n",
    "\n",
    "# deployment_name = 'IOP2_033022' # '031623_mass_test' # 'IOP2_030323' # 'IOP5_040523' # 'IOP4_033123' # 'IOP3_032423' # 'IOP3_040522'\n",
    "# PIPS_input_dir = os.path.join(PIPS_base_dir, deployment_name, 'netcdf')\n",
    "# PIPS_output_dir = os.path.join(PIPS_base_dir, deployment_name, 'netcdf_T_Td_QC')\n",
    "\n",
    "if not os.path.exists(PIPS_output_dir):\n",
    "    os.makedirs(PIPS_output_dir)\n",
    "\n",
    "# IOP1 2022\n",
    "# PIPS_names = ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B']\n",
    "# IOP2 2022\n",
    "# PIPS_names = ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS3B']\n",
    "# IOP3 2022\n",
    "PIPS_names = ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B', 'PIPS3A', 'PIPS3B']\n",
    "# IOP3 2023\n",
    "# PIPS_names = ['PIPS2A', 'PIPS3A']\n",
    "# IOP2, IOP4 or IOP5 2023\n",
    "# PIPS_names = ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B', 'PIPS3A', 'PIPS3B']\n",
    "parsivel_interval = 10\n",
    "intervalstr = '10S'\n",
    "\n",
    "parsivel_filenames = ['parsivel_combined_{}_{}_{:d}s.nc'.format(deployment_name, PIPS_name, parsivel_interval)\n",
    "                      for PIPS_name in PIPS_names]\n",
    "parsivel_filepaths = [os.path.join(PIPS_input_dir, parsivel_filename) for parsivel_filename in parsivel_filenames]\n",
    "output_parsivel_filepaths = [os.path.join(PIPS_output_dir, parsivel_filename) \n",
    "                             for parsivel_filename in parsivel_filenames]\n",
    "conv_filenames = ['conventional_raw_{}_{}.nc'.format(deployment_name, PIPS_name) for PIPS_name in PIPS_names]\n",
    "conv_filepaths = [os.path.join(PIPS_input_dir, conv_filename) for conv_filename in conv_filenames]\n",
    "output_conv_filepaths = [os.path.join(PIPS_output_dir, conv_filename) for conv_filename in conv_filenames]\n",
    "parsivel_ds_dict = {}\n",
    "conv_ds_dict = {}\n",
    "for PIPS_name, parsivel_filepath, conv_filepath in zip(PIPS_names, parsivel_filepaths, conv_filepaths):\n",
    "    try:\n",
    "        parsivel_ds_dict[PIPS_name] = xr.load_dataset(parsivel_filepath)\n",
    "    except:\n",
    "        parsivel_ds_dict[PIPS_name] = None\n",
    "    conv_ds_dict[PIPS_name] = xr.load_dataset(conv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_cycler = (cycler(color=['r', 'orange', 'y', 'g', 'b', 'purple']))\n",
    "\n",
    "# plt.rc('lines', linewidth=4)\n",
    "# plt.rc('axes', prop_cycle=default_cycler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPS_to_comp = PIPS_names\n",
    "\n",
    "start_times = []\n",
    "stop_times = []\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    start_times.append(conv_ds_dict[PIPS_name]['time'][0])\n",
    "    stop_times.append(conv_ds_dict[PIPS_name]['time'][-1])\n",
    "    \n",
    "min_time = min(start_times)\n",
    "max_time = max(stop_times)\n",
    "\n",
    "print(min_time, max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = min_time # '2023-03-17T8:30:00'\n",
    "time_stop = max_time # '2023-03-17T9:30:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a comparison of the fast and slow temps for this mass test\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['fasttemp'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_fastT', \n",
    "                                                                    ls='None', marker='o', ms=1., alpha=0.5) \n",
    "    \n",
    "    ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the fast temps look to be pretty close to each other with no obvious outliers on average, so we can\n",
    "# proceed to take a simple ensemble average of all the PIPS sensors as a function of time and use the \n",
    "# difference between the average and each PIPS in turn to correct them.\n",
    "\n",
    "all_PIPS_fastT_list = [conv_ds_dict[PIPS_name]['fasttemp'] for PIPS_name in PIPS_to_comp]\n",
    "all_PIPS_fastT_ds = xr.concat(all_PIPS_fastT_list, dim='PIPS')\n",
    "\n",
    "avg_PIPS_fastT_ds = all_PIPS_fastT_ds.mean(dim='PIPS', skipna=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_PIPS_fastT_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_PIPS_fastT_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PIPS-averaged fast temp\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "avg_PIPS_fastT_ds.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'PIPS_avg_fastT', \n",
    "                                                              ls='None', marker='o', ms=1., alpha=0.5) \n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now compute the differences of each PIPS from the PIPS mean at each time and then take the\n",
    "# average of the diffs for each PIPS over time. This time-averaged diff for each PIPS will be used as a\n",
    "# constant offset to correct the timeseries for each. This is not perfect because it assumes that any bias\n",
    "# is constant and independent of temperature, etc. but it's good enough for most purposes.\n",
    "\n",
    "# First compute the diffs\n",
    "diff_T_dict = {}\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_T = conv_ds_dict[PIPS_name]['fasttemp'] - avg_PIPS_fastT_ds\n",
    "    diff_T_dict[PIPS_name] = diff_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the diffs. For the most part they are pretty small and within 0.2 deg of each other\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_T = diff_T_dict[PIPS_name]\n",
    "    diff_T.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_diff_fastT', \n",
    "                                                       ls='None', marker='o', ms=1., alpha=0.5)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now find the time-mean diffs and then subtract them from the original fasttemp timeseries for each PIPS\n",
    "# and store them in a new \"corrected\" fasttemp variable\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_T = diff_T_dict[PIPS_name]\n",
    "    mean_diff_T = diff_T.mean().values\n",
    "    print(PIPS_name, mean_diff_T)\n",
    "    conv_ds_dict[PIPS_name]['fasttemp_corrected'] = conv_ds_dict[PIPS_name]['fasttemp'].copy() - mean_diff_T\n",
    "    # Add the value subtracted to the attributes so we know that we modified it\n",
    "    conv_ds_dict[PIPS_name]['fasttemp_corrected'].attrs['bias_subtracted'] = mean_diff_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now plot the bias-corrected fasttemps\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['fasttemp_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, \n",
    "                                                                              label=f'{PIPS_name}_fastT_corrected', \n",
    "                                                                              ls='None', marker='o', ms=1., \n",
    "                                                                              alpha=0.5)    \n",
    "# plt.gca().set_prop_cycle(None)\n",
    "\n",
    "# for PIPS_name in PIPS_to_comp[:1]:\n",
    "#     conv_ds = conv_ds_dict[PIPS_name]\n",
    "#     conv_ds['fasttemp'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_fastT', \n",
    "#                                                                     ls='None', marker='x', ms=5., alpha=0.75)\n",
    "    \n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now that we've handled the fasttemps, lets move on to the slowtemps\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['slowtemp'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_slowT', \n",
    "                                                                    ls='None', marker='o', ms=1., alpha=0.5) \n",
    "    \n",
    "    ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ok, in this case there is a clear clustering of PIPS3A and PIPS3B on the one hand, which read about a degree\n",
    "# higher than the others, which are all clustered around a lower temp (although PIPS1B seems to have a\n",
    "# systematic cold bias by about 0.25 deg). Let's dig a bit deeper by comparing the fast and slow temps for\n",
    "# each PIPS. This will give us some idea of which PIPS slowtemps are closer to being correct. Then we can use\n",
    "# that info to figure out how best to correct them\n",
    "\n",
    "# First, for each PIPS, plot the slow and (corrected) fast temps together. Make separate plots for each PIPS this time\n",
    "# to avoid clutter\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    fig, ax = plt.subplots()\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['slowtemp'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_slowT', \n",
    "                                                                    ls='None', marker='o', ms=1., alpha=0.5)\n",
    "    conv_ds['fasttemp_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_fastT_corrected', \n",
    "                                                                    ls='None', marker='x', ms=1., alpha=0.5)\n",
    "    \n",
    "    ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above plots strongly suggest that the biases for each PIPS for the slow temps would be most easily\n",
    "# corrected by adding a constant offset representing the mean difference between the slow temps and fast temps\n",
    "# for each PIPS. In other words, it is likely that the corrected fast temps are closest to being the most\n",
    "# accurate. To really tell for sure we would like to have a well-calibrated reference temperature to compare\n",
    "# everthing to, but we don't have that in this case. So we will go with the assumption that the fast temps\n",
    "# are best and correct the slow temps based on them.\n",
    "# Again, this isn't perfect because the offset may not be constant, but it should be good enough.\n",
    "\n",
    "# So, let's compute differences between the fast and slow temps for each PIPS and then take the time average\n",
    "# as before. Then subtract the time-averaged diffs from the original slow temps and store them in a new\n",
    "# \"corrected\" slow temp variable\n",
    "\n",
    "diff_T_dict2 = {}\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_T = conv_ds_dict[PIPS_name]['slowtemp'] - conv_ds_dict[PIPS_name]['fasttemp_corrected']\n",
    "    diff_T_dict2[PIPS_name] = diff_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series of the slow-fast temp differences\n",
    "# Note there are a couple \"spikes\" in the difference that correspond to where there was a rapid drop in\n",
    "# temperature. This spike reflects the different time constants of the fast and slow-response temperature\n",
    "# sensors, but since the time period where this is happening is so short, we can still get by with a simple\n",
    "# time average of all the diffs. If we really wanted to get fancy, we could probably exclude any period in \n",
    "# the average\n",
    "# where the temperature is changing too much, but it probably wouldn't make much of a difference in this case.\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_T = diff_T_dict2[PIPS_name]\n",
    "    diff_T.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_diff_T', \n",
    "                                                       ls='None', marker='o', ms=1., alpha=0.5)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean differences and then subtract from the original slowtemp, storing in a new corrected slowtemp\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_T = diff_T_dict2[PIPS_name]\n",
    "    mean_diff_T = diff_T.mean().values\n",
    "    print(PIPS_name, mean_diff_T)\n",
    "    conv_ds_dict[PIPS_name]['slowtemp_corrected'] = conv_ds_dict[PIPS_name]['slowtemp'].copy() - mean_diff_T\n",
    "    # Add the value subtracted to the attributes so we know that we modified it\n",
    "    conv_ds_dict[PIPS_name]['slowtemp_corrected'].attrs['bias_subtracted'] = mean_diff_T\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now plot the bias-corrected slowtemps\n",
    "# Much better!\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['slowtemp_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_slowT_corrected', \n",
    "                                                                              ls='None', marker='o', ms=1., alpha=0.5)    \n",
    "# plt.gca().set_prop_cycle(None)\n",
    "\n",
    "# for PIPS_name in PIPS_to_comp[:1]:\n",
    "#     conv_ds = conv_ds_dict[PIPS_name]\n",
    "#     conv_ds['fasttemp'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_fastT', \n",
    "#                                                                     ls='None', marker='x', ms=5., alpha=0.75)\n",
    "    \n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do the same for the RH\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['RH'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_RH', \n",
    "                                                              ls='None', marker='o', ms=1., alpha=0.5) \n",
    "    \n",
    "    ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this case it looks like there is again a cluster where PIPS 3A and 3B are reading a bit too high,\n",
    "# while the others are all clustered lower. So in the absence of an independent comparison, we'll assume\n",
    "# that it's PIPS 3A and 3B that are \"wrong\" and use the time average of all the others (excluding PIPS3A and\n",
    "# PIPS3B) to correct everything.\n",
    "\n",
    "PIPS_to_avg = ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B']\n",
    "PIPS_RH_list = [conv_ds_dict[PIPS_name]['RH'] for PIPS_name in PIPS_to_avg]\n",
    "PIPS_RH_ds = xr.concat(PIPS_RH_list, dim='PIPS')\n",
    "avg_PIPS_RH_ds = PIPS_RH_ds.mean(dim='PIPS', skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PIPS-averaged RH\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "avg_PIPS_RH_ds.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'PIPS_avg_RH', \n",
    "                                                           ls='None', marker='o', ms=1., alpha=0.5) \n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now compute the differences of each PIPS from the PIPS mean at each time and then take the\n",
    "# average of the diffs for each PIPS over time. This time-averaged diff for each PIPS will be used as a\n",
    "# constant offset to correct the timeseries for each. This is not perfect because it assumes that any bias\n",
    "# is constant and independent of temperature, etc. but it's good enough for most purposes.\n",
    "\n",
    "# First compute the diffs\n",
    "diff_RH_dict = {}\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_RH = conv_ds_dict[PIPS_name]['RH'] - avg_PIPS_RH_ds\n",
    "    diff_RH_dict[PIPS_name] = diff_RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the diffs.\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_RH = diff_RH_dict[PIPS_name]\n",
    "    diff_RH.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_diff_RH', \n",
    "                                                        ls='None', marker='o', ms=1., alpha=0.5)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now find the time-mean diffs and then subtract them from the original RH timeseries for each PIPS\n",
    "# and store them in a new \"corrected\" fasttemp variable\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_RH = diff_RH_dict[PIPS_name]\n",
    "    mean_diff_RH = diff_RH.mean().values\n",
    "    print(PIPS_name, mean_diff_RH)\n",
    "    conv_ds_dict[PIPS_name]['RH_corrected'] = conv_ds_dict[PIPS_name]['RH'].copy() - mean_diff_RH\n",
    "    # Add the value subtracted to the attributes so we know that we modified it\n",
    "    conv_ds_dict[PIPS_name]['RH_corrected'].attrs['bias_subtracted'] = mean_diff_RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now plot the bias-corrected RH\n",
    "# Much better! Still some residual differences in spots but we can (probably) live with them\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['RH_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, \n",
    "                                                                        label=f'{PIPS_name}_RH_corrected', \n",
    "                                                                        ls='None', marker='o', ms=1., \n",
    "                                                                        alpha=0.5)\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we need to check the pressure and correct any biases. Then we need to\n",
    "# recompute the dewpoint and the \"derived\" RH using the bias-corrected temperatures, RH, and pressure\n",
    "# After that, we resample everything to 10-s intervals for the parsivel_ds for each PIPS and save the updated\n",
    "# netCDF files back to disk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for pressure.\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['pressure'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_pressure', \n",
    "                                                                    ls='None', marker='o', ms=1., alpha=0.5) \n",
    "    \n",
    "    ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the probes all agree very well with each other in regard to pressure so like with the fasttemps\n",
    "# we can\n",
    "# proceed to take a simple ensemble average of all the PIPS sensors as a function of time and use the \n",
    "# difference between the average and each PIPS in turn to correct them.\n",
    "\n",
    "all_PIPS_pressure_list = [conv_ds_dict[PIPS_name]['pressure'] for PIPS_name in PIPS_to_comp]\n",
    "all_PIPS_pressure_ds = xr.concat(all_PIPS_pressure_list, dim='PIPS')\n",
    "\n",
    "avg_PIPS_pressure_ds = all_PIPS_pressure_ds.mean(dim='PIPS', skipna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the PIPS-averaged pressure\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "avg_PIPS_pressure_ds.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'PIPS_avg_pressure', \n",
    "                                                                 ls='None', marker='o', ms=1., alpha=0.5) \n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now compute the differences of each PIPS from the PIPS mean at each time and then take the\n",
    "# average of the diffs for each PIPS over time. This time-averaged diff for each PIPS will be used as a\n",
    "# constant offset to correct the timeseries for each. This is not perfect because it assumes that any bias\n",
    "# is constant and independent of pressure, etc. but it's good enough for most purposes.\n",
    "\n",
    "# First compute the diffs\n",
    "diff_p_dict = {}\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_p = conv_ds_dict[PIPS_name]['pressure'] - avg_PIPS_pressure_ds\n",
    "    diff_p_dict[PIPS_name] = diff_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the diffs. For the most part they are pretty small and within 0.2 Pa of each other\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_p = diff_p_dict[PIPS_name]\n",
    "    diff_p.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_diff_pressure', \n",
    "                                                       ls='None', marker='o', ms=1., alpha=0.5)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now find the time-mean diffs and then subtract them from the original pressure timeseries for each PIPS\n",
    "# and store them in a new \"corrected\" pressure variable\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_p = diff_p_dict[PIPS_name]\n",
    "    mean_diff_p = diff_p.mean().values\n",
    "    print(PIPS_name, mean_diff_p)\n",
    "    conv_ds_dict[PIPS_name]['pressure_corrected'] = conv_ds_dict[PIPS_name]['pressure'].copy() - mean_diff_p\n",
    "    # Add the value subtracted to the attributes so we know that we modified it\n",
    "    conv_ds_dict[PIPS_name]['pressure_corrected'].attrs['bias_subtracted'] = mean_diff_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now plot the bias-corrected pressure\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['pressure_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, \n",
    "                                                                              label=f'{PIPS_name}_pressure_corrected', \n",
    "                                                                              ls='None', marker='o', ms=1., \n",
    "                                                                              alpha=0.5)    \n",
    "\n",
    "ax.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we need to recompute the dewpoint and RH_derived using the bias-corrected values from above\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    pressure = conv_ds_dict[PIPS_name]['pressure_corrected']\n",
    "    slowtemp = conv_ds_dict[PIPS_name]['slowtemp_corrected']\n",
    "    fasttemp = conv_ds_dict[PIPS_name]['fasttemp_corrected']\n",
    "    RH = conv_ds_dict[PIPS_name]['RH_corrected']\n",
    "    dewpoint = thermo.calTdfromRH(pressure * 100., slowtemp + 273.15, RH / 100.) - 273.15\n",
    "#     dewpoint.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_dewpoint', \n",
    "#                                                          ls='None', marker='o', ms=1., alpha=0.5)\n",
    "    RH_derived = thermo.calRH(pressure * 100., fasttemp + 273.15, dewpoint + 273.15) * 100.\n",
    "    \n",
    "    conv_ds_dict[PIPS_name]['dewpoint_corrected'] = conv_ds_dict[PIPS_name]['dewpoint'].copy()\n",
    "    conv_ds_dict[PIPS_name]['dewpoint_corrected'].data = dewpoint\n",
    "    \n",
    "    conv_ds_dict[PIPS_name]['RH_derived_corrected'] = conv_ds_dict[PIPS_name]['RH_derived'].copy()\n",
    "    conv_ds_dict[PIPS_name]['RH_derived_corrected'].data = RH_derived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the timeseries of RH_derived_corrected\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['RH_derived_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_RH_derived_corrected', \n",
    "                                                              ls='None', marker='o', ms=1., alpha=0.5)    \n",
    "# plt.gca().set_prop_cycle(None)\n",
    "\n",
    "# for PIPS_name in PIPS_to_comp:\n",
    "#     conv_ds = conv_ds_dict[PIPS_name]\n",
    "#     conv_ds['RH_derived_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_RH_derived_cor', \n",
    "#                                                                     ls='None', marker='x', ms=5., alpha=0.75)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the timeseries of dewpoint_corrected\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['dewpoint_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_dewpoint'), \n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute some of the derived thermodynamic parameters (pt, qv, rho) using the new corrected vars\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds = pips.calc_thermo(conv_ds, p_var='pressure_corrected', T_var='fasttemp_corrected', \n",
    "                               RH_var='RH_derived_corrected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the timeseries of pt_corrected to check\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['pt_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_pt'), \n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now resample the corrected timeseries to the parsivel times\n",
    "\n",
    "corrected_varnames = ['fasttemp_corrected', 'slowtemp_corrected', 'RH_corrected', 'pressure_corrected',\n",
    "                      'dewpoint_corrected', 'RH_derived_corrected', 'pt_corrected', 'qv_corrected',\n",
    "                      'rho_corrected']\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    PSD_datetimes = pips.get_PSD_datetimes(parsivel_ds_dict[PIPS_name]['VD_matrix'])\n",
    "    sec_offset = PSD_datetimes[0].second\n",
    "    print(sec_offset)\n",
    "    offset_str = pips.get_interval_str(sec_offset)\n",
    "    \n",
    "    for corrected_varname in corrected_varnames:\n",
    "        corrected_var = conv_ds_dict[PIPS_name][corrected_varname]\n",
    "        new_var = corrected_var.resample(time=intervalstr, label='right', closed='right', \n",
    "                                         offset=offset_str).mean()\n",
    "        \n",
    "        parsivel_ds_dict[PIPS_name][corrected_varname] = new_var\n",
    "        parsivel_ds_dict[PIPS_name][corrected_varname].attrs = conv_ds_dict[PIPS_name][corrected_varname].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    parsivel_ds_dict[PIPS_name]['pt_corrected'].plot(ax=ax, label=f'{PIPS_name}_pt_corrected', \n",
    "                                                             ls='None', marker='o', ms=1., alpha=0.75)\n",
    "#     parsivel_ds_dict[PIPS_name]['RH_derived'].plot(ax=ax, label=f'{PIPS_name}_RH_derived', \n",
    "#                                                    ls='None', marker='x', ms=5., alpha=0.5)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save to new output directory\n",
    "for PIPS_name, output_parsivel_filepath, output_conv_filepath in zip(PIPS_names, \n",
    "                                                                     output_parsivel_filepaths, \n",
    "                                                                     output_conv_filepaths):\n",
    "    if PIPS_name in PIPS_to_comp:\n",
    "        print(PIPS_name)\n",
    "        \n",
    "        \n",
    "        print(\"Saving {}\".format(output_parsivel_filepath))\n",
    "        parsivel_ds_dict[PIPS_name].to_netcdf(output_parsivel_filepath)\n",
    "        print(\"Saving {}\".format(output_conv_filepath))\n",
    "        conv_ds_dict[PIPS_name].to_netcdf(output_conv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, print out the offsets for the original measured variables for use in another notebook to correct the data\n",
    "# for the IOPs\n",
    "\n",
    "corrected_vars = ['fasttemp_corrected', 'slowtemp_corrected', 'RH_corrected', 'pressure_corrected']\n",
    "\n",
    "print(\"Biases to subtract:\")\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    print(PIPS_name)\n",
    "    for corrected_var in corrected_vars:\n",
    "        bias = conv_ds[corrected_var].bias_subtracted\n",
    "        print(f'{corrected_var}: {str(bias)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OLD CELLS BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the PIPS show high freq variations in slowT of roughly 0.5 deg C for some weird reason. \n",
    "# You can see that here\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['slowtemp'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_slowT', \n",
    "                                                                    ls='None', marker='o', ms=1., alpha=0.5) \n",
    "    \n",
    "    ax.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To clean it up, let's try this solution from ChatGPT that uses a butterworth low-pass filter\n",
    "\n",
    "from scipy.signal import butter, filtfilt\n",
    "\n",
    "# Load your dataset\n",
    "# ds = xr.open_dataset('path_to_your_dataset.nc')\n",
    "\n",
    "# For demonstration, let's create a sample DataArray\n",
    "# time = pd.date_range('2000-01-01', periods=200, freq='D')\n",
    "# data = np.random.rand(200)  # Random data for example\n",
    "# ds = xr.DataArray(data, coords=[time], dims=['time'])\n",
    "\n",
    "\n",
    "# Test on PIPS3A\n",
    "conv_ds = conv_ds_dict['PIPS3A']\n",
    "\n",
    "slow_temp = conv_ds['slowtemp']\n",
    "\n",
    "# Set your cutoff frequency (e.g., if your time unit is days, and you want to keep frequencies lower than 0.1/day)\n",
    "cutoff_frequency = 0.005  # Change as needed (units are in inverse seconds)\n",
    "\n",
    "# Design a Butterworth low-pass filter\n",
    "order = 6  # Filter order\n",
    "sampling_rate = 1  # Inverse of the sampling interval in units of your data\n",
    "nyquist_rate = 0.5 * sampling_rate\n",
    "normalized_cutoff = cutoff_frequency / nyquist_rate\n",
    "\n",
    "print(normalized_cutoff)\n",
    "b, a = butter(order, normalized_cutoff, btype='low', analog=False)\n",
    "\n",
    "# Apply the filter\n",
    "filtered_slow_temp = filtfilt(b, a, slow_temp.values)\n",
    "\n",
    "# Insert the filtered data back into an xarray DataArray\n",
    "slow_temp_filt = xr.DataArray(filtered_slow_temp, coords=slow_temp.coords, dims=slow_temp.dims)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the filtered data to see what it looks like\n",
    "fig, ax = plt.subplots()\n",
    "slow_temp_filt.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_slowT_filt', \n",
    "                                                           ls='None', marker='o', ms=1., alpha=0.5)\n",
    "slow_temp.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_slowT_filt', \n",
    "                                                      ls='None', marker='o', ms=1., alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hmmm... this is better but still doesn't quite do what I want. I have to set the cutoff frequency too low\n",
    "# Let's try a simple running mean\n",
    "\n",
    "# Apply a running mean with a window size of 60 s\n",
    "window_size = 60\n",
    "smoothed_slow_temp = slow_temp.rolling(time=window_size, center=True).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "smoothed_slow_temp.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_slowT_filt', \n",
    "                                                               ls='None', marker='o', ms=1., alpha=0.5)\n",
    "slow_temp.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_slowT_filt', \n",
    "                                                      ls='None', marker='o', ms=1., alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the timeseries of slowtemp and fasttemp\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['slowtemp'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_slowT', \n",
    "                                                                    ls='None', marker='o', ms=1., alpha=0.5)    \n",
    "plt.gca().set_prop_cycle(None)\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['fasttemp'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_fastT', \n",
    "                                                                    ls='None', marker='x', ms=5., alpha=0.75)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It looks like 3A and 3B have wonky slow-temp sensors that read too high. Let's take the differences between the\n",
    "# fast temp and slow temp obs and find the average difference\n",
    "\n",
    "diff_T_dict = {}\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_T = conv_ds_dict[PIPS_name]['slowtemp'] - conv_ds_dict[PIPS_name]['fasttemp']\n",
    "    diff_T_dict[PIPS_name] = diff_T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the time series of the slow-fast temp differences\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_T = diff_T_dict[PIPS_name]\n",
    "    diff_T.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_diff_T', \n",
    "                                                       ls='None', marker='o', ms=1., alpha=0.5)\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the mean differences and then subtract from the original slowtemp, storing in a new corrected slowtemp\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    diff_T = diff_T_dict[PIPS_name]\n",
    "    mean_diff_T = diff_T.mean().values\n",
    "    print(mean_diff_T)\n",
    "    conv_ds_dict[PIPS_name]['slowtemp_corrected'] = conv_ds_dict[PIPS_name]['slowtemp'].copy() - mean_diff_T\n",
    "    # Add the value subtracted to the attributes so we know that we modified it\n",
    "    conv_ds_dict[PIPS_name]['slowtemp_corrected'].attrs['bias_subtracted'] = mean_diff_T\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok, now plot the bias-corrected slowtemps along with the fasttemps\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp[:1]:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['slowtemp_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_slowT', \n",
    "                                                                              ls='None', marker='o', ms=1., alpha=0.5)    \n",
    "plt.gca().set_prop_cycle(None)\n",
    "\n",
    "for PIPS_name in PIPS_to_comp[:1]:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['fasttemp'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_fastT', \n",
    "                                                                    ls='None', marker='x', ms=5., alpha=0.75)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we need to recompute the dewpoint and RH_derived using the corrected slowtemps\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    pressure = conv_ds_dict[PIPS_name]['pressure']\n",
    "    slowtemp = conv_ds_dict[PIPS_name]['slowtemp_corrected']\n",
    "    fasttemp = conv_ds_dict[PIPS_name]['fasttemp']\n",
    "    RH = conv_ds_dict[PIPS_name]['RH']\n",
    "    dewpoint = thermo.calTdfromRH(pressure * 100., slowtemp + 273.15, RH / 100.) - 273.15\n",
    "    dewpoint.sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_dewpoint', \n",
    "                                                         ls='None', marker='o', ms=1., alpha=0.5)\n",
    "    RH_derived = thermo.calRH(pressure * 100., fasttemp + 273.15, dewpoint + 273.15) * 100.\n",
    "    \n",
    "    conv_ds_dict[PIPS_name]['dewpoint_corrected'] = conv_ds_dict[PIPS_name]['dewpoint'].copy()\n",
    "    conv_ds_dict[PIPS_name]['dewpoint_corrected'].data = dewpoint\n",
    "    \n",
    "    conv_ds_dict[PIPS_name]['RH_derived_corrected'] = conv_ds_dict[PIPS_name]['RH_derived'].copy()\n",
    "    conv_ds_dict[PIPS_name]['RH_derived_corrected'].data = RH_derived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the timeseries of RH and RH_derived\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['RH_derived'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_RH_derived', \n",
    "                                                              ls='None', marker='o', ms=1., alpha=0.5)    \n",
    "plt.gca().set_prop_cycle(None)\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['RH_derived_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_RH_derived_cor', \n",
    "                                                                    ls='None', marker='x', ms=5., alpha=0.75)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the timeseries of dewpoint\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    conv_ds = conv_ds_dict[PIPS_name]\n",
    "    conv_ds['dewpoint_corrected'].sel(time=slice(time_start, time_stop)).plot(ax=ax, label=f'{PIPS_name}_dewpoint'), \n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now resample the corrected slowtemp, dewpoint, and RH_derived to the parsivel times\n",
    "\n",
    "\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    PSD_datetimes = pips.get_PSD_datetimes(parsivel_ds_dict[PIPS_name]['VD_matrix'])\n",
    "    sec_offset = PSD_datetimes[0].second\n",
    "    print(sec_offset)\n",
    "    offset_str = pips.get_interval_str(sec_offset)\n",
    "    \n",
    "    slowtemp_corrected = conv_ds_dict[PIPS_name]['slowtemp_corrected']\n",
    "    new_slowtemp = slowtemp_corrected.resample(time=intervalstr, label='right', closed='right', \n",
    "                                               offset=offset_str).mean()\n",
    "    dewpoint_corrected = conv_ds_dict[PIPS_name]['dewpoint_corrected']\n",
    "    new_dewpoint = dewpoint_corrected.resample(time=intervalstr, label='right', closed='right', \n",
    "                                               offset=offset_str).mean()\n",
    "    RH_derived_corrected = conv_ds_dict[PIPS_name]['RH_derived_corrected']\n",
    "    new_RH_derived = RH_derived_corrected.resample(time=intervalstr, label='right', closed='right', \n",
    "                                                   offset=offset_str).mean()\n",
    "    \n",
    "    parsivel_ds_dict[PIPS_name]['slowtemp_corrected'] = new_slowtemp\n",
    "    parsivel_ds_dict[PIPS_name]['dewpoint_corrected'] = new_dewpoint\n",
    "    parsivel_ds_dict[PIPS_name]['RH_derived_corrected'] = new_RH_derived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for PIPS_name in PIPS_to_comp:\n",
    "    parsivel_ds_dict[PIPS_name]['RH_derived_corrected'].plot(ax=ax, label=f'{PIPS_name}_RH_derived_corrected', \n",
    "                                                             ls='None', marker='o', ms=1., alpha=0.75)\n",
    "    parsivel_ds_dict[PIPS_name]['RH_derived'].plot(ax=ax, label=f'{PIPS_name}_RH_derived', \n",
    "                                                   ls='None', marker='x', ms=5., alpha=0.5)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now save to new output directory\n",
    "for PIPS_name, output_parsivel_filepath, output_conv_filepath in zip(PIPS_names, \n",
    "                                                                     output_parsivel_filepaths, \n",
    "                                                                     output_conv_filepaths):\n",
    "    if PIPS_name in PIPS_to_comp:\n",
    "        print(PIPS_name)\n",
    "        \n",
    "        \n",
    "        print(\"Saving {}\".format(output_parsivel_filepath))\n",
    "        parsivel_ds_dict[PIPS_name].to_netcdf(output_parsivel_filepath)\n",
    "        print(\"Saving {}\".format(output_conv_filepath))\n",
    "        conv_ds_dict[PIPS_name].to_netcdf(output_conv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pyPIPS]",
   "language": "python",
   "name": "conda-env-pyPIPS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

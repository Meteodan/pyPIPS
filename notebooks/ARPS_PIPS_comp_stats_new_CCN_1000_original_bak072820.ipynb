{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T17:38:11.308401Z",
     "start_time": "2020-07-08T17:38:07.043707Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "#%set_env PROJ_LIB=/depot/dawson29/apps/condaenv/envs/cent7/5.1.0-py27/pyPIPS/share/proj\n",
    "# %set_env LD_LIBRARY_PATH=/apps/cent7/intel/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64\n",
    "# %set_env LIBRARY_PATH=/apps/cent7/intel/compilers_and_libraries_2017.1.132/linux/compiler/lib/intel64\n",
    "#import pyCRMtools.modules.dualpara as dualpol\n",
    "#import pyPIPS.dualpara as dualpol\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid,make_axes_locatable,host_subplot\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import pytz as pytz\n",
    "import sys\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "import pyPIPS.simulator as sim\n",
    "import pyPIPS.radarmodule as pyPIPSradar\n",
    "import pyPIPS.PIPS as pips\n",
    "import pyPIPS.pips_io as pips_io\n",
    "import pyPIPS.parsivel_qc as pqc\n",
    "import pyPIPS.parsivel_params as pp\n",
    "from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "from pyCRMtools.pycaps import arps_read\n",
    "from pyCRMtools.pycaps import pycaps_fields\n",
    "from pyCRMtools.pycaps import calvars_radar as radar\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy.random as random\n",
    "from scipy.stats import gamma, uniform\n",
    "from scipy.special import gamma as gammafunc\n",
    "from scipy import ndimage\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.calc import wind_components as get_wind_components\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.plots.wx_symbols import current_weather, sky_cover\n",
    "from metpy.units import units\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:00:19.237761Z",
     "start_time": "2020-05-13T17:00:18.942836Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in nc files with PIPS data and ARPS model data interpolated to PIPS locations.\n",
    "# PIPS data should be interpolated already to ARPS times in these files.\n",
    "\n",
    "input_dir = '/depot/dawson29/data/Projects/VORTEXSE/simulations/ARPS/2017_IOP4C/EnKF/PIPS/nc/CCN1000_original/'\n",
    "#input_dir = '/Volumes/scr_fast/Projects/VORTEXSE/obsdata/full_PIPS_dataset/SATP_retr/ARPS_at_PIPS'\n",
    "deployment_name = 'IOP4C_D1_2017'\n",
    "input_file_paths = glob.glob(input_dir + '/*{}*nc'.format(deployment_name))\n",
    "PIPS_ARPS_ds_list = []\n",
    "for input_file in input_file_paths:\n",
    "    PIPS_ARPS_ds_list.append(xr.open_dataset(input_file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:00:22.052191Z",
     "start_time": "2020-05-13T17:00:21.943887Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(PIPS_ARPS_ds_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:00:37.007052Z",
     "start_time": "2020-05-13T17:00:36.916867Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyPIPS.polarimetric as pol\n",
    "min_diameters = pp.parsivel_parameters['min_diameter_bins_mm']\n",
    "mid_diameters = pp.parsivel_parameters['avg_diameter_bins_mm']\n",
    "max_diameters = pp.parsivel_parameters['max_diameter_bins_mm']\n",
    "mid_fallspeeds = pp.parsivel_parameters['avg_fallspeed_bins_mps']\n",
    "wavelength = 10.7\n",
    "scatt_file = '/home/cbelak/pyPIPS/tmatrix/S-Band/SCTT_RAIN_fw100.dat'\n",
    "bin_width = pp.parsivel_parameters['max_diameter_bins_mm'] - pp.parsivel_parameters['min_diameter_bins_mm']\n",
    "plotdir = '/depot/dawson29/data/Projects/VORTEXSE/simulations/ARPS/2017_IOP4C/EnKF/PIPS/plots/CCN1000_original/'\n",
    "#plotdir = '/Volumes/scr_fast/Projects/VORTEXSE/obsdata/full_PIPS_dataset/SATP_retr/plots/ARPS_at_PIPS'\n",
    "meteogram_plotdir = os.path.join(plotdir, 'meteograms')\n",
    "if not os.path.exists(meteogram_plotdir):\n",
    "    os.makedirs(meteogram_plotdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:01:01.067411Z",
     "start_time": "2020-05-13T17:00:52.567107Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot observed DSD meteograms interpolated to model times\n",
    "# Get PSD times valid at the model times\n",
    "\n",
    "PSD_datetimes_model = pips.get_PSD_datetimes(PIPS_ARPS_ds_list[0], dim_name='time')\n",
    "PSD_datetimes_model_dict = pips.get_PSD_time_bins(PSD_datetimes_model)\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "# Prepare axis parameters\n",
    "# We'll use the model times for the boundaries of the x-axis\n",
    "timelimits = [PSDstarttimes[0], PSDstarttimes[-1]]\n",
    "diamlimits = [0.0, 9.0]\n",
    "diamytick = 1.0\n",
    "DSDtype = 'observed'\n",
    "locator = dates.MinuteLocator(byminute=[0,15,30,45])\n",
    "minorlocator = dates.MinuteLocator(byminute=range(0,60,5))\n",
    "dateformat = '%H:%M'\n",
    "formatter = dates.DateFormatter(dateformat)\n",
    "\n",
    "axparams = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "            'minorxlocator': minorlocator,\n",
    "            'axeslimits': [timelimits, diamlimits],\n",
    "            'majorylocator': ticker.MultipleLocator(base=diamytick),\n",
    "            'axeslabels': [None, 'D (mm)']}\n",
    "\n",
    "# Ok, now we should have everything ready to go to plot the meteograms.\n",
    "# Let'er rip!\n",
    "for PIPS_ARPS_ds in PIPS_ARPS_ds_list:\n",
    "    ND = PIPS_ARPS_ds['ND_qc']\n",
    "    logND = np.log10(ND)\n",
    "    D0 = dsd.calc_D0_bin(ND) * 1000. # Get to mm\n",
    "    dualpol_PIPS = pol.calpolrain(wavelength, scatt_file, ND, bin_width)\n",
    "    dBZ = dualpol_PIPS['REF']\n",
    "    ZDR = dualpol_PIPS['ZDR']\n",
    "    \n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'D_0': D0, 'REF': dBZ, 'ZDR': ZDR}\n",
    "    \n",
    "    dis_plot_name = PIPS_ARPS_ds.probe_name + '_interp_to_model_' + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_plotdir, axparams, disvars, close_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:04:15.639454Z",
     "start_time": "2020-05-13T17:04:07.521523Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "member = 40\n",
    "for PIPS_ARPS_ds in PIPS_ARPS_ds_list:\n",
    "    ND_ARPS = PIPS_ARPS_ds['ND'].sel(member=member) / 1000. # Get to m^-3 mm^-1 TODO: really need to make this\n",
    "                                                            # consistent with PIPS ND...\n",
    "    logND_ARPS = np.log10(ND_ARPS)\n",
    "    logND_ARPS = logND_ARPS.where(logND_ARPS >= -1.)\n",
    "    D0_ARPS = dsd.calc_D0_bin(ND_ARPS) * 1000. # Get to mm\n",
    "    dualpol_ARPS = pol.calpolrain(wavelength, scatt_file, ND_ARPS, bin_width)\n",
    "    dBZ = dualpol_ARPS['REF']\n",
    "    ZDR = dualpol_ARPS['ZDR']\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND_ARPS.T, 'D_0': D0_ARPS, 'REF': dBZ, 'ZDR': ZDR}\n",
    "    \n",
    "    dis_plot_name = '{}_raw_model_member_{:d}'.format(PIPS_ARPS_ds.probe_name, member)\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_plotdir, axparams, disvars, close_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:12:45.146864Z",
     "start_time": "2020-05-13T17:12:44.989746Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a combined DataArray for all the ensemble members and then convert to a DataFrame for use in seaborn\n",
    "PIPS_time_range = {\n",
    "    'PIPS1A': [datetime(2017, 4, 30, 18, 30), datetime(2017, 4, 30, 19, 30)],\n",
    "    'PIPS1B': [datetime(2017, 4, 30, 18, 30), datetime(2017, 4, 30, 19, 30)],\n",
    "    'PIPS2B': [datetime(2017, 4, 30, 18, 30), datetime(2017, 4, 30, 19, 30)]\n",
    "}\n",
    "\n",
    "PIPS_names = [PIPS_ARPS_ds.probe_name for PIPS_ARPS_ds in PIPS_ARPS_ds_list]\n",
    "PIPS_to_plot = 'PIPS1A'\n",
    "PIPS_to_plot_index = PIPS_names.index(PIPS_to_plot)\n",
    "\n",
    "# D0_raw_model_list = []\n",
    "# for PIPS_ARPS_ds in PIPS_ARPS_ds_list:\n",
    "#     D0_raw_model_list.append(dsd.calc_D0_bin(PIPS_ARPS_ds['ND']) * 1000.)\n",
    "# D0_raw_model_combined = xr.concat(D0_raw_model_list, xr.DataArray(PIPS_names, dims='PIPS'))\n",
    "# print(D0_raw_model_combined)\n",
    "ND = PIPS_ARPS_ds_list[PIPS_to_plot_index]['ND']\n",
    "D0_raw_model_combined = dsd.calc_D0_bin(ND) * 1000.\n",
    "D0_raw_model_combined_df = D0_raw_model_combined.to_dataframe(name='D0')\n",
    "print(D0_raw_model_combined_df)\n",
    "\n",
    "\n",
    "\n",
    "# # D0\n",
    "# D0_raw_model_list = [D0_raw_model_dict[PIPS_to_plot].reset_coords(drop=True) \n",
    "#                             for D0_raw_model_dict in D0_raw_model_dict_list]\n",
    "# D0_raw_model_combined = xr.concat(D0_raw_model_list, dim='member')\n",
    "# D0_raw_model_combined_df = D0_raw_model_combined.to_dataframe(name='D0')\n",
    "\n",
    "\n",
    "# # Reflectivity\n",
    "\n",
    "# dBZ_raw_model_list = [dBZ_raw_model_dict[PIPS_to_plot].reset_coords(drop=True) \n",
    "#                             for dBZ_raw_model_dict in dBZ_raw_model_dict_list]\n",
    "# dBZ_raw_model_combined = xr.concat(dBZ_raw_model_list, dim='member')\n",
    "# dBZ_raw_model_combined_df = dBZ_raw_model_combined.to_dataframe(name='dBZ')\n",
    "\n",
    "# # ZDR\n",
    "\n",
    "# ZDR_raw_model_list = [dualpol_raw_model_dict[PIPS_to_plot]['ZDR'].reset_coords(drop=True) \n",
    "#                             for dualpol_raw_model_dict in dualpol_raw_model_dict_list]\n",
    "# ZDR_raw_model_combined = xr.concat(ZDR_raw_model_list, dim='member')\n",
    "# ZDR_raw_model_combined_df = ZDR_raw_model_combined.to_dataframe(name='ZDR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:12:48.383759Z",
     "start_time": "2020-05-13T17:12:47.403071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot a timeseries of D0 with confidence intervals from the model ensemble\n",
    "import seaborn as sns\n",
    "\n",
    "#PSD_datetimes_model = pips.get_PSD_datetimes(var_ds, dim_name='time')\n",
    "#PSD_datetimes_model_dict = pips.get_PSD_time_bins(PSD_datetimes_model)\n",
    "#PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "#PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "ND = PIPS_ARPS_ds_list[PIPS_to_plot_index]['ND_qc']\n",
    "D0_obs = dsd.calc_D0_bin(ND) * 1000. # Get to mm\n",
    "D0_raw_model_combined_df_test = D0_raw_model_combined_df.copy()\n",
    "D0_raw_model_combined_df_test.reset_index(inplace=True)\n",
    "g = sns.relplot(x=\"time\", y=\"D0\", kind=\"line\", ci=\"sd\", data=D0_raw_model_combined_df_test, label='Model')\n",
    "g.fig.set_size_inches(8., 3., forward = True)\n",
    "g.fig.autofmt_xdate()\n",
    "g.set_ylabels(r'$D_0$ (mm)')\n",
    "g.ax.plot(PSDmidtimes, D0_obs, 'r', label='Obs')\n",
    "plt.legend(loc='best')\n",
    "g.ax.set_xlim(PIPS_time_range[PIPS_to_plot])\n",
    "\n",
    "figname = '{}_model_obs_D0_original.png'.format(PIPS_to_plot)\n",
    "figpath = os.path.join(meteogram_plotdir, figname)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:12:48.383759Z",
     "start_time": "2020-05-13T17:12:47.403071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot a timeseries of D0 with confidence intervals from the model ensemble\n",
    "import seaborn as sns\n",
    "\n",
    "#PSD_datetimes_model = pips.get_PSD_datetimes(var_ds, dim_name='time')\n",
    "#PSD_datetimes_model_dict = pips.get_PSD_time_bins(PSD_datetimes_model)\n",
    "#PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "#PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "ND = PIPS_ARPS_ds_list[PIPS_to_plot_index]['ND_qc']\n",
    "D0_obs = dsd.calc_D0_bin(ND) * 1000. # Get to mm\n",
    "D0_raw_model_combined_df_test = D0_raw_model_combined_df.copy()\n",
    "D0_raw_model_combined_df_test.reset_index(inplace=True)\n",
    "g = sns.relplot(x=\"time\", y=\"D0\", kind=\"line\", ci=95, data=D0_raw_model_combined_df_test, label='Model')\n",
    "g.fig.set_size_inches(8., 3., forward = True)\n",
    "g.fig.autofmt_xdate()\n",
    "g.set_ylabels(r'$D_0$ (mm)')\n",
    "g.ax.plot(PSDmidtimes, D0_obs, 'r', label='Obs')\n",
    "plt.legend(loc='best')\n",
    "g.ax.set_xlim(PIPS_time_range[PIPS_to_plot])\n",
    "\n",
    "figname = '{}_model_obs_D0_new.png'.format(PIPS_to_plot)\n",
    "figpath = os.path.join(meteogram_plotdir, figname)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T18:40:25.895153Z",
     "start_time": "2020-07-08T18:40:22.757365Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot a timeseries of D0 with confidence intervals from the model ensemble\n",
    "import seaborn as sns\n",
    "\n",
    "#PSD_datetimes_model = pips.get_PSD_datetimes(var_ds, dim_name='time')\n",
    "#PSD_datetimes_model_dict = pips.get_PSD_time_bins(PSD_datetimes_model)\n",
    "#PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "#PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "ND = PIPS_ARPS_ds_list[PIPS_to_plot_index]['ND_qc']\n",
    "D0_obs = dsd.calc_D0_bin(ND) * 1000. # Get to mm\n",
    "D0_obs_df = D0_obs.to_dataframe(name='D0_obs')\n",
    "D0_raw_model_combined_df_test = D0_raw_model_combined_df.copy()\n",
    "D0_raw_model_combined_df_test.reset_index(inplace=True)\n",
    "fig, ax = plt.subplots(figsize=(8,3))\n",
    "# Create a new axes object \"ax2\" that is a twin of ax\n",
    "ax2 = ax.twinx()\n",
    "#g = sns.boxplot(x=\"time\", y=\"D0\",data=D0_raw_model_combined_df_test, ax=ax)\n",
    "#g.fig.set_size_inches(8., 3., forward = True)\n",
    "ax.set_ylabel(r'$D_0$ (mm)')\n",
    "#D0_obs_df.reset_index(inplace=True)\n",
    "#sns.lineplot(x=\"time\", y=\"D0\", data=D0_raw_model_combined_df_test, label='Model', ax=ax)\n",
    "#sns.lineplot(x=\"time\", y=\"D0_obs\", data=D0_obs_df, label='Obs', ax=ax)\n",
    "sns.boxplot(x=\"time\", y=\"D0\",data=D0_raw_model_combined_df_test, ax=ax)\n",
    "# Plot the observation line plot on ax2 instead of ax, and give it a simple range of indices\n",
    "# from 0 to the length of the D0_obs_df Dataframe, that is, the number of times.\n",
    "ax2.plot(np.arange(len(D0_obs_df)), D0_obs_df['D0_obs'].values, label='Obs')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "# Code snippet from https://stackoverflow.com/questions/53528054/\n",
    "# the-most-elegant-way-to-modify-messy-and-overlapping-date-labels-below-x-axis\n",
    "\n",
    "# set the frequency for labelling the xaxis\n",
    "freq = int(10)\n",
    "# set the xlabels as the datetime data for the given labelling frequency,\n",
    "# also use only the date for the label\n",
    "ax.set_xticklabels(D0_raw_model_combined_df_test.iloc[::freq].time.dt.time)\n",
    "# set the xticks at the same frequency as the xlabels\n",
    "xtix = ax.get_xticks()\n",
    "ax.set_xticks(xtix[::freq])\n",
    "# nicer label format for dates\n",
    "fig.autofmt_xdate()\n",
    "\n",
    "# Set the two axes to have the same y-range. Very important!\n",
    "ax.set_ylim(0., 3.0)\n",
    "ax2.set_ylim(0., 3.0)\n",
    "# Turns of the y ticks and labels for the right side of the graph that would otherwise be placed there\n",
    "plt.tick_params(axis='y', which='both', right=False, labelright=False)\n",
    "\n",
    "figname = '{}_model_obs_D0_box_new_2.png'.format(PIPS_to_plot)\n",
    "figpath = os.path.join(meteogram_plotdir, figname)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:12:48.383759Z",
     "start_time": "2020-05-13T17:12:47.403071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot a timeseries of D0 with confidence intervals from the model ensemble\n",
    "import seaborn as sns\n",
    "import matplotlib.colors \n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "#PSD_datetimes_model = pips.get_PSD_datetimes(var_ds, dim_name='time')\n",
    "#PSD_datetimes_model_dict = pips.get_PSD_time_bins(PSD_datetimes_model)\n",
    "#PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "#PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "ND = PIPS_ARPS_ds_list[PIPS_to_plot_index]['ND_qc']\n",
    "D0_obs = dsd.calc_D0_bin(ND) * 1000. # Get to mm\n",
    "D0_raw_model_combined_df_test = D0_raw_model_combined_df.copy()\n",
    "D0_raw_model_combined_df_test.reset_index(inplace=True)\n",
    "\n",
    "palette = sns.cubehelix_palette(light=0.7,n_colors=6)\n",
    "g = sns.relplot(x=\"time\", y=\"D0\", hue=\"D0\",data=D0_raw_model_combined_df_test, label=\"Model\")\n",
    "\n",
    "#g.ax.plot(time, D0, 'b', kind=\"line\", data=D0_raw_model_combined_df_test, label=\"Model\")\n",
    "\n",
    "g.fig.set_size_inches(8., 3., forward = True)\n",
    "g.fig.autofmt_xdate()\n",
    "g.set_ylabels(r'$D_0$ (mm)')\n",
    "g.ax.plot(PSDmidtimes, D0_obs, 'r', label='Obs')\n",
    "plt.legend(loc='best')\n",
    "g.ax.set_xlim(PIPS_time_range[PIPS_to_plot])\n",
    "g._legend.remove()\n",
    "\n",
    "figname = '{}_model_obs_D0_color.png'.format(PIPS_to_plot)\n",
    "figpath = os.path.join(meteogram_plotdir, figname)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-13T17:12:48.383759Z",
     "start_time": "2020-05-13T17:12:47.403071Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot a timeseries of D0 with confidence intervals from the model ensemble\n",
    "import seaborn as sns\n",
    "import matplotlib.colors \n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "#PSD_datetimes_model = pips.get_PSD_datetimes(var_ds, dim_name='time')\n",
    "#PSD_datetimes_model_dict = pips.get_PSD_time_bins(PSD_datetimes_model)\n",
    "#PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "#PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "ND = PIPS_ARPS_ds_list[PIPS_to_plot_index]['ND_qc']\n",
    "D0_obs = dsd.calc_D0_bin(ND) * 1000. # Get to mm\n",
    "D0_raw_model_combined_df_test = D0_raw_model_combined_df.copy()\n",
    "D0_raw_model_combined_df_test.reset_index(inplace=True)\n",
    "\n",
    "palette = sns.cubehelix_palette(light=0.7,n_colors=6)\n",
    "g = sns.relplot(x=\"time\", y=\"D0\",data=D0_raw_model_combined_df_test)\n",
    "\n",
    "#g.ax.plot(time, D0, 'b', kind=\"line\", data=D0_raw_model_combined_df_test, label=\"Model\")\n",
    "\n",
    "g.fig.set_size_inches(8., 3., forward = True)\n",
    "g.fig.autofmt_xdate()\n",
    "g.set_ylabels(r'$D_0$ (mm)')\n",
    "g.ax.plot(PSDmidtimes, D0_obs, 'r', label='Obs')\n",
    "plt.legend(loc='best')\n",
    "g.ax.set_xlim(PIPS_time_range[PIPS_to_plot])\n",
    "#g._legend.remove()\n",
    "\n",
    "figname = '{}_model_obs_D0_spread.png'.format(PIPS_to_plot)\n",
    "figpath = os.path.join(meteogram_plotdir, figname)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZDR\n",
    "ZDR_obs = dualpol_PIPS_interp_to_model_times_dict[PIPS_to_plot]['ZDR']\n",
    "ZDR_raw_model_combined_df_test = ZDR_raw_model_combined_df.copy()\n",
    "ZDR_raw_model_combined_df_test.reset_index(inplace=True)\n",
    "g = sns.relplot(x=\"time\", y=\"ZDR\", kind=\"line\", ci=\"sd\", data=ZDR_raw_model_combined_df_test, label='Model')\n",
    "g.fig.set_size_inches(8., 3., forward = True)\n",
    "g.fig.autofmt_xdate()\n",
    "g.set_ylabels(r'$Z_{DR}$ (dB)')\n",
    "g.ax.plot(PSDmidtimes, ZDR_obs, 'r', label='Obs')\n",
    "plt.legend(loc='best')\n",
    "g.ax.set_xlim(PIPS_time_range[PIPS_to_plot])\n",
    "\n",
    "figname = '{}_model_obs_ZDR.png'.format(PIPS_to_plot)\n",
    "figpath = os.path.join(meteogram_plotdir, figname)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ZDR\n",
    "ZDR_obs = dualpol_PIPS_interp_to_model_times_dict[PIPS_to_plot]['ZDR']\n",
    "ZDR_raw_model_combined_df_test = ZDR_raw_model_combined_df.copy()\n",
    "ZDR_raw_model_combined_df_test.reset_index(inplace=True)\n",
    "g = sns.relplot(x=\"time\", y=\"ZDR\", kind=\"line\", ci=\"sd\", data=ZDR_raw_model_combined_df_test, label='Model')\n",
    "g.fig.set_size_inches(8., 3., forward = True)\n",
    "g.fig.autofmt_xdate()\n",
    "g.set_ylabels(r'$Z_{DR}$ (dB)')\n",
    "g.ax.plot(PSDmidtimes, ZDR_obs, 'r', label='Obs')\n",
    "plt.legend(loc='best')\n",
    "g.ax.set_xlim(PIPS_time_range[PIPS_to_plot])\n",
    "\n",
    "figname = '{}_model_obs_ZDR.png'.format(PIPS_to_plot)\n",
    "figpath = os.path.join(meteogram_plotdir, figname)\n",
    "plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the raw model DSDs (interpolated to PIPS locations but not the times)\n",
    "\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "for member, logND_model_raw_PIPS_dict in enumerate(logND_model_raw_PIPS_dict_list):\n",
    "    for i, dis_name in enumerate(dis_names):\n",
    "        logND = logND_model_raw_PIPS_dict[dis_name]\n",
    "        logND = logND.where(logND > -1.0)\n",
    "        D0 = D0_raw_model_dict[dis_name] * 1000. # Get to mm again\n",
    "        dBZ = dBZ_raw_model_dict[dis_name]\n",
    "        ZDR = dualpol_raw_model_dict[dis_name]['ZDR']\n",
    "        disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "                   'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'D_0': D0, 'dBZ': dBZ, 'ZDR': ZDR}\n",
    "        dis_plot_name = dis_name + '_raw_model_member_{:02d}_'.format(member+1) + DSDtype\n",
    "        PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_plotdir, axparams, disvars, close_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now plot the mean raw model DSDs (interpolated to PIPS locations but not the times)\n",
    "\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND_all = logND_model_raw_combined_da.isel(PIPS=i)\n",
    "    logND_mean = logND_all.mean(dim='member')\n",
    "    logND_mean = logND_mean.where(logND_mean > -1.0)\n",
    "#     D0 = D0_raw_model_dict[dis_name] * 1000. # Get to mm again\n",
    "#     dBZ = dBZ_raw_model_dict[dis_name]\n",
    "#     ZDR = dualpol_raw_model_dict[dis_name]['ZDR']\n",
    "#     disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "#                'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'D_0': D0, 'dBZ': dBZ, 'ZDR': ZDR}\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND_mean.T}\n",
    "    dis_plot_name = dis_name + '_raw_model_member_mean_' + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_plotdir, axparams, disvars, close_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now compute sampled PSDs from the model\n",
    "DSDtype = 'observed'\n",
    "# Now plot the sampled model DSD\n",
    "\n",
    "sampling_interval = 60.\n",
    "sampling_length = pp.parsivel_parameters['sensor_length_mm'] / 1000. # To m\n",
    "sampling_width = pp.parsivel_parameters['sensor_width_mm'] / 1000. # To m\n",
    "\n",
    "Dmax = 9.\n",
    "Dmax_index = np.searchsorted(mid_diameters, Dmax, side='right')\n",
    "# print(Dmax_index)\n",
    "mid_diameters_trunc = np.array(mid_diameters[:Dmax_index+1]) / 1000.\n",
    "min_diameters_trunc = np.array(min_diameters[:Dmax_index+1]) / 1000.\n",
    "max_diameters_trunc = np.array(max_diameters[:Dmax_index+1]) / 1000.\n",
    "\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "D0_sample_dict_list = []\n",
    "ND_sample_dict_list = []\n",
    "dBZ_sample_dict_list = []\n",
    "dualpol_sample_dict_list = []\n",
    "\n",
    "for member, var_ds_interp in enumerate(var_ds_interp_list):\n",
    "\n",
    "    D0_sample_dict = {}\n",
    "    ND_sample_dict = {}\n",
    "    dBZ_sample_dict = {}\n",
    "    dualpol_sample_dict = {}\n",
    "\n",
    "    for dis_name in dis_names:\n",
    "        nr_model = var_ds_interp['nr'].loc[dict(PIPS=dis_name)].values\n",
    "        lamdar_model = var_ds_interp['lamdar'].loc[dict(PIPS=dis_name)].values\n",
    "        alphar_model = var_ds_interp['alphar'].loc[dict(PIPS=dis_name)].values\n",
    "        rho_model = var_ds_interp['rho'].loc[dict(PIPS=dis_name)].values\n",
    "\n",
    "        # print(mid_diameters_trunc.shape)\n",
    "        Vtr = pips.calc_empirical_fallspeed(mid_diameters_trunc * 1000., correct_rho=True, rho=rho_model)\n",
    "\n",
    "        Vtr = Vtr.T\n",
    "    #     print(Vtr[0])\n",
    "    #     print(Vtr.shape)\n",
    "    #     print(mid_diameters_trunc.shape)\n",
    "        ND_samp_series = np.zeros((np.size(PSDmidtimes), np.size(mid_diameters_trunc)))\n",
    "\n",
    "    #     print(ND_samp_series.shape)\n",
    "    #     print(nr_model[0])\n",
    "        # Nc_bin_tmp2 = np.zeros((np.size(N0r), np.size(D[:Dmax_index+1])))\n",
    "        # Nc_bin2 = np.zeros((np.size(np.array(sampling_times)), np.size(D[:Dmax_index+1])))\n",
    "\n",
    "        all_valid = (not np.isnan(lamdar_model[0]) and (not np.isnan(alphar_model[0])) and (not np.isnan(nr_model[0])))\n",
    "        if all_valid:\n",
    "            # Special treatment for first sampling time. Just assume DSD valid at that time was constant for the previous \n",
    "            # sampling interval\n",
    "            sample_dict = sim.create_random_gamma_DSD(nr_model[0], lamdar_model[0], \n",
    "                                                      alphar_model[0], Vtr[0], sampling_length, \n",
    "                                                      sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                                      max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                                      remove_margins=True, rhocorrect=True, rho=rho_model[0], verbose=False)\n",
    "\n",
    "\n",
    "            ND_sample = sample_dict['ND']\n",
    "            pcount_binned_sample = sample_dict['pcount_binned']\n",
    "        #     print(ND_sample.shape)\n",
    "        #     print(ND_samp_series.shape)\n",
    "            ND_samp_series[0, :] = 1.e-3*ND_sample\n",
    "            # Nc_bin_tmp2[0, :] = 1.e-3*ND_sample\n",
    "            # Nc_bin2[0, :] = Nc_bin_tmp2[0, :]\n",
    "\n",
    "\n",
    "        pcount_binned_samples = []\n",
    "        for index in range(np.size(PSDmidtimes[1:])):\n",
    "            all_valid = (not np.isnan(lamdar_model[index]) \n",
    "                         and (not np.isnan(alphar_model[index]))\n",
    "                         and (not np.isnan(nr_model[index])))\n",
    "            # print('nr = ', nr_model[index], 'lamdar = ', lamdar_model[index], 'alphar = ', alphar_model[index])\n",
    "            if all_valid:\n",
    "                sample_dict = sim.create_random_gamma_DSD(nr_model[index], lamdar_model[index], \n",
    "                                                          alphar_model[index], Vtr[index], sampling_length, \n",
    "                                                          sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                                          max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                                          remove_margins=True, rhocorrect=True, rho=rho_model[index], verbose=False)\n",
    "                ND_sample = sample_dict['ND']\n",
    "                pcount_binned_samples.append(sample_dict['pcount_binned'])\n",
    "                ND_samp_series[index, :] = 1.e-3*ND_sample\n",
    "            else:\n",
    "                pcount_binned_samples.append(np.zeros(np.size(mid_diameters_trunc)+1))\n",
    "                #pcount_binned_samples.append(np.zeros_like(sample_dict['pcount_binned']))\n",
    "\n",
    "        pcount_binned_samples = np.array(pcount_binned_samples)\n",
    "\n",
    "        ND_samp_da = xr.DataArray(ND_samp_series,\n",
    "                                         coords={'time': PSD_datetimes_model_dict['PSD_datetimes_edges'][:-1],\n",
    "                                                 'diameter': ('diameter_bin', mid_diameters_trunc * 1000.),\n",
    "                                                 'max_diameter': ('diameter_bin', max_diameters_trunc * 1000.),\n",
    "                                                 'min_diameter': ('diameter_bin', min_diameters_trunc * 1000.)\n",
    "                                                },\n",
    "                                         dims=['time', 'diameter_bin'])\n",
    "\n",
    "        ND_samp_da = ND_samp_da.fillna(0.0)\n",
    "\n",
    "        # sampling_volumes_D = sim.calc_sampling_volumes_D(Vtr, Dr, Dmax, sampling_interval, sampling_area)\n",
    "        # for s, sample_index in enumerate(sample_indices[:-1]):\n",
    "        #     sample_index_end = sample_indices[s+1]\n",
    "        #     current_sample_indices = slice(sample_index, sample_index_end, None)\n",
    "        #     pcount_binned = np.sum(pcount_binned_samples[current_sample_indices], axis=0)\n",
    "        #     Nc_bin2[s+1, :] = 1.e-3*sim.calc_ND(pcount_binned, sampling_volumes_D, Dr, Dl, Dmax)\n",
    "        # #     Nc_bin2[s+1, :] = np.sum(Nc_bin_tmp2[current_sample_indices, :]*dt[current_sample_indices, None], axis = 0)/sampling_interval\n",
    "        # #     print \"s = \", s\n",
    "        # #     print \"sample time (beginning) = \", sampling_times[s]\n",
    "        # #     print \"sample time (end) = \", sampling_times[s+1]\n",
    "        # #     print \"dt[current_sample_indices] = \", dt[current_sample_indices]\n",
    "        # #     print \"Nc_bin_tmp = \", Nc_bin_tmp[current_sample_indices, :], dt[current_sample_indices]\n",
    "        # #     print \"Nc_bin = \", Nc_bin[s+1, :]\n",
    "\n",
    "        logND_samp_da = np.log10(ND_samp_da)\n",
    "        logND_samp_da = logND_samp_da.where(logND_samp_da > -1.0)\n",
    "\n",
    "        # Compute dBZ and D0 from the sampled DSD\n",
    "        dBZ_samp_model = dsd.calc_dBZ_from_bins(ND_samp_da)\n",
    "        dBZ_samp_model = dBZ_samp_model.where(dBZ_samp_model > -np.inf)\n",
    "        D0_samp_model = dsd.calc_D0_bin(ND_samp_da) * 1000. # Get to mm again\n",
    "        pol_samp_model_dict = pol.calpolrain(wavelength, scatt_file, ND_samp_da, bin_width)\n",
    "\n",
    "        dBZ_sample_dict[dis_name] = dBZ_samp_model\n",
    "        D0_sample_dict[dis_name] = D0_samp_model\n",
    "        dualpol_sample_dict[dis_name] = pol_samp_model_dict\n",
    "        ND_sample_dict[dis_name] = ND_samp_da\n",
    "\n",
    "        disvars = {'min_diameter': min_diameters[:Dmax_index+1], 'PSDstarttimes': PSDstarttimes,\n",
    "                   'PSDmidtimes': PSDmidtimes, 'logND': logND_samp_da.T, 'D_0': D0_samp_model, \n",
    "                   'dBZ': dBZ_samp_model, 'ZDR': pol_samp_model_dict['ZDR']}\n",
    "        dis_plot_name = dis_name + '_sampled_model_member_{:02d}_'.format(member+1) + DSDtype\n",
    "        PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_plotdir, axparams, disvars, close_fig=True)\n",
    "    \n",
    "    D0_sample_dict_list.append(D0_sample_dict)\n",
    "    ND_sample_dict_list.append(ND_sample_dict)\n",
    "    dBZ_sample_dict_list.append(dBZ_sample_dict)\n",
    "    dualpol_sample_dict_list.append(dualpol_sample_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some statistical comparison plots\n",
    "\n",
    "# Make some one-to-one plots of D0 (model) vs. D0 (disdrometer)\n",
    "\n",
    "yvals = pp.parsivel_parameters['avg_diameter_bins_mm']\n",
    "xvals = yvals\n",
    "\n",
    "color_list = ['r', 'orange', 'g', 'b']\n",
    "\n",
    "fig_all, ax_all = plt.subplots(figsize=(8,8))\n",
    "\n",
    "for d, dis_name in enumerate(dis_names):\n",
    "    obs = D0_PIPS_interp_to_model_times_dict[dis_name] * 1000.\n",
    "    mod = D0_raw_model_dict[dis_name] * 1000.\n",
    "    mod_sampled = D0_sample_dict[dis_name]\n",
    "    bias_mod = ((np.nansum(mod - obs)) / np.nansum(obs))\n",
    "    bias_mod_sampled = ((np.nansum(mod_sampled - obs)) / np.nansum(obs))\n",
    "    cc_mod = pd.DataFrame({'obs': obs, 'mod': mod}).corr().iloc[0, 1]\n",
    "    cc_mod_sampled = pd.DataFrame({'obs': obs, 'mod': mod_sampled}).corr().iloc[0, 1]\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.scatter(obs, mod, c=color_list[d], marker='*', label=dis_name+'_gamma')\n",
    "    plt.scatter(obs, mod_sampled, c=color_list[d], marker='+', alpha=0.75, label=dis_name+'_sampled')\n",
    "    ax_all.scatter(obs, mod, c=color_list[d], marker='*', label=dis_name+'_gamma')\n",
    "    ax_all.scatter(obs, mod_sampled, c=color_list[d], marker='+', alpha=0.75, label=dis_name+'_sampled')\n",
    "    ax.plot(xvals, yvals, lw=2, color='k')\n",
    "    ax.set_xlim(0.0, 6.0)\n",
    "    ax.set_ylim(0.0, 6.0)\n",
    "    ax.set_xlabel('Observed')\n",
    "    ax.set_ylabel('Model')\n",
    "    ax.text(0.6, 0.20, 'Bias (model): {:2.2f}'.format(bias_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.15, 'Cor. Coef. (model) {:2.3f}'.format(cc_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.10, 'Bias (model sampled): {:2.2f}'.format(bias_mod_sampled), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.05, 'Cor. Coef. (model sampled) {:2.3f}'.format(cc_mod_sampled), transform=ax.transAxes)\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "D0_raw_model_list = [v for k, v in D0_raw_model_dict.items()]\n",
    "D0_PIPS_list = [v for k, v in D0_PIPS_interp_to_model_times_dict.items()]\n",
    "D0_samp_model_list = [v for k, v in D0_sample_dict.items()]\n",
    "\n",
    "D0r_mod = xr.concat(D0_raw_model_list, dim='PIPS') * 1000.\n",
    "D0r_obs = xr.concat(D0_PIPS_list, dim='PIPS') * 1000.  \n",
    "D0r_mod_samp = xr.concat(D0_samp_model_list, dim='PIPS')\n",
    "\n",
    "bias_mod_all = ((np.nansum(D0r_mod - D0r_obs)) / np.nansum(D0r_obs))\n",
    "bias_mod_samp_all = ((np.nansum(D0r_mod_samp - D0r_obs)) / np.nansum(D0r_obs))\n",
    "cc_mod_all = pd.DataFrame({'obs': D0r_obs.stack(points=['PIPS', 'time']), \n",
    "                           'mod': D0r_mod.stack(points=['PIPS', 'time'])}).corr().iloc[0, 1]\n",
    "cc_mod_samp_all = pd.DataFrame({'obs': D0r_obs.stack(points=['PIPS', 'time']),\n",
    "                                'mod': D0r_mod_samp.stack(points=['PIPS', 'time'])}).corr().iloc[0, 1]\n",
    "\n",
    "ax_all.plot(xvals, yvals, lw=2, color='k')\n",
    "ax_all.set_xlim(0.0, 6.0)\n",
    "ax_all.set_ylim(0.0, 6.0)\n",
    "ax_all.set_xlabel('Observed')\n",
    "ax_all.set_ylabel('Model')\n",
    "ax_all.text(0.6, 0.20, 'Bias (model): {:2.2f}'.format(bias_mod_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.15, 'Cor. Coef. (model) {:2.3f}'.format(cc_mod_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.10, 'Bias (model sampled): {:2.2f}'.format(bias_mod_samp_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.05, 'Cor. Coef. (model sampled) {:2.3f}'.format(cc_mod_samp_all), transform=ax_all.transAxes)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make some statistical comparison plots\n",
    "\n",
    "# Make some one-to-one plots of ZDR (model) vs. ZDR (disdrometer)\n",
    "\n",
    "yvals = pp.parsivel_parameters['avg_diameter_bins_mm']\n",
    "xvals = yvals\n",
    "\n",
    "color_list = ['r', 'orange', 'g', 'b']\n",
    "\n",
    "fig_all, ax_all = plt.subplots(figsize=(8,8))\n",
    "\n",
    "for d, dis_name in enumerate(dis_names):\n",
    "    obs = dualpol_PIPS_interp_to_model_times_dict[dis_name]['ZDR']\n",
    "    mod = dualpol_raw_model_dict[dis_name]['ZDR']\n",
    "    mod_sampled = dualpol_sample_dict[dis_name]['ZDR']\n",
    "    bias_mod = ((np.nansum(mod - obs)) / np.nansum(obs))\n",
    "    bias_mod_sampled = ((np.nansum(mod_sampled - obs)) / np.nansum(obs))\n",
    "    cc_mod = pd.DataFrame({'obs': obs, 'mod': mod}).corr().iloc[0, 1]\n",
    "    cc_mod_sampled = pd.DataFrame({'obs': obs, 'mod': mod_sampled}).corr().iloc[0, 1]\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.scatter(obs, mod, c=color_list[d], marker='*', label=dis_name+'_gamma')\n",
    "    plt.scatter(obs, mod_sampled, c=color_list[d], marker='+', alpha=0.75, label=dis_name+'_sampled')\n",
    "    ax_all.scatter(obs, mod, c=color_list[d], marker='*', label=dis_name+'_gamma')\n",
    "    ax_all.scatter(obs, mod_sampled, c=color_list[d], marker='+', alpha=0.75, label=dis_name+'_sampled')\n",
    "    ax.plot(xvals, yvals, lw=2, color='k')\n",
    "    ax.set_xlim(0.0, 6.0)\n",
    "    ax.set_ylim(0.0, 6.0)\n",
    "    ax.set_xlabel('Observed')\n",
    "    ax.set_ylabel('Model')\n",
    "    ax.text(0.6, 0.20, 'Bias (model): {:2.2f}'.format(bias_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.15, 'Cor. Coef. (model) {:2.3f}'.format(cc_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.10, 'Bias (model sampled): {:2.2f}'.format(bias_mod_sampled), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.05, 'Cor. Coef. (model sampled) {:2.3f}'.format(cc_mod_sampled), transform=ax.transAxes)\n",
    "    plt.legend(loc='upper left')\n",
    "\n",
    "ZDR_raw_model_list = [v['ZDR'] for k, v in dualpol_raw_model_dict.items()]\n",
    "ZDR_PIPS_list = [v['ZDR'] for k, v in dualpol_PIPS_interp_to_model_times_dict.items()]\n",
    "ZDR_samp_model_list = [v['ZDR'] for k, v in dualpol_sample_dict.items()]\n",
    "\n",
    "ZDR_mod = xr.concat(ZDR_raw_model_list, dim='PIPS')\n",
    "ZDR_obs = xr.concat(ZDR_PIPS_list, dim='PIPS') \n",
    "ZDR_mod_samp = xr.concat(ZDR_samp_model_list, dim='PIPS')\n",
    "\n",
    "bias_mod_all = ((np.nansum(ZDR_mod - ZDR_obs)) / np.nansum(ZDR_obs))\n",
    "bias_mod_samp_all = ((np.nansum(ZDR_mod_samp - ZDR_obs)) / np.nansum(ZDR_obs))\n",
    "cc_mod_all = pd.DataFrame({'obs': ZDR_obs.stack(points=['PIPS', 'time']), \n",
    "                           'mod': ZDR_mod.stack(points=['PIPS', 'time'])}).corr().iloc[0, 1]\n",
    "cc_mod_samp_all = pd.DataFrame({'obs': ZDR_obs.stack(points=['PIPS', 'time']),\n",
    "                                'mod': ZDR_mod_samp.stack(points=['PIPS', 'time'])}).corr().iloc[0, 1]\n",
    "\n",
    "ax_all.plot(xvals, yvals, lw=2, color='k')\n",
    "ax_all.set_xlim(0.0, 6.0)\n",
    "ax_all.set_ylim(0.0, 6.0)\n",
    "ax_all.set_xlabel('Observed')\n",
    "ax_all.set_ylabel('Model')\n",
    "ax_all.text(0.6, 0.20, 'Bias (model): {:2.2f}'.format(bias_mod_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.15, 'Cor. Coef. (model) {:2.3f}'.format(cc_mod_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.10, 'Bias (model sampled): {:2.2f}'.format(bias_mod_samp_all), transform=ax_all.transAxes)\n",
    "ax_all.text(0.6, 0.05, 'Cor. Coef. (model sampled) {:2.3f}'.format(cc_mod_samp_all), transform=ax_all.transAxes)\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate dual-pol variables for both the model and observations and make scatterplots of Z vs. ZDR\n",
    "# Z, ZDR relation from Cao et al. (2008)\n",
    "Zh_Cao = np.arange(10, 61, 0.1)\n",
    "Zdr_Cao = 10**((-2.6857 * 10**-4 * Zh_Cao**2) + 0.04892 * Zh_Cao - 1.4287)\n",
    "color_list = ['r', 'orange', 'g', 'b']\n",
    "\n",
    "for d, dis_name in enumerate(dis_names):\n",
    "    \n",
    "    \n",
    "    dualpol_mod = dualpol_sample_dict[dis_name]\n",
    "    dualpol_mod_raw = dualpol_raw_model_dict[dis_name]\n",
    "    dualpol_obs = dualpol_PIPS_interp_to_model_times_dict[dis_name]\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    sc = plt.scatter(dualpol_mod['dBZ'], dualpol_mod['ZDR'], c=color_list[d], marker='*', label=dis_name+'_mod',\n",
    "                     vmin=-15000., vmax=15000.)\n",
    "    sc = plt.scatter(dualpol_mod_raw['dBZ'], dualpol_mod_raw['ZDR'], c=color_list[d], marker='+', label=dis_name+'_mod_raw',\n",
    "                     vmin=-15000., vmax=15000.)\n",
    "    plt.scatter(dualpol_obs['dBZ'], dualpol_obs['ZDR'], c=color_list[d], marker='o', label=dis_name+'_obs', vmin=-15000., vmax=15000.)\n",
    "    plt.plot(Zh_Cao, Zdr_Cao, c='k', ls='-', lw=1.0)\n",
    "    #plt.colorbar(sc)\n",
    "    ax.set_xlabel('dBZ')\n",
    "    ax.set_ylabel(r'Z$_DR$')\n",
    "    ax.set_xlim(10.0, 60.0)\n",
    "    ax.set_ylim(-2.0, 6.0)\n",
    "    plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(D0_PIPS_interp_to_model_times_dict['PIPS2B'] * 1000).plot.hist()\n",
    "(D0_raw_model_dict['PIPS2B'] * 1000.).plot.hist(alpha=0.5)\n",
    "D0_sample_dict['PIPS2B'].plot.hist(alpha=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old cells below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:31:30.133150Z",
     "start_time": "2019-09-10T03:31:29.930465Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: maybe it's better to try to do this the other direction: namely interpolate the ND values at the PIPS\n",
    "# times, which are different for each PIPS, to the common model times.\n",
    "\n",
    "# Now, interpolate these values at the model times to the PIPS DSD times, one PIPS at a time.\n",
    "# Also get the PSD time bin edges and centers as a numpy array of python datetime objects\n",
    "model_vars_PIPS_dict = {}\n",
    "model_gamma_DSD_params_PIPS_modeltimes_dict = {}\n",
    "model_gamma_DSD_PIPS_modeltimes_dict = {}\n",
    "model_gamma_DSD_params_PIPS_dict = {}\n",
    "model_gamma_DSD_PIPS_dict = {}\n",
    "\n",
    "# Get PSD times valid at the model times\n",
    "PSD_datetimes_model = pips.get_PSD_datetimes(var_ds, dim_name='time')\n",
    "PSD_datetimes_model_dict = pips.get_PSD_time_bins(PSD_datetimes_model)\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    \n",
    "    # Get the DataArrays for individual PIPS\n",
    "    \n",
    "    # Velocity-diameter matrix\n",
    "    vd_matrix_rs_da = vd_matrix_rs_da_dict[dis_name]\n",
    "    \n",
    "    # Rename \"time\" to \"time\" so that we have the same dimension name as the model\n",
    "    vd_matrix_rs_da = vd_matrix_rs_da.rename({'time': 'time'})\n",
    "    \n",
    "    # Shape, intercept, and slope parameters for model DSD, already interpolated in space to each\n",
    "    # PIPS location\n",
    "    # New way\n",
    "    \n",
    "    \n",
    "#     alphar_model_PIPS_da = var_ds_interp['alphar'].loc[dict(PIPS=dis_name)]\n",
    "#     N0r_model_PIPS_da = var_ds_interp['N0r'].loc[dict(PIPS=dis_name)]\n",
    "#     lamdar_model_PIPS_da = var_ds_interp['lamdar'].loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    # Do the same for ND and logND\n",
    "    ND_model_PIPS_da = var_ds_interp['ND'].loc[dict(PIPS=dis_name)]\n",
    "    logND_model_PIPS_da = var_ds_interp['logND'].loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    # Old way\n",
    "    alphar_model_PIPS_da = alphar_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    N0r_model_PIPS_da = N0r_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    lamdar_model_PIPS_da = lamdar_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    # Get the values of some needed variables from the model dataset, already interpolated in space to each\n",
    "    # PIPS location\n",
    "    \n",
    "    # We just need rho and nr\n",
    "    rho_model_pips_da = var_ds_interp['rho'].loc[dict(PIPS=dis_name)]\n",
    "    nr_model_pips_da = var_ds_interp['nr'].loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    # Now interpolate the DSD parameters in time to the PIPS times, which are different for each PIPS\n",
    "    \n",
    "    alphar_model_PIPS_da_interp = alphar_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    N0r_model_PIPS_da_interp = N0r_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    lamdar_model_PIPS_da_interp = lamdar_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    \n",
    "    # Do the same for ND and logND\n",
    "    ND_model_PIPS_da_interp = ND_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    logND_model_PIPS_da_interp = logND_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    \n",
    "    # Do the same for rho and nr\n",
    "    rho_model_pips_da_interp = rho_model_pips_da.interp_like(vd_matrix_rs_da)\n",
    "    nr_model_pips_da = nr_model_pips_da.interpolate_na(dim='time')\n",
    "    nr_model_pips_da_interp = nr_model_pips_da.interp_like(vd_matrix_rs_da)\n",
    "    \n",
    "    # Stuff them into a dict of dicts (gahhh!)\n",
    "    model_gamma_DSD_params_modeltimes_dict = {'alphar': alphar_model_PIPS_da,\n",
    "                                              'N0r': N0r_model_PIPS_da,\n",
    "                                              'lamdar': lamdar_model_PIPS_da}\n",
    "    model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name] = model_gamma_DSD_params_modeltimes_dict\n",
    "    model_gamma_DSD_params_dict = {'alphar': alphar_model_PIPS_da_interp,\n",
    "                                   'N0r': N0r_model_PIPS_da_interp,\n",
    "                                   'lamdar': lamdar_model_PIPS_da_interp}\n",
    "    model_gamma_DSD_params_PIPS_dict[dis_name] = model_gamma_DSD_params_dict\n",
    "    \n",
    "    model_gamma_DSD_modeltimes_dict = {'ND': ND_model_PIPS_da, \n",
    "                                       'logND': logND_model_PIPS_da}\n",
    "    model_gamma_DSD_PIPS_modeltimes_dict[dis_name] = model_gamma_DSD_modeltimes_dict\n",
    "    \n",
    "    model_gamma_DSD_dict = {'ND': ND_model_PIPS_da_interp,\n",
    "                            'logND': logND_model_PIPS_da_interp}\n",
    "    model_gamma_DSD_PIPS_dict[dis_name] = model_gamma_DSD_dict\n",
    "    \n",
    "    model_vars_PIPS_dict[dis_name] = {'rho': rho_model_pips_da_interp, 'nr': nr_model_pips_da_interp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:09:53.421810Z",
     "start_time": "2019-09-10T03:09:53.316079Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute N(D) from the raw model parameters at original model times\n",
    "import pyPIPS.parsivel_params as pp\n",
    "\n",
    "ND_model_raw_PIPS_modeltimes_dict = {}\n",
    "logND_model_raw_PIPS_modeltimes_dict = {}\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    mid_diameters_da = vd_matrix_da_dict[dis_name]['diameter']\n",
    "    alphar_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['alphar']\n",
    "    N0r_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['N0r']\n",
    "    lamdar_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['lamdar']\n",
    "    print(alphar_model_PIPS_da)\n",
    "    # Broadcast DSD parameter DataArrays to get everyone on the same dimensional page\n",
    "    mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da = \\\n",
    "        xr.broadcast(mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da)\n",
    "    # Transpose these DataArrays to get time as the first dimension\n",
    "    mid_diameters_da = mid_diameters_da.T\n",
    "    N0r_model_PIPS_da = N0r_model_PIPS_da.T\n",
    "    lamdar_model_PIPS_da = lamdar_model_PIPS_da.T\n",
    "    alphar_model_PIPS_da = alphar_model_PIPS_da.T\n",
    "    \n",
    "    ND_model_raw_PIPS = dsd.calc_binned_DSD_from_params(N0r_model_PIPS_da, lamdar_model_PIPS_da, \n",
    "                                                        alphar_model_PIPS_da, mid_diameters_da)\n",
    "    logND_model_raw_PIPS = np.log10(ND_model_raw_PIPS)\n",
    "    logND_model_raw_PIPS = logND_model_raw_PIPS.where(logND_model_raw_PIPS > -1.0)\n",
    "    \n",
    "    ND_model_raw_PIPS_modeltimes_dict[dis_name] = ND_model_raw_PIPS\n",
    "    logND_model_raw_PIPS_modeltimes_dict[dis_name] = logND_model_raw_PIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:32:04.112418Z",
     "start_time": "2019-09-10T03:32:04.022606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute N(D) from the raw model parameters (interpolated to the PIPS times and locations)\n",
    "import pyPIPS.parsivel_params as pp\n",
    "\n",
    "ND_model_raw_PIPS_dict = {}\n",
    "logND_model_raw_PIPS_dict = {}\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    mid_diameters_da = vd_matrix_da_dict[dis_name]['diameter']\n",
    "    alphar_model_PIPS_da = model_gamma_DSD_params_PIPS_dict[dis_name]['alphar']\n",
    "    N0r_model_PIPS_da = model_gamma_DSD_params_PIPS_dict[dis_name]['N0r']\n",
    "    lamdar_model_PIPS_da = model_gamma_DSD_params_PIPS_dict[dis_name]['lamdar']\n",
    "    # Broadcast DSD parameter DataArrays to get everyone on the same dimensional page\n",
    "    mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da = \\\n",
    "        xr.broadcast(mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da)\n",
    "    # Transpose these DataArrays to get time as the first dimension\n",
    "    mid_diameters_da = mid_diameters_da.T\n",
    "    N0r_model_PIPS_da = N0r_model_PIPS_da.T\n",
    "    lamdar_model_PIPS_da = lamdar_model_PIPS_da.T\n",
    "    alphar_model_PIPS_da = alphar_model_PIPS_da.T\n",
    "    \n",
    "    ND_model_raw_PIPS = dsd.calc_binned_DSD_from_params(N0r_model_PIPS_da, lamdar_model_PIPS_da, \n",
    "                                                        alphar_model_PIPS_da, mid_diameters_da)\n",
    "    logND_model_raw_PIPS = np.log10(ND_model_raw_PIPS)\n",
    "    logND_model_raw_PIPS = logND_model_raw_PIPS.where(logND_model_raw_PIPS > -1.0)\n",
    "    \n",
    "    ND_model_raw_PIPS_dict[dis_name] = ND_model_raw_PIPS\n",
    "    logND_model_raw_PIPS_dict[dis_name] = logND_model_raw_PIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:32:05.856524Z",
     "start_time": "2019-09-10T03:32:05.648931Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute some radar and DSD parameters from the raw model DSDs (interpolated to PIPS times and locations)\n",
    "dBZ_raw_model_dict = {}\n",
    "D0_raw_model_dict = {}\n",
    "for dis_name in dis_names:\n",
    "    dBZ_raw_model = dsd.calc_dBZ_from_bins(model_gamma_DSD_PIPS_dict[dis_name]['ND'])\n",
    "    dBZ_raw_model = dBZ_raw_model.where(dBZ_raw_model > -np.inf)\n",
    "    dBZ_raw_model_dict[dis_name] = dBZ_raw_model\n",
    "    D0_raw_model = dsd.calc_D0_bin(model_gamma_DSD_PIPS_dict[dis_name]['ND'])\n",
    "    D0_raw_model_dict[dis_name] = D0_raw_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T01:42:40.236360Z",
     "start_time": "2019-09-10T01:42:38.255873Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Now plot the raw model DSDs (interpolated to PIPS locations but not the times)\n",
    "\n",
    "# PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "# PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "# for i, dis_name in enumerate(dis_names):\n",
    "#     logND = model_gamma_DSD_PIPS_modeltimes_dict[dis_name]['logND']\n",
    "#     logND = logND.where(logND > -1.0)\n",
    "#     disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "#                'PSDmidtimes': PSDmidtimes, 'logND': logND.T}\n",
    "#     dis_plot_name = dis_name + '_raw_model_modeltimes_' + DSDtype\n",
    "#     PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:04:24.928139Z",
     "start_time": "2019-09-08T23:04:22.881514Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Now plot the raw model DSDs (interpolated to PIPS locations but not the times) - version 2 with logND computed\n",
    "# # from interpolated alpha, lamda, N0\n",
    "\n",
    "# PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "# PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "# for i, dis_name in enumerate(dis_names):\n",
    "#     logND = logND_model_raw_PIPS_modeltimes_dict[dis_name]\n",
    "#     logND = logND.where(logND > -1.0)\n",
    "#     print(logND)\n",
    "#     print(PSDstarttimes)\n",
    "#     disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "#                'PSDmidtimes': PSDmidtimes, 'logND': logND.T}\n",
    "#     dis_plot_name = dis_name + '_raw_model_modeltimes_v2_' + DSDtype\n",
    "#     PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:32:13.477374Z",
     "start_time": "2019-09-10T03:32:11.095613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now plot the raw model DSDs (interpolated to PIPS times and locations)\n",
    "\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND = model_gamma_DSD_PIPS_dict[dis_name]['logND']\n",
    "    logND = logND.where(logND > -1.0)\n",
    "    D0 = D0_raw_model_dict[dis_name] * 1000. # Get to mm again\n",
    "    dBZ = dBZ_raw_model_dict[dis_name]\n",
    "    PSDstarttimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_edges'])\n",
    "    PSDmidtimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_centers'])\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'D_0': D0, 'dBZ': dBZ}\n",
    "    dis_plot_name = dis_name + '_raw_model_{:d}'.format(member) + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:04:57.995119Z",
     "start_time": "2019-09-08T23:04:55.982881Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Now plot the raw model DSDs (interpolated to PIPS times and locations) - version 2 with logND computed\n",
    "# # from interpolated alpha, lamda, N0\n",
    "\n",
    "# for i, dis_name in enumerate(dis_names):\n",
    "#     logND = logND_model_raw_PIPS_dict[dis_name]\n",
    "#     logND = logND.where(logND > -1.0)\n",
    "#     PSDstarttimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_edges'])\n",
    "#     PSDmidtimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_centers'])\n",
    "#     print(logND)\n",
    "#     print(PSDstarttimes)\n",
    "#     disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "#                'PSDmidtimes': PSDmidtimes, 'logND': logND.T}\n",
    "#     dis_plot_name = dis_name + '_raw_model_v2_' + DSDtype\n",
    "#     PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:32:20.701802Z",
     "start_time": "2019-09-10T03:32:16.011139Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now compute sampled PSDs from the model\n",
    "\n",
    "# Now plot the sampled model DSD\n",
    "\n",
    "sampling_interval = 60.\n",
    "sampling_length = pp.parsivel_parameters['sensor_length_mm'] / 1000. # To m\n",
    "sampling_width = pp.parsivel_parameters['sensor_width_mm'] / 1000. # To m\n",
    "\n",
    "Dmax = 9.\n",
    "Dmax_index = np.searchsorted(mid_diameters, Dmax, side='right')\n",
    "# print(Dmax_index)\n",
    "mid_diameters_trunc = np.array(mid_diameters[:Dmax_index+1]) / 1000.\n",
    "min_diameters_trunc = np.array(min_diameters[:Dmax_index+1]) / 1000.\n",
    "max_diameters_trunc = np.array(max_diameters[:Dmax_index+1]) / 1000.\n",
    "\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    PSDstarttimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_edges'])\n",
    "    PSDmidtimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_centers'])\n",
    "    ND_raw = model_gamma_DSD_PIPS_dict[dis_name]['ND']\n",
    "    # print(ND_raw)\n",
    "    nr_model = model_vars_PIPS_dict[dis_name]['nr'].values\n",
    "    lamdar_model = model_gamma_DSD_params_PIPS_dict[dis_name]['lamdar'].values\n",
    "    alphar_model = model_gamma_DSD_params_PIPS_dict[dis_name]['alphar'].values\n",
    "    rho_model = model_vars_PIPS_dict[dis_name]['rho'].values\n",
    "\n",
    "    # print(mid_diameters_trunc.shape)\n",
    "    Vtr = pips.calc_empirical_fallspeed(mid_diameters_trunc * 1000., correct_rho=True, rho=rho_model)\n",
    "\n",
    "    Vtr = Vtr.T\n",
    "#     print(Vtr[0])\n",
    "#     print(Vtr.shape)\n",
    "#     print(mid_diameters_trunc.shape)\n",
    "    ND_samp_series = np.zeros((np.size(PSDmidtimes), np.size(mid_diameters_trunc)))\n",
    "\n",
    "#     print(ND_samp_series.shape)\n",
    "#     print(nr_model[0])\n",
    "    # Nc_bin_tmp2 = np.zeros((np.size(N0r), np.size(D[:Dmax_index+1])))\n",
    "    # Nc_bin2 = np.zeros((np.size(np.array(sampling_times)), np.size(D[:Dmax_index+1])))\n",
    "\n",
    "    all_valid = (not np.isnan(lamdar_model[0]) and (not np.isnan(alphar_model[0])) and (not np.isnan(nr_model[0])))\n",
    "    if all_valid:\n",
    "        # Special treatment for first sampling time. Just assume DSD valid at that time was constant for the previous \n",
    "        # sampling interval\n",
    "        sample_dict = sim.create_random_gamma_DSD(nr_model[0], lamdar_model[0], \n",
    "                                                  alphar_model[0], Vtr[0], sampling_length, \n",
    "                                                  sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                                  max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                                  remove_margins=True, rhocorrect=True, rho=rho_model[0], verbose=True)\n",
    "\n",
    "\n",
    "        ND_sample = sample_dict['ND']\n",
    "        pcount_binned_sample = sample_dict['pcount_binned']\n",
    "    #     print(ND_sample.shape)\n",
    "    #     print(ND_samp_series.shape)\n",
    "        ND_samp_series[0, :] = 1.e-3*ND_sample\n",
    "        # Nc_bin_tmp2[0, :] = 1.e-3*ND_sample\n",
    "        # Nc_bin2[0, :] = Nc_bin_tmp2[0, :]\n",
    "\n",
    "    \n",
    "    pcount_binned_samples = []\n",
    "    for index in range(np.size(PSDmidtimes[1:-1])):\n",
    "        all_valid = (not np.isnan(lamdar_model[index]) \n",
    "                     and (not np.isnan(alphar_model[index]))\n",
    "                     and (not np.isnan(nr_model[index])))\n",
    "        print('nr = ', nr_model[index], 'lamdar = ', lamdar_model[index], 'alphar = ', alphar_model[index])\n",
    "        if all_valid:\n",
    "            sample_dict = sim.create_random_gamma_DSD(nr_model[index], lamdar_model[index], \n",
    "                                                      alphar_model[index], Vtr[index], sampling_length, \n",
    "                                                      sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                                      max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                                      remove_margins=True, rhocorrect=True, rho=rho_model[index], verbose=True)\n",
    "            ND_sample = sample_dict['ND']\n",
    "            pcount_binned_samples.append(sample_dict['pcount_binned'])\n",
    "            ND_samp_series[index, :] = 1.e-3*ND_sample\n",
    "        else:\n",
    "            pcount_binned_samples.append(np.zeros_like(sample_dict['pcount_binned']))\n",
    "\n",
    "    pcount_binned_samples = np.array(pcount_binned_samples)\n",
    "    \n",
    "    ND_samp_da = xr.DataArray(ND_samp_series,\n",
    "                                     coords={'time': PSDmidtimes,\n",
    "                                             'diameter': ('diameter_bin', mid_diameters_trunc * 1000.),\n",
    "                                             'max_diameter': ('diameter_bin', max_diameters_trunc * 1000.),\n",
    "                                             'min_diameter': ('diameter_bin', min_diameters_trunc * 1000.)\n",
    "                                            },\n",
    "                                     dims=['time', 'diameter_bin'])\n",
    "    \n",
    "    ND_samp_da = ND_samp_da.fillna(0.0)\n",
    "\n",
    "    # sampling_volumes_D = sim.calc_sampling_volumes_D(Vtr, Dr, Dmax, sampling_interval, sampling_area)\n",
    "    # for s, sample_index in enumerate(sample_indices[:-1]):\n",
    "    #     sample_index_end = sample_indices[s+1]\n",
    "    #     current_sample_indices = slice(sample_index, sample_index_end, None)\n",
    "    #     pcount_binned = np.sum(pcount_binned_samples[current_sample_indices], axis=0)\n",
    "    #     Nc_bin2[s+1, :] = 1.e-3*sim.calc_ND(pcount_binned, sampling_volumes_D, Dr, Dl, Dmax)\n",
    "    # #     Nc_bin2[s+1, :] = np.sum(Nc_bin_tmp2[current_sample_indices, :]*dt[current_sample_indices, None], axis = 0)/sampling_interval\n",
    "    # #     print \"s = \", s\n",
    "    # #     print \"sample time (beginning) = \", sampling_times[s]\n",
    "    # #     print \"sample time (end) = \", sampling_times[s+1]\n",
    "    # #     print \"dt[current_sample_indices] = \", dt[current_sample_indices]\n",
    "    # #     print \"Nc_bin_tmp = \", Nc_bin_tmp[current_sample_indices, :], dt[current_sample_indices]\n",
    "    # #     print \"Nc_bin = \", Nc_bin[s+1, :]\n",
    "\n",
    "    logND_samp_da = np.log10(ND_samp_da)\n",
    "    logND_samp_da = logND_samp_da.where(logND_samp_da > -1.0)\n",
    "\n",
    "    # Compute dBZ and D0 from the sampled DSD\n",
    "    dBZ_samp_model = dsd.calc_dBZ_from_bins(ND_samp_da)\n",
    "    dBZ_samp_model = dBZ_samp_model.where(dBZ_samp_model > -np.inf)\n",
    "    D0_samp_model = dsd.calc_D0_bin(ND_samp_da) * 1000. # Get to mm again\n",
    "    \n",
    "    disvars = {'min_diameter': min_diameters[:Dmax_index+1], 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND_samp_da.T, 'D_0': D0_samp_model, \n",
    "               'dBZ': dBZ_samp_model}\n",
    "    dis_plot_name = dis_name + '_sampled_model_{:d}'.format(member) + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:32:22.342960Z",
     "start_time": "2019-09-10T03:32:22.267770Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model_vars_PIPS_dict['PIPS1B']['nr'].loc['2016-03-31T22:25':'2016-03-31T22:30'])\n",
    "print(model_gamma_DSD_params_PIPS_dict['PIPS1B']['lamdar'].loc['2016-03-31T22:25':'2016-03-31T22:30'])\n",
    "print(model_gamma_DSD_params_PIPS_dict['PIPS1B']['alphar'].loc['2016-03-31T22:25':'2016-03-31T22:30'])\n",
    "print(model_gamma_DSD_params_PIPS_modeltimes_dict['PIPS1B']['alphar'].loc['2016-03-31T22:25':'2016-03-31T22:30'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pyPIPS]",
   "language": "python",
   "name": "conda-env-pyPIPS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

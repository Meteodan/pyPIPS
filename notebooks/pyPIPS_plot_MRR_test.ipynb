{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to test plotting of UAH MRR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T14:40:32.290220Z",
     "start_time": "2020-06-24T14:40:28.958219Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid,make_axes_locatable,host_subplot\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "#import pyPIPS.disdrometer_module as dis\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "#import pyPIPS.simulator as sim\n",
    "import pyPIPS.pips_io as pipsio\n",
    "import pyPIPS.PIPS as pips\n",
    "import pyPIPS.parsivel_params as pp\n",
    "import pyPIPS.parsivel_qc as pqc\n",
    "import pyPIPS.polarimetric as dualpol\n",
    "import pyPIPS.timemodule as ptime\n",
    "# from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "# from pyCRMtools.pycaps import arps_read\n",
    "# from pyCRMtools.pycaps import pycaps_fields\n",
    "# from pyCRMtools.pycaps import calvars_radar as radar\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRR_dir = '/Users/dawson29/Projects/PERiLS/obsdata/2022/UAH_MRR'\n",
    "MRR_file1 = 'RaDAPS_MRR_20220330.nc'\n",
    "MRR_file2 = 'RaDAPS_MRR_20220331.nc'\n",
    "\n",
    "MRR_path1 = os.path.join(MRR_dir, MRR_file1)\n",
    "MRR_path2 = os.path.join(MRR_dir, MRR_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRR_ds1 = xr.load_dataset(MRR_path1)\n",
    "MRR_ds2 = xr.load_dataset(MRR_path2)\n",
    "# MRR_ds = xr.merge(MRR_ds1, MRR_ds2)\n",
    "# MRR_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRR_ds1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRR_ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRR_ds = xr.concat([MRR_ds1, MRR_ds2], dim='time')\n",
    "starttime = '2022-03-30T22:49'\n",
    "endtime = '2022-03-31T01:34'\n",
    "MRR_ds = MRR_ds.sel(time=slice(starttime, endtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRR_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRR_ds = MRR_ds.set_coords('MRR_D')\n",
    "# MRR_ds = MRR_ds.where(MRR_ds['MRR_D'] >= 0., drop=True)\n",
    "# MRR_ds = MRR_ds.where(np.isfinite(MRR_ds['MRR_D']), drop=True)\n",
    "# MRR_ds = MRR_ds.dropna(dim='MRR spectralclass', subset=['MRR_D'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "MRR_ds['MRR_Capital_Z'].plot(ax=ax, x='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "MRR_ds['MRR_RR'].plot(ax=ax, x='time', robust=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# I suspect the units are actually in m^-4, not m^-3 mm^-1, so divide by 1000 here to fix that\n",
    "log_N = np.log10(MRR_ds['MRR_N'] / 1000.)\n",
    "log_N = log_N.where(log_N > -1.0)\n",
    "\n",
    "\n",
    "log_N_plot = log_N.isel({'MRR rangegate': 2})\n",
    "# log_N.isel({'MRR rangegate': 2}).plot(x='time', y='MRR_D', vmin=-1.0, vmax=3.0, cmap='viridis')\n",
    "\n",
    "# print(log_N_plot.sizes)\n",
    "\n",
    "print(log_N_plot['time'].shape, log_N_plot['MRR_D'].shape)\n",
    "# Need to promote the time dimension to 2D with same shape as MRR_D, which is dimensioned by (time, MRR spectralclass). pcolor requires\n",
    "# that both x and y coordinates are the same shape...\n",
    "time_plot = np.tile(log_N_plot['time'], (log_N_plot.sizes['MRR spectralclass'], 1)).T\n",
    "print(time_plot.shape)\n",
    "\n",
    "# Have to use pcolor here instead of pcolormesh because MRR_D contains nans\n",
    "ax.pcolor(time_plot, log_N_plot['MRR_D'], log_N_plot.values, vmin=-1.0, vmax=3.0, cmap='viridis')\n",
    "# ax.set_ylim(0., 9.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MRR_D = MRR_ds['MRR_D']\n",
    "MRR_D.isel({'MRR rangegate': 20}).plot(x='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert combined time string to hours, minutes, seconds\n",
    "def parse_time(time_str):\n",
    "    hour = int(time_str[:2])\n",
    "    minute = int(time_str[2:4])\n",
    "    second = int(time_str[4:])\n",
    "    return hour, minute, second\n",
    "\n",
    "# Function to convert year, Julian day, and time to datetime\n",
    "def julian_to_datetime(row):\n",
    "    time_int = int(row['HHMMSS'])  # Annoying that this is read in by default as a float, so have to do some finagling\n",
    "    hour, minute, second = parse_time(f'{time_int:06d}')\n",
    "    return pd.to_datetime(f\"{int(row['year'])}-01-01\") + pd.to_timedelta(row['julian_day'] - 1, unit='d') + \\\n",
    "           pd.to_timedelta(hour, unit='h') + pd.to_timedelta(minute, unit='m') + pd.to_timedelta(second, unit='s')\n",
    "\n",
    "def read_UAH_parsivel_to_xarray(parsivel_path):\n",
    "    # Construct the header, because the files don't have one\n",
    "    header1 = ['year', 'julian_day', 'HHMMSS', 'sensor_temp', 'pcount', 'RR']\n",
    "    header2 = [f'N({avg_diameter:.4f})' for avg_diameter in pp.avg_diameter]\n",
    "    header3 = [f'V({avg_fallspeed:.4f})' for avg_fallspeed in pp.avg_fallspeed]\n",
    "    header4 = ['Unknown']  # I think this is the reflectivity, but the documentation doesn't say\n",
    "    header = header1 + header2 + header3 + header4\n",
    "    parsivel_df = pd.read_csv(parsivel_path, header=None, names=header, index_col=False)\n",
    "    # Apply the function to create a new datetime column\n",
    "    parsivel_df['time'] = parsivel_df.apply(julian_to_datetime, axis=1)\n",
    "    # Set the new datetime column as the index\n",
    "    parsivel_df.set_index('time', inplace=True)\n",
    "    # Drop the existing \"year\", \"julian_day\", and \"time\" columns\n",
    "    parsivel_df.drop(columns=['year', 'julian_day', 'HHMMSS'], inplace=True)\n",
    "\n",
    "    # Convert to xarray Dataset\n",
    "    parsivel_ds = parsivel_df.to_xarray()\n",
    "\n",
    "    # We're not done yet. We want the N(D) and V(D) to be two new DataArrays in the new DataSet, so we have to\n",
    "    # wrangle the existing variables into submission by concatenating them along new diameter and velocity dimensions\n",
    "\n",
    "    # Start with ND\n",
    "    NDs = [parsivel_ds[var].expand_dims(dim='diameter', axis=0) for var in header2]\n",
    "\n",
    "    # Assign the new dimension coordinate values\n",
    "    for i, da in enumerate(NDs):\n",
    "        NDs[i] = da.assign_coords(diameter=[pp.avg_diameter[i]])\n",
    "    \n",
    "    # Concatenate the DataArrays along the new dimension\n",
    "    ND = xr.concat(NDs, dim='diameter')\n",
    "    \n",
    "    # Drop the original variables from the dataset\n",
    "    parsivel_ds = parsivel_ds.drop_vars(header2)\n",
    "    \n",
    "    # Add the concatenated variable back to the dataset\n",
    "    parsivel_ds['ND'] = ND\n",
    "\n",
    "    # Now do the same for VD\n",
    "    VDs = [parsivel_ds[var].expand_dims(dim='fallspeed', axis=0) for var in header3]\n",
    "\n",
    "    # Assign the new dimension coordinate values\n",
    "    for i, da in enumerate(VDs):\n",
    "        VDs[i] = da.assign_coords(fallspeed=[pp.avg_fallspeed[i]])\n",
    "    \n",
    "    # Concatenate the DataArrays along the new dimension\n",
    "    VD = xr.concat(VDs, dim='fallspeed')\n",
    "    \n",
    "    # Drop the original variables from the dataset\n",
    "    parsivel_ds = parsivel_ds.drop_vars(header3)\n",
    "    \n",
    "    # Add the concatenated variable back to the dataset\n",
    "    parsivel_ds['VD'] = VD\n",
    "    \n",
    "    return parsivel_ds\n",
    "\n",
    "parsivel_dir = '/Users/dawson29/sshfs_mounts/depot/data/Projects/PERiLS/obsdata/2022/UAH_MAPNET_Parsivel'\n",
    "parsivel_file1 = 'radaps_20220330_parsivel.dat'\n",
    "parsivel_file2 = 'radaps_20220331_parsivel.dat'\n",
    "\n",
    "parsivel_path1 = os.path.join(parsivel_dir, parsivel_file1)\n",
    "parsivel_path2 = os.path.join(parsivel_dir, parsivel_file2)\n",
    "\n",
    "parsivel_ds1 = read_UAH_parsivel_to_xarray(parsivel_path1)\n",
    "parsivel_ds2 = read_UAH_parsivel_to_xarray(parsivel_path2)\n",
    "\n",
    "parsivel_ds = xr.concat([parsivel_ds1, parsivel_ds2], dim='time')\n",
    "parsivel_ds\n",
    "\n",
    "\n",
    "# def read_UAH_parsivel_to_xarray(parsivel_path):\n",
    "#     \"\"\"Given a UAH Parsivel file path, read it into an xarray Dataset\"\"\"\n",
    "\n",
    "#     parsivel_df = pd.read_csv(parsivel_path)\n",
    "#     # Set the time index\n",
    "\n",
    "    \n",
    "#     probe_filename = f\"0{probe_id}_{deployment_name}_level3.txt\"\n",
    "#     probe_filepath = os.path.join(dir, probe_filename)\n",
    "#     probe_df = pd.read_csv(probe_filepath)\n",
    "#     # Set the time index\n",
    "#     probe_df['Time'] = pd.DatetimeIndex(probe_df['Time'])\n",
    "#     probe_df.set_index(\"Time\", inplace=True)\n",
    "#     probe_ds = probe_df.to_xarray()\n",
    "\n",
    "#     # Set location, probe id, start and end times, etc., as attributes\n",
    "#     probe_ds.attrs['probe_name'] = probe_id\n",
    "#     lat = loc_ds.sel(ID=probe_id)['Latitude'].to_numpy().item()\n",
    "#     lon = loc_ds.sel(ID=probe_id)['Longitude'].to_numpy().item()\n",
    "#     elev = loc_ds.sel(ID=probe_id)['Elevation'].to_numpy().item()\n",
    "#     location_tuple = (lat, lon, elev)\n",
    "#     probe_ds.attrs['location'] = str(location_tuple)\n",
    "#     probe_ds.attrs['Array_Type'] = \"Fine\"\n",
    "#     starting_time = probe_ds['Time'][0].dt.strftime(\"%Y%m%d%H%M%S\").item()\n",
    "#     ending_time = probe_ds['Time'][-1].dt.strftime(\"%Y%m%d%H%M%S\").item()\n",
    "#     probe_ds.attrs['starting_time'] = starting_time\n",
    "#     probe_ds.attrs['ending_time'] = ending_time\n",
    "\n",
    "#     return probe_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsivel_ds = parsivel_ds.sel(time=slice(starttime, endtime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "parsivel_ds['ND'].plot(ax=ax, vmin=-1, vmax=3, cmap='viridis')\n",
    "ax.set_ylim(0., 9.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "parsivel_ds['Unknown'].plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "MRR_ds['MRR_Capital_Z'].isel({'MRR rangegate': 0}).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot observed DSD meteograms\n",
    "\n",
    "ND = parsivel_ds['ND'].T\n",
    "ZH = parsivel_ds['Unknown']\n",
    "ZH_MRR = MRR_ds['MRR_Capital_Z'].isel({'MRR rangegate': 1})\n",
    "radmidtimes = ZH_MRR['time']\n",
    "# print(ZH_MRR)\n",
    "\n",
    "# Truncate diameter range to less than 9 mm\n",
    "D_max = 9.\n",
    "D_range_full = ND['diameter'].values\n",
    "D_max_ind = np.searchsorted(D_range_full, D_max)\n",
    "D_range = D_range_full[:D_max_ind]\n",
    "print(D_max_ind, D_range)\n",
    "ND_trunc = ND.isel(diameter=slice(0, D_max_ind))\n",
    "\n",
    "# Get PSD times\n",
    "PSD_datetimes = pips.get_PSD_datetimes(ND)\n",
    "PSD_datetimes_dict = pips.get_PSD_time_bins(PSD_datetimes)\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_dict['PSD_datetimes_centers'])\n",
    "\n",
    "# Prepare axis parameters\n",
    "# We'll use the model times for the boundaries of the x-axis\n",
    "timelimits = [PSDstarttimes[0], PSDstarttimes[-1]]\n",
    "diamlimits = [0.0, 9.0]\n",
    "diamytick = 1.0\n",
    "DSDtype = 'observed'\n",
    "locator = dates.MinuteLocator(byminute=[0,15,30,45])\n",
    "minorlocator = dates.MinuteLocator(byminute=range(0,60,5))\n",
    "dateformat = '%H:%M'\n",
    "formatter = dates.DateFormatter(dateformat)\n",
    "\n",
    "axparams = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "            'minorxlocator': minorlocator,\n",
    "            'axeslimits': [timelimits, diamlimits],\n",
    "            'majorylocator': ticker.MultipleLocator(base=diamytick),\n",
    "            'axeslabels': [None, 'D (mm)']}\n",
    "\n",
    "# It seems that this is already in log units for the UAH Parsivel\n",
    "logND = ND_trunc # np.log10(ND_trunc)\n",
    "logND = logND.where(logND > -1.0)\n",
    "\n",
    "# Ok, now we should have everything ready to go to plot the meteograms.\n",
    "# Let'er rip!\n",
    "\n",
    "# D0 = D0_PIPS_interp_to_model_times_dict[dis_name] * 1000. # Get to mm again\n",
    "# dBZ = dBZ_PIPS_interp_to_model_times_dict[dis_name]\n",
    "# ZDR = dualpol_PIPS_interp_to_model_times_dict[dis_name]['ZDR']\n",
    "\n",
    "diameter_bin_edges = pp.parsivel_parameters['diameter_bin_edges_mm']\n",
    "diameter_bin_edges = diameter_bin_edges[:D_max_ind+1]\n",
    "\n",
    "disvars = {'diameter_bin_edges': diameter_bin_edges, 'PSDstarttimes': PSDstarttimes,\n",
    "           'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'REF': ZH} # , 'D_m': Dm_sorted_PIPS_da, 'dBZ': ZH_sorted_PIPS_da, \n",
    "           # 'ZDR': ZDR_sorted_PIPS_da}\n",
    "\n",
    "radvars = {'radmidtimes': radmidtimes, 'REF': ZH_MRR}\n",
    "\n",
    "plot_dir = os.path.join(parsivel_dir, 'plots')\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "dis_plot_name = 'UAH_' + DSDtype\n",
    "PIPSplot.plotDSDmeteograms(dis_plot_name, plot_dir, axparams, disvars, radvars=radvars, close_fig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pyPIPS]",
   "language": "python",
   "name": "conda-env-pyPIPS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

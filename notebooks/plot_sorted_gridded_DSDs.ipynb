{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T22:55:48.420246Z",
     "start_time": "2021-01-02T22:55:45.665406Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "## You are using the Python ARM Radar Toolkit (Py-ART), an open source\n",
      "## library for working with weather radar data. Py-ART is partly\n",
      "## supported by the U.S. Department of Energy as part of the Atmospheric\n",
      "## Radiation Measurement (ARM) Climate Research Facility, an Office of\n",
      "## Science user facility.\n",
      "##\n",
      "## If you use this software to prepare a publication, please cite:\n",
      "##\n",
      "##     JJ Helmus and SM Collis, JORS 2016, doi: 10.5334/jors.119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "import matplotlib.animation as animation\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid, make_axes_locatable, host_subplot\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "#import pyPIPS.disdrometer_module as dis\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "#import pyPIPS.simulator as sim\n",
    "import pyPIPS.pips_io as pipsio\n",
    "import pyPIPS.PIPS as pips\n",
    "import pyPIPS.parsivel_params as pp\n",
    "import pyPIPS.parsivel_qc as pqc\n",
    "import pyPIPS.radarmodule as radar\n",
    "import pyPIPS.polarimetric as dualpol\n",
    "#from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy.random as random\n",
    "from scipy.stats import gamma, uniform\n",
    "from scipy.special import gamma as gammafunc\n",
    "from scipy import ndimage\n",
    "from scipy import interpolate\n",
    "from metpy.plots import StationPlot\n",
    "import metpy.calc as mpcalc\n",
    "from metpy.calc import wind_components\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.plots.wx_symbols import current_weather, sky_cover\n",
    "from metpy.units import units\n",
    "from scipy.signal import medfilt2d\n",
    "import pyart\n",
    "import cartopy.crs as ccrs\n",
    "from IPython.display import HTML\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T22:55:49.001054Z",
     "start_time": "2021-01-02T22:55:48.893869Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "def readESC(sounding_path, interpnan=True, handle=False):\n",
    "    \"\"\"\n",
    "    Reads in a sounding in ESC format from a provided file path or handle (can be a StringIO object or an open\n",
    "    file handle)\n",
    "    \"\"\"\n",
    "    col_names = ['pressure','temperature','dewpoint','u_wind','v_wind','speed','direction','height',\n",
    "                 'Qp_code','Qt_code','Qrh_code','Qu_code','Qv_code']\n",
    "    # First read the file and extract the field widths from the 14th header line\n",
    "    if not handle:\n",
    "        f = open(sounding_path, 'r')\n",
    "    else:\n",
    "        f = sounding_path\n",
    "\n",
    "    # Read in the header and extract some metadata from it\n",
    "    dummy = f.readline()\n",
    "    dummy = f.readline()\n",
    "    header2 = f.readline().strip().split(':')\n",
    "    # Read next header line and extract station id and wmo number from it (if it exists)\n",
    "    staid_wmo_str = header2[1]\n",
    "    if ' / ' in staid_wmo_str:\n",
    "        staid_wmo = staid_wmo_str.strip().split(' / ')\n",
    "        staid = staid_wmo[0][1:4]\n",
    "        wmo = int(staid_wmo[1])\n",
    "    else:\n",
    "        if '. ' in staid_wmo_str:\n",
    "            staid = staid_wmo_str.replace('. ', '').strip()[:4]\n",
    "        else:\n",
    "            staid = staid_wmo_str.strip()[:4]\n",
    "            staid = staid.replace(\" \", \"\")\n",
    "        wmo = 99999\n",
    "    print(staid)\n",
    "    # Read the next header line and extract the location information from it\n",
    "    header3 = f.readline().strip().split(':')\n",
    "    location = header3[1].strip().split(',')\n",
    "    print(location)\n",
    "    lon = np.float(location[2])\n",
    "    lat = np.float(location[3])\n",
    "    elev = np.float(location[4])\n",
    "    # Read the next header line and extract the time information from it\n",
    "    header4 = f.readline().strip()[31:].lstrip()   \n",
    "    sounding_datetime = datetime.strptime(header4, '%Y, %m, %d, %H:%M:%S')\n",
    "    \n",
    "    # Now read and dump the rest of the header\n",
    "    for i in range(9):\n",
    "        f.readline()\n",
    "    \n",
    "    # Except for the last header line, which is used to determine the widths of the fields\n",
    "    line = f.readline().strip().split()\n",
    "    fw = [len(field)+1 for field in line]\n",
    "\n",
    "    # Now read the file into the dataframe, using the extracted field widths\n",
    "    df = pd.read_fwf(f, usecols=[1, 2, 3, 5, 6, 7, 8, 14, 15, 16, 17, 18, 19],\n",
    "                     names=col_names, na_values=['99999.0', '9999.0', '999.0'], widths=fw)\n",
    "    \n",
    "    # For some reason, need to convert all the columns to floating point here, as some get interpreted as strings\n",
    "    # when they shouldn't be...\n",
    "    # print(df['pressure'], df['temperature'])\n",
    "    for column in df.columns:\n",
    "        df[column] = df[column].astype(np.float)\n",
    "    \n",
    "    # Drop rows where height or pressure is NaN. TODO: Can't remember why I have to use reset_index(drop=True). \n",
    "    # Figure this out.\n",
    "    df = df.dropna(subset=('height', 'pressure')).reset_index(drop=True)\n",
    "    # Set the height as the index so we can use it as weights to interpolate other columns across NaN\n",
    "    df = df.set_index('height')\n",
    "    df['height'] = df.index\n",
    "    \n",
    "    if interpnan:\n",
    "        # First convert direction and speed to u, v components\n",
    "        df['u'], df['v'] = mpcalc.wind_components(df['speed'].values*units('m/s'),\n",
    "                                                      df['direction'].values*units.degrees)\n",
    "        # Now interpolate\n",
    "        df = df.interpolate(method='values')\n",
    "        # Finally recompute direction and speed from u, v components\n",
    "        df['speed'] = mpcalc.wind_speed(df['u'].values*units('m/s'), df['v'].values*units('m/s'))\n",
    "        df['direction'] = mpcalc.wind_direction(df['u'].values*units('m/s'), df['v'].values*units('m/s'))\n",
    "    else:\n",
    "        # Drop any rows with all NaN values for T, Td, winds\n",
    "        df = df.dropna(subset=('temperature', 'dewpoint', 'direction', 'speed',\n",
    "                               'u_wind', 'v_wind'), how='all').reset_index(drop=True)\n",
    "    \n",
    "    df = df[(df.Qp_code == 1.0) & (df.Qt_code == 1.0) & (df.Qrh_code == 1.0) & (df.Qu_code == 1.0) & \n",
    "            (df.Qv_code == 1.0)]\n",
    "\n",
    "    nlines = df.count()['pressure']\n",
    "    \n",
    "    if not handle:\n",
    "        f.close()\n",
    "    \n",
    "    snd_metadata = {\n",
    "        'sounding_datetime': sounding_datetime,\n",
    "        'lat': lat,\n",
    "        'lon': lon,\n",
    "        'selev': elev,\n",
    "        'staid': staid,\n",
    "        'wmo': wmo,\n",
    "        'nlevs': nlines,\n",
    "        'staid_long': staid_wmo_str\n",
    "    }\n",
    "    \n",
    "    return snd_metadata, df\n",
    "\n",
    "\n",
    "def roundPartial(value, resolution, decimals=4):\n",
    "    return np.around(np.round(value / resolution) * resolution, decimals=decimals)\n",
    "\n",
    "\n",
    "def rain_Brandes(D):\n",
    "    \"\"\"Given a range of diameters D, compute rain fall speed curve, a quartic polynomial\n",
    "       fit after Brandes et al. (2002).\"\"\"\n",
    "    \n",
    "    D_mm=D*1000. # get it to (mm)\n",
    "    \n",
    "    Vtr = -0.1021 + 4.932*D_mm - 0.9551*D_mm**2. + 0.07934*D_mm**3. - 0.002362*D_mm**4.\n",
    "    \n",
    "    return Vtr\n",
    "\n",
    "\n",
    "def cal_xf_tf(usm, vsm, vt, H, perturb_vt=False, sigma=0.1):\n",
    "    \"\"\"Computes final horizontal position and residence time (relative to starting position) of a raindrop\n",
    "       falling through a horizontally homogeneous layer H with terminal velocity vt and \n",
    "       storm releative mean wind given by (usm, vsm).\"\"\"\n",
    "    \n",
    "    if perturb_vt:\n",
    "        rng = np.random.default_rng()\n",
    "        vt_perts = sigma * rng.standard_normal(vt.size)\n",
    "        vt = vt + vt_perts\n",
    "    \n",
    "    tf = H / vt\n",
    "    xf = tf * usm\n",
    "    yf = tf * vsm\n",
    "    \n",
    "    return xf, yf, tf\n",
    "\n",
    "\n",
    "def mtokm(val,pos):\n",
    "    \"\"\"Convert m to km for formatting axes tick labels\"\"\"\n",
    "    val=val/1000.0\n",
    "    return '%i' % val\n",
    "\n",
    "def interpolate_all(gridded_radar, tinterp_intv, base_field_name='reflectivity_masked'):\n",
    "    # Get list of intervals in seconds between subsequent radar times\n",
    "    tdiffs = gridded_radar['time_seconds'].diff(dim='time')\n",
    "    \n",
    "    # This list will hold all the time-interpolated grids (xarray Datasets). \n",
    "    # Can later be concatenated into a new xarray Dataset containing all times\n",
    "    gridded_radar_interp_list = []\n",
    "    \n",
    "    # Grab first time from full dataset and restore singular time dimension\n",
    "    first_time_ds = gridded_radar.isel(time=0)\n",
    "    first_time_ds = first_time_ds.expand_dims(dim='time')\n",
    "\n",
    "    gridded_radar_interp_list.append(first_time_ds)\n",
    "    \n",
    "#     tbgn = first_time_ds.coords['time_seconds'].values.item()  # Need to get scalar value, not 0-d\n",
    "#                                                                # numpy array\n",
    "    \n",
    "    # Loop through the gridded_radar times, perform advection correction/interpolation between successive times\n",
    "    # and add each to the list, making sure the time coordinate is consistent\n",
    "    # new_time = tbgn\n",
    "    for i, tdiff in enumerate(tdiffs.values):\n",
    "        gridded_radar_interp_sublist = advection_correction_ds(gridded_radar.isel(time=slice(i, i+2)), \n",
    "                                                               tdiff, tinterp_intv, \n",
    "                                                               base_field_name=base_field_name)\n",
    "        for t, gridded_radar_interp in enumerate(gridded_radar_interp_sublist):\n",
    "#             new_time = new_time + tinterp_intv\n",
    "#             new_ds = first_time_ds.copy()\n",
    "#             new_ds[:] = gridded_radar_interp\n",
    "#             new_ds.coords['time'] = new_ds['time'] + np.timedelta64(int(new_time), 's')\n",
    "#             new_ds.coords['time_seconds'] = new_time\n",
    "            gridded_radar_interp_list.append(gridded_radar_interp)\n",
    "    \n",
    "    return gridded_radar_interp_list\n",
    "\n",
    "\n",
    "def advection_correction_ds(radar_ds, tintv_obs, tintv, base_field_name='reflectivity_masked', method=\"LK\"):\n",
    "    # Evaluate advection\n",
    "    oflow_method = motion.get_method(method)\n",
    "    fd_kwargs = {\"buffer_mask\": 10}  # avoid edge effects\n",
    "\n",
    "    base_field = radar_ds[base_field_name]\n",
    "    oflow_field = oflow_method(base_field, fd_kwargs=fd_kwargs)\n",
    "    \n",
    "    # Perform temporal interpolation on all variables in Dataset using the flow field derived from the \"base\"\n",
    "    # field (by default, reflectivity)\n",
    "    \n",
    "    tbgn = base_field[0].coords['time_seconds'].values.item()   # Need to get scalar value, not 0-d\n",
    "                                                                # numpy array\n",
    "    \n",
    "    radar_ds_list = []\n",
    "    x, y = np.meshgrid(\n",
    "        np.arange(base_field[0].shape[1], dtype=float), np.arange(base_field[0].shape[0], dtype=float),\n",
    "    )\n",
    "    \n",
    "    new_time = tbgn\n",
    "    for i in np.arange(tintv, tintv_obs + tintv, tintv):\n",
    "\n",
    "        new_time = new_time + tintv\n",
    "        \n",
    "        pos1 = (y - i / tintv_obs * oflow_field[1], x - i / tintv_obs * oflow_field[0])\n",
    "        pos2 = (y + (tintv_obs - i) / tintv_obs * oflow_field[1], \n",
    "                x + (tintv_obs - i) / tintv_obs * oflow_field[0])\n",
    "        \n",
    "        field_interp_list = []\n",
    "        for field_name, field_da in radar_ds.items():\n",
    "            fieldt1 = map_coordinates(field_da[0], pos1, order=1)\n",
    "            fieldt2 = map_coordinates(field_da[1], pos2, order=1)\n",
    "       \n",
    "            field_interp = field_da.isel(time=[0]).copy()\n",
    "            field_interp[:] = ((tintv_obs - i) * fieldt1 + i * fieldt2) / tintv_obs\n",
    "            field_interp.coords['time'] = field_interp['time'] + np.timedelta64(int(new_time - tbgn), 's')\n",
    "            field_interp.coords['time_seconds'] = new_time\n",
    "            field_interp_list.append(field_interp)\n",
    "        \n",
    "        radar_ds_interp = xr.merge(field_interp_list)\n",
    "        radar_ds_list.append(radar_ds_interp)\n",
    "        \n",
    "    return radar_ds_list\n",
    "\n",
    "\n",
    "def advection_correction(arr, tintv_obs, tintv):\n",
    "    \"\"\"\n",
    "    R = np.array([qpe_previous, qpe_current])\n",
    "    T = time between two observations (5 min)\n",
    "    t = interpolation timestep (1 min)\n",
    "    \"\"\"\n",
    "\n",
    "    # Evaluate advection\n",
    "    oflow_method = motion.get_method(\"LK\")\n",
    "    fd_kwargs = {\"buffer_mask\": 10}  # avoid edge effects\n",
    "    V = oflow_method(arr, fd_kwargs=fd_kwargs)\n",
    "\n",
    "    # Perform temporal interpolation\n",
    "    # arr_d = np.zeros((arr[0].shape))\n",
    "    arr_list = []\n",
    "    x, y = np.meshgrid(\n",
    "        np.arange(arr[0].shape[1], dtype=float), np.arange(arr[0].shape[0], dtype=float),\n",
    "    )\n",
    "    for i in np.arange(tintv, tintv_obs + tintv, tintv):\n",
    "\n",
    "        pos1 = (y - i / tintv_obs * V[1], x - i / tintv_obs * V[0])\n",
    "        R1 = map_coordinates(arr[0], pos1, order=1)\n",
    "        \n",
    "        pos2 = (y + (tintv_obs - i) / tintv_obs * V[1], x + (tintv_obs - i) / tintv_obs * V[0])\n",
    "        R2 = map_coordinates(arr[1], pos2, order=1)\n",
    "\n",
    "        arr_interp = ((tintv_obs - i) * R1 + i * R2) / tintv_obs\n",
    "        arr_list.append(arr_interp)\n",
    "\n",
    "    return arr_list\n",
    "\n",
    "\n",
    "def plot_animation(xplt, yplt, field, clevels, cbarlabel=None, cbarintv=None, cmap='pyart_HomeyerRainbow', \n",
    "                   norm=None, PIPS_list=None, PIPS_xy_list=None, ax=None, ptype='pcolor', axestickintv=10000., \n",
    "                   axeslimits=None):\n",
    "    \n",
    "    if norm is None:\n",
    "        norm = cm.colors.Normalize(vmin=clevels[0], vmax=clevels[-1])\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    else:\n",
    "        fig = ax.get_figure()\n",
    "    ims = []\n",
    "    for i, var in enumerate(var_da):\n",
    "        plotdata = []\n",
    "        time = np.datetime_as_string(var.coords['time'].values, unit='m')  # Ugly, but whatever\n",
    "        \n",
    "        title = ax.text(0.5,1.05,\"Time: {}\".format(time), \n",
    "                        size=plt.rcParams[\"axes.titlesize\"],\n",
    "                        ha=\"center\", transform=ax.transAxes)\n",
    "        plotdata.append(title)\n",
    "        \n",
    "        if ptype == 'pcolor':\n",
    "            ci = ax.pcolormesh(xplt, yplt, var.squeeze(), vmin=clevels[0], vmax=clevels[-1], cmap=cmap, \n",
    "                                     norm=norm)\n",
    "            plotdata.append(ci)\n",
    "        else:\n",
    "            ci = ax.contourf(xplt, yplt, var.squeeze(), levels=clevels, \n",
    "                             cmap=cmap, norm=norm)\n",
    "            plotdata.extend(ci.collections)\n",
    "            \n",
    "        if PIPS_list is not None and PIPS_xy_list is not None:\n",
    "            # Plot PIPS locations\n",
    "            for PIPS, PIPS_xy in zip(PIPS_list, PIPS_xy_list):\n",
    "                PIPS_x = PIPS_xy[0]\n",
    "                PIPS_y = PIPS_xy[1]\n",
    "                ax.plot([PIPS_x], [PIPS_y], 'k*')\n",
    "        if i == 0.:\n",
    "            if cbarintv is None:\n",
    "                cbarintv = clevels[1] - clevels[0]\n",
    "            cbarlevels = ticker.MultipleLocator(base=cbarintv)\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            fig.colorbar(ci, orientation='vertical', ticks=cbarlevels, cax=cax)\n",
    "            if cbarlabel is not None:\n",
    "                cax.set_ylabel(cbarlabel)\n",
    "            formatter = ticker.FuncFormatter(mtokm)\n",
    "            ax.xaxis.set_major_formatter(formatter)\n",
    "            ax.yaxis.set_major_formatter(formatter)\n",
    "            ax.xaxis.set_major_locator(ticker.MultipleLocator(base=axestickintv))\n",
    "            ax.yaxis.set_major_locator(ticker.MultipleLocator(base=axestickintv))\n",
    "            ax.set_xlabel('km')\n",
    "            ax.set_ylabel('km')\n",
    "            if axeslimits is None:\n",
    "                xmin = xplt[0]\n",
    "                xmax = xplt[-1]\n",
    "                ymin = yplt[0]\n",
    "                ymax = yplt[-1]\n",
    "            else:\n",
    "                xmin, xmax, ymin, ymax = axeslimits\n",
    "            ax.set_xlim(xmin, xmax)\n",
    "            ax.set_ylim(ymin, ymax)\n",
    "            ax.set_aspect('equal')\n",
    "            \n",
    "        ims.append(plotdata)\n",
    "    \n",
    "    ani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                    repeat_delay=1000)\n",
    "    plt.close()\n",
    "    return ani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T22:55:49.600277Z",
     "start_time": "2021-01-02T22:55:49.480673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the file containing the original gridded radar at the top of the sorting layer\n",
    "\n",
    "# 03/25 case\n",
    "radar_name = 'KGWX'\n",
    "radar_type= 'NEXRAD'\n",
    "date = '0325'\n",
    "radar_start_datetimestamp = '20170325170500'\n",
    "radar_end_datetimestamp = '20170325183559'\n",
    "height = 2000.\n",
    "\n",
    "# Create datetime objects for start and end times\n",
    "datetime_start = datetime.strptime(radar_start_datetimestamp, '%Y%m%d%H%M%S')\n",
    "datetime_end = datetime.strptime(radar_end_datetimestamp, '%Y%m%d%H%M%S')\n",
    "\n",
    "radar_basedir = \\\n",
    "    '/Volumes/scr_fast/Projects/VORTEXSE/obsdata/2017/NEXRAD/IOP_1A/'\n",
    "gridded_radar_dir = os.path.join(radar_basedir, 'gridded_new')\n",
    "# plot_dir = os.path.join(gridded_radar_dir, 'plots')\n",
    "plot_dir = '/Users/dawson29/Dropbox/Students/Marcus_Terrell/plots/'\n",
    "if not os.path.exists(plot_dir):\n",
    "    os.makedirs(plot_dir)\n",
    "\n",
    "radar_start_timestamp = datetime_start.strftime('%Y%m%d%H%M')\n",
    "radar_end_timestamp = datetime_end.strftime('%Y%m%d%H%M')\n",
    "\n",
    "# Read in original gridded radar at top of sorting layer\n",
    "gridded_radar_interp_filename = '{}_{}_{}_z{:d}_gridded_interp.nc'.format(radar_name, radar_start_timestamp,\n",
    "                                                                          radar_end_timestamp, int(height))\n",
    "gridded_radar_interp_filepath = os.path.join(gridded_radar_dir, gridded_radar_interp_filename)\n",
    "gridded_radar_interp_ds = xr.open_dataset(gridded_radar_interp_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T22:55:50.207636Z",
     "start_time": "2021-01-02T22:55:50.123510Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the \"sorted\" gridded radar at bottom of sorting layer\n",
    "radar_sorted_start_datetimestamp = '20170325170500'\n",
    "radar_sorted_end_datetimestamp = '20170325183559'\n",
    "\n",
    "# Create datetime objects for start and end times\n",
    "datetime_start = datetime.strptime(radar_sorted_start_datetimestamp, '%Y%m%d%H%M%S')\n",
    "datetime_end = datetime.strptime(radar_sorted_end_datetimestamp, '%Y%m%d%H%M%S')\n",
    "\n",
    "radar_sorted_start_timestamp = datetime_start.strftime('%Y%m%d%H%M')\n",
    "radar_sorted_end_timestamp = datetime_end.strftime('%Y%m%d%H%M')\n",
    "\n",
    "gridded_radar_sorted_filename = '{}_{}_{}_d{:d}_gridded_sorted.nc'.format(radar_name, \n",
    "                                                                          radar_sorted_start_timestamp,\n",
    "                                                                          radar_sorted_end_timestamp, \n",
    "                                                                          int(height))\n",
    "gridded_radar_sorted_filepath = os.path.join(gridded_radar_dir, gridded_radar_sorted_filename)\n",
    "gridded_radar_sorted_ds = xr.open_dataset(gridded_radar_sorted_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray 'z' ()>\n",
      "array(2000.)\n",
      "Coordinates:\n",
      "    z        float64 2e+03\n",
      "Attributes:\n",
      "    standard_name:  projection_z_coordinate\n",
      "    long_name:      Z distance on the projection plane from the origin\n",
      "    axis:           Z\n",
      "    units:          m\n",
      "    positive:       up\n"
     ]
    }
   ],
   "source": [
    "print(gridded_radar_interp_ds['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T22:55:53.346368Z",
     "start_time": "2021-01-02T22:55:53.282164Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract x and y coordinates from sorted grid file. These represent the *left* edges of the grid cells,\n",
    "# not the centers, and are therefore missing the final *right* edge. This is because of the way I constructed\n",
    "# the coordinates. I really should have used the grid centers. Anyway, add the final edge here and then\n",
    "# calculate the grid centers\n",
    "# TODO: go back and fix this in the calc_precip_trajectories... notebook\n",
    "\n",
    "xedges = gridded_radar_sorted_ds.coords['x'].values\n",
    "dx = xedges[1] - xedges[0]\n",
    "xedges = np.append(xedges, xedges[-1] + dx)\n",
    "\n",
    "yedges = gridded_radar_sorted_ds.coords['y'].values\n",
    "dy = yedges[1] - yedges[0]\n",
    "yedges = np.append(yedges, yedges[-1] + dy)\n",
    "\n",
    "xctr = 0.5 * (xedges[1:] + xedges[:-1])\n",
    "yctr = 0.5 * (yedges[1:] + yedges[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T22:55:54.670301Z",
     "start_time": "2021-01-02T22:55:54.287683Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in PIPS data (just to get lat/lon for now)\n",
    "deployment = 'IOP1A_D1_2017'\n",
    "PIPS_list = ['PIPS1A', 'PIPS1B', 'PIPS2B']\n",
    "PIPS_data_dir = '/Volumes/scr_fast/Projects/VORTEXSE/obsdata/full_PIPS_dataset_RB15'\n",
    "\n",
    "PIPS_ds_list = []\n",
    "PIPS_locs = []\n",
    "\n",
    "for PIPS in PIPS_list:\n",
    "    PIPS_filename = 'parsivel_combined_{}_{}_60s.nc'.format(deployment, PIPS)\n",
    "    PIPS_filepath = os.path.join(PIPS_data_dir, PIPS_filename)\n",
    "    PIPS_ds = xr.load_dataset(PIPS_filepath)\n",
    "    PIPS_ds_list.append(PIPS_ds)\n",
    "    PIPS_loc = eval(PIPS_ds.location)\n",
    "    PIPS_locs.append(PIPS_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T22:55:56.190957Z",
     "start_time": "2021-01-02T22:55:56.125420Z"
    }
   },
   "outputs": [],
   "source": [
    "# Find PIPS x, y location by interpolating to its lat/lon point\n",
    "gridded_radar_interp_latlon_ds = gridded_radar_interp_ds.swap_dims({'x': 'lon', 'y': 'lat'})\n",
    "\n",
    "radar_at_PIPS_list = []\n",
    "PIPS_xy_list = []\n",
    "\n",
    "for PIPS_loc in PIPS_locs:\n",
    "    PIPS_lat = PIPS_loc[0]\n",
    "    PIPS_lon = PIPS_loc[1]\n",
    "    radar_at_PIPS_da = gridded_radar_interp_latlon_ds.interp(lat=PIPS_lat, lon=PIPS_lon)\n",
    "    print(PIPS_lat, PIPS_lon)\n",
    "    PIPS_x = radar_at_PIPS_da['x'].values.item()\n",
    "    PIPS_y = radar_at_PIPS_da['y'].values.item()\n",
    "    PIPS_xy = (PIPS_x, PIPS_y)\n",
    "    PIPS_xy_list.append(PIPS_xy)\n",
    "    print(PIPS_x, PIPS_y)\n",
    "    radar_at_PIPS_list.append(radar_at_PIPS_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T22:55:58.536551Z",
     "start_time": "2021-01-02T22:55:58.431210Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in sounding file to get low-level wind field and then derive storm-relative wind\n",
    "# Storm motion taken from subjective reflectivity tag tracking using GRLevel2\n",
    "# EDIT: don't need storm motion because it is implicitly handled in time-dependent trajectory model\n",
    "# ustorm = 12.51\n",
    "# vstorm = 12.95\n",
    "\n",
    "# EDIT: setting ustorm, vstorm to 0 to force ground-relative flow\n",
    "ustorm = 0.\n",
    "vstorm = 0.\n",
    "\n",
    "sounding_dir = '/Users/terrell8/Dropbox/0325_sounding/sounding_zip/'\n",
    "sounding_filename = 'Courtland_1759.txt'\n",
    "# sounding_dir = '/Users/dawson29/sshfs_mounts/depot/data/Projects/VORTEXSE/obsdata/2017/soundings/COMP5mb'\n",
    "# sounding_filename = 'Hollywood_201704301954.cls'\n",
    "sounding_path = os.path.join(sounding_dir, sounding_filename)\n",
    "sounding_metadata, sounding_df = readESC(sounding_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-03T03:35:25.838743Z",
     "start_time": "2021-01-03T03:35:25.229541Z"
    }
   },
   "outputs": [],
   "source": [
    "from metpy.plots import SkewT, Hodograph\n",
    "\n",
    "# ustorm, vstorm = (4.121136597951332, 6.968096312979091) # From mean of pysteps u and v field (04/30)\n",
    "# ustorm, vstorm = (4.893569553782078, 2.6387864245583765) # 03/27\n",
    "ustorm, vstorm = (3.164247877224066, 5.370989998643443) #03/25\n",
    "\n",
    "hodo_units='m/s'\n",
    "\n",
    "u = sounding_df['u']\n",
    "v = sounding_df['v']\n",
    "z = sounding_df['height'] - sounding_metadata['selev']\n",
    "\n",
    "u1km = u.loc[z <= 1000.]\n",
    "v1km = v.loc[z <= 1000.]\n",
    "\n",
    "u1kmavg = u1km.mean()\n",
    "v1kmavg = v1km.mean()\n",
    "\n",
    "ug1km = u.loc[~(z <= 1000.)]\n",
    "vg1km = v.loc[~(z <= 1000.)]\n",
    "\n",
    "hodo = Hodograph(component_range=40)\n",
    "hodo.add_grid(increment=10)\n",
    "if(hodo_units == 'm/s'):\n",
    "    hodo.plot(u, v, color='b')\n",
    "    hodo.plot(u1km, v1km, color='r')\n",
    "    hodo.plot(u1kmavg, v1kmavg, color='k', marker='o')\n",
    "    hodo.plot(ustorm, vstorm, color='purple', marker='o')\n",
    "    hodo.plot([ustorm, u1kmavg], [vstorm, v1kmavg], color='purple', linewidth=0.5)\n",
    "    hodo.ax.set_xlim(-10., 20.)\n",
    "    hodo.ax.set_ylim(0., 30.)\n",
    "    hodo.ax.set_xlabel(r'm s$^{-1}$')\n",
    "    hodo.ax.set_ylabel(r'm s$^{-1}$')\n",
    "else:\n",
    "    hodo.plot(u,v)\n",
    "    hodo.ax.set_xlabel('kts')\n",
    "    hodo.ax.set_ylabel('kts')\n",
    "#hodo.ax.set_xlim(-10.,40.)\n",
    "\n",
    "plot_filename = '{}_hodo.png'.format(sounding_filename[:-4]) \n",
    "plot_filepath = os.path.join(plot_dir, plot_filename)\n",
    "plt.savefig(plot_filepath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T22:56:06.379111Z",
     "start_time": "2021-01-02T22:56:06.311591Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set up start and end time objects and strings for animations\n",
    "# 04/30 case\n",
    "# anim_start = '2017-04-30T20:00'\n",
    "# anim_end = '2017-04-30T21:30'\n",
    "\n",
    "# 03/25 case\n",
    "anim_start = '2017-03-25T17:00'\n",
    "anim_end = '2017-03-25T18:45'\n",
    "\n",
    "anim_start_datetime = datetime.strptime(anim_start, '%Y-%m-%dT%H:%M')\n",
    "anim_end_datetime = datetime.strptime(anim_end, '%Y-%m-%dT%H:%M')\n",
    "\n",
    "anim_start_out = anim_start_datetime.strftime('%Y%m%d%H%M')\n",
    "anim_end_out = anim_end_datetime.strftime('%Y%m%d%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T20:00:50.101139Z",
     "start_time": "2020-12-31T20:00:00.017278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot reflectivity for time-interpolated grid\n",
    "var_da = gridded_radar_interp_ds['reflectivity_masked'].sel(time=slice(anim_start, anim_end))\n",
    "# print(var_da.coords['time'].values)\n",
    "xplt = var_da.coords['x']\n",
    "yplt = var_da.coords['y']\n",
    "\n",
    "clevels = np.arange(0., 61., 1.)\n",
    "cbarintv = 10.\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=60.)\n",
    "\n",
    "ani = plot_animation(xplt, yplt, var_da, clevels, cbarintv=cbarintv, cbarlabel='dBZ', \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm, PIPS_list=PIPS_list, PIPS_xy_list=PIPS_xy_list, \n",
    "                     ax=None, ptype='contourf', axestickintv=50000., axeslimits=None)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T20:11:14.467735Z",
     "start_time": "2020-12-31T20:10:34.469180Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = '{}_{}_{}_grid_z{:d}_big_dBZ.mp4'.format(radar_name, anim_start_out, anim_end_out, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-30T20:03:54.316697Z",
     "start_time": "2020-12-30T20:01:38.783987Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot ND animation for a given diameter bin\n",
    "D_to_plot = 1.  # Diameter of raindrop to plot. Will select the nearest central value of the Parsivel bin\n",
    "\n",
    "var_da = gridded_radar_sorted_ds['ND'].sel(diameter=D_to_plot, method='nearest')\n",
    "var_da = var_da.sel(time=slice(anim_start, anim_end))\n",
    "\n",
    "clevels = np.logspace(-1., 4., num=100)\n",
    "norm = cm.colors.LogNorm(vmin=1., vmax=10000.)\n",
    "\n",
    "# Put call to plot_animation here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T20:15:53.313453Z",
     "start_time": "2020-12-31T20:15:03.391483Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot reflectivity at bottom of sorting layer\n",
    "\n",
    "var_da = gridded_radar_sorted_ds['REF']\n",
    "clevels =np.arange(0., 61., 1.)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=60.)\n",
    "cbarintv = 10.\n",
    "\n",
    "ani = plot_animation(xctr, yctr, var_da, clevels, cbarintv=cbarintv, cbarlabel='dBZ', \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm, PIPS_list=PIPS_list, PIPS_xy_list=PIPS_xy_list, \n",
    "                     ax=None, ptype='contourf', axestickintv=10000., axeslimits=None)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T20:19:01.021266Z",
     "start_time": "2020-12-31T20:18:21.532342Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = '{}_{}_{}_d{:d}_grid_bottom_dBZ.mp4'.format(radar_name, radar_sorted_start_timestamp, \n",
    "                                                     radar_sorted_end_timestamp, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T20:21:18.061775Z",
     "start_time": "2020-12-31T20:20:28.212085Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot reflectivity at top of sorting layer (zoomed in to same limits as the animation at the bottom of the\n",
    "# sorting layer)\n",
    "\n",
    "var_da = gridded_radar_interp_ds['reflectivity_masked'].sel(time=slice(anim_start, anim_end))\n",
    "xplt = gridded_radar_interp_ds.coords[\"x\"]\n",
    "yplt = gridded_radar_interp_ds.coords[\"y\"]\n",
    "\n",
    "clevels =np.arange(0., 61., 1.)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=60.)\n",
    "cbarintv = 10.\n",
    "\n",
    "ani = plot_animation(xplt, yplt, var_da, clevels, cbarintv=cbarintv, cbarlabel='dBZ', \n",
    "                     cmap='pyart_HomeyerRainbow', norm=norm, PIPS_loc=[PIPS_x, PIPS_y], ax=None, \n",
    "                     ptype='contourf', axestickintv=50000., axeslimits=[xedges[0], xedges[-1], \n",
    "                                                                        yedges[0], yedges[-1]])\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T20:22:43.558172Z",
     "start_time": "2020-12-31T20:22:06.639758Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = '{}_{}_{}_grid_z{:d}_dBZ.mp4'.format(radar_name, anim_start_out, anim_end_out, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T21:19:40.049724Z",
     "start_time": "2020-12-31T21:18:57.802450Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot ZDR at bottom of sorting layer\n",
    "\n",
    "var_da = gridded_radar_sorted_ds['ZDR']\n",
    "clevels =np.arange(0., 6., 0.1)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=6.)\n",
    "cbarintv = 1.\n",
    "\n",
    "ani = plot_animation(xctr, yctr, var_da, clevels, cbarintv=cbarintv, cbarlabel='ZDR (dB)', \n",
    "                     cmap='plasma', norm=norm, PIPS_loc=[PIPS_x, PIPS_y], ax=None, \n",
    "                     ptype='contourf', axestickintv=50000., axeslimits=None)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T21:24:01.143576Z",
     "start_time": "2020-12-31T21:23:24.866606Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = '{}_{}_{}_d{:d}_grid_bottom_ZDR.mp4'.format(radar_name, anim_start_out, anim_end_out, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T21:26:42.347611Z",
     "start_time": "2020-12-31T21:25:53.216475Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot ZDR at top of sorting layer (zoomed in to same limits as the animation at the bottom of the\n",
    "# sorting layer)\n",
    "\n",
    "var_da = gridded_radar_interp_ds['differential_reflectivity_masked'].sel(time=slice(anim_start, anim_end))\n",
    "xplt = gridded_radar_interp_ds.coords[\"x\"]\n",
    "yplt = gridded_radar_interp_ds.coords[\"y\"]\n",
    "\n",
    "clevels =np.arange(0., 6., 0.1)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=6.)\n",
    "cbarintv = 1.\n",
    "\n",
    "ani = plot_animation(xplt, yplt, var_da, clevels, cbarintv=cbarintv, cbarlabel='ZDR (dB)', \n",
    "                     cmap='plasma', norm=norm, PIPS_loc=[PIPS_x, PIPS_y], ax=None, \n",
    "                     ptype='contourf', axestickintv=50000., axeslimits=[xedges[0], xedges[-1], \n",
    "                                                                        yedges[0], yedges[-1]])\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T21:27:59.505345Z",
     "start_time": "2020-12-31T21:27:23.946597Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save above animation to disk\n",
    "ani_filename = '{}_{}_{}_grid_z{:d}_ZDR.mp4'.format(radar_name, anim_start_out, anim_end_out, int(height))\n",
    "ani_filepath = os.path.join(plot_dir, ani_filename)\n",
    "\n",
    "ani.save(ani_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-31T21:29:20.091024Z",
     "start_time": "2020-12-31T21:29:20.007381Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute polarimetric fields from PIPS DSDs\n",
    "dD = PIPS_ds['max_diameter'] - PIPS_ds['min_diameter']\n",
    "dualpol_dict_PIPS = dualpol.calpolrain_bulk_xr(10.7, \n",
    "                                               '/Users/dawson29/Projects/pyPIPS/tmatrix/S-Band/SCTT_RAIN_fw100.dat',\n",
    "                                               PIPS_ds['ND_qc'], dD, diameter_bin_name='diameter_bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T18:11:28.747292Z",
     "start_time": "2021-01-01T18:11:28.661097Z"
    }
   },
   "outputs": [],
   "source": [
    "# Interpolate Z and ZDR from sorted grid to PIPS location\n",
    "ZH_sorted_PIPS_da = gridded_radar_sorted_ds['REF'].interp(x=PIPS_x, y=PIPS_y)\n",
    "ZDR_sorted_PIPS_da = gridded_radar_sorted_ds['ZDR'].interp(x=PIPS_x, y=PIPS_y)\n",
    "ZH_PIPS = dualpol_dict_PIPS['REF']\n",
    "ZDR_PIPS = dualpol_dict_PIPS['ZDR']\n",
    "ZH_radar_at_PIPS = PIPS_ds['KHTX_at_PIPS'].sel(fields_KHTX='REF_filtered')\n",
    "ZDR_radar_at_PIPS = PIPS_ds['KHTX_at_PIPS'].sel(fields_KHTX='ZDR_filtered')\n",
    "ZH_gridded_radar_at_PIPS = radar_at_PIPS_da['reflectivity_masked']\n",
    "ZDR_gridded_radar_at_PIPS = radar_at_PIPS_da['differential_reflectivity_masked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T18:21:44.653447Z",
     "start_time": "2021-01-01T18:21:44.583905Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_start = '2017-04-30T20:30'\n",
    "plot_end = '2017-04-30T21:30'\n",
    "\n",
    "plot_start_datetime = datetime.strptime(plot_start, '%Y-%m-%dT%H:%M')\n",
    "plot_end_datetime = datetime.strptime(plot_end, '%Y-%m-%dT%H:%M')\n",
    "\n",
    "plot_start_out = plot_start_datetime.strftime('%Y%m%d%H%M')\n",
    "plot_end_out = plot_end_datetime.strftime('%Y%m%d%H%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T18:25:02.710115Z",
     "start_time": "2021-01-01T18:25:01.621697Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot reflectivity at PIPS location, comparing PIPS observation, gridded radar at 1 km, and sorting-model\n",
    "# results at the surface\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ZH_PIPS.plot.line(xlim=(plot_start, plot_end), color='k', label='PIPS observed surface DSD')\n",
    "ZH_gridded_radar_at_PIPS.plot.line(xlim=(plot_start, plot_end), color='r', label='Radar at 1km AGL')\n",
    "ZH_sorted_PIPS_da.plot.line(xlim=(plot_start, plot_end), color='b', label='Sorting-model surface DSD')\n",
    "ax.legend()\n",
    "ax.set_title('Reflectivity at PIPS')\n",
    "ax.set_ylabel('dBZ')\n",
    "ax.set_ylim(0.0, 60.0)\n",
    "\n",
    "plot_filename = 'Z_at_PIPS_{}_{}.png'.format(plot_start_out, plot_end_out)\n",
    "plot_path = os.path.join(plot_dir, plot_filename)\n",
    "fig.savefig(plot_path, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-01T18:28:01.820022Z",
     "start_time": "2021-01-01T18:28:00.712839Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot differential reflectivity at PIPS location, comparing PIPS observation, gridded radar at 1 km, and \n",
    "# sorting-model results at the surface\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ZDR_PIPS.plot.line(xlim=(plot_start, plot_end), color='k', label='PIPS observed surface DSD')\n",
    "ZDR_gridded_radar_at_PIPS.plot.line(xlim=(plot_start, plot_end), color='r', label='Radar at 1km AGL')\n",
    "ZDR_sorted_PIPS_da.plot.line(xlim=(plot_start, plot_end), color='b', label='Sorting-model surface DSD')\n",
    "ax.legend()\n",
    "ax.set_title('Differential Reflectivity at PIPS')\n",
    "ax.set_ylabel('dB')\n",
    "ax.set_ylim(0.0, 4.0)\n",
    "\n",
    "plot_filename = 'ZDR_at_PIPS_{}_{}.png'.format(plot_start_out, plot_end_out)\n",
    "plot_path = os.path.join(plot_dir, plot_filename)\n",
    "fig.savefig(plot_path, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T23:04:34.995447Z",
     "start_time": "2021-01-02T23:04:34.004596Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot ZDR at bottom of sorting layer for a single time\n",
    "\n",
    "gridded_radar_sorted_ds_2 = gridded_radar_sorted_ds.swap_dims({'time': 'time_seconds'})\n",
    "\n",
    "var_da = gridded_radar_sorted_ds_2['ZDR'].sel(time_seconds=120.)\n",
    "clevels =np.arange(0., 4., 0.1)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=4.)\n",
    "cbarintv = 1.\n",
    "\n",
    "xplt = gridded_radar_sorted_ds_2.coords[\"x\"]\n",
    "yplt = gridded_radar_sorted_ds_2.coords[\"y\"]\n",
    "# print(xplt[0], xplt[-1], yplt[0], yplt[-1])\n",
    "\n",
    "clevels =np.arange(0., 4., 0.1)\n",
    "norm = cm.colors.Normalize(vmin=0., vmax=4.)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ci = ax.contourf(xplt, yplt, var_da.squeeze(), levels=clevels, cmap='plasma', norm=norm)\n",
    "\n",
    "cbarintv = 1.\n",
    "cbarlevels = ticker.MultipleLocator(base=cbarintv)\n",
    "divider = make_axes_locatable(ax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "fig.colorbar(ci, orientation='vertical', ticks=cbarlevels, cax=cax)\n",
    "cax.set_ylabel('dB')\n",
    "\n",
    "ax.set_xlim(-26000., -16000.)\n",
    "ax.set_ylim(-40000., -30000.)\n",
    "formatter = ticker.FuncFormatter(mtokm)\n",
    "ax.xaxis.set_major_formatter(formatter)\n",
    "ax.yaxis.set_major_formatter(formatter)\n",
    "ax.set_xlabel('km')\n",
    "ax.set_ylabel('km')\n",
    "# ax.legend()\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plot_filename = 'ZDR_bottom_example.png'\n",
    "plot_filepath = os.path.join(plot_dir, plot_filename)\n",
    "fig.savefig(plot_filepath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-02T23:02:05.858578Z",
     "start_time": "2021-01-02T23:02:05.782896Z"
    }
   },
   "outputs": [],
   "source": [
    "print(gridded_radar_sorted_ds['time_seconds'])\n",
    "print(gridded_radar_sorted_ds['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

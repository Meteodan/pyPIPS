{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T15:57:46.371833Z",
     "start_time": "2019-09-07T15:57:43.506680Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid,make_axes_locatable,host_subplot\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import pytz as pytz\n",
    "import sys\n",
    "import os\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "import pyPIPS.disdrometer_module as dis\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "import pyPIPS.simulator as sim\n",
    "import pyPIPS.radarmodule as pyPIPSradar\n",
    "import pyPIPS.PIPS as pips\n",
    "from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "from pyCRMtools.pycaps import arps_read\n",
    "from pyCRMtools.pycaps import pycaps_fields\n",
    "from pyCRMtools.pycaps import calvars_radar as radar\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy.random as random\n",
    "from scipy.stats import gamma, uniform\n",
    "from scipy.special import gamma as gammafunc\n",
    "from scipy import ndimage\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.calc import get_wind_components\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.plots.wx_symbols import current_weather, sky_cover\n",
    "from metpy.units import units\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T15:57:49.131889Z",
     "start_time": "2019-09-07T15:57:49.067883Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define dictionaries, keyed by case date (i.e. '060509', '060709', '060909', '033116'), to store parameters related\n",
    "# to NEXRAD radar data, disdrometer data, and model output, respectively\n",
    "\n",
    "# Case we are looking at right now. Should only have to change this up here and then execute all the cells below\n",
    "# to generate the appropriate analysis\n",
    "casedate = '033116'\n",
    "\n",
    "# Import the file containing the dictionaries needed to gather the radar, disdrometer, and model data.\n",
    "sys.path.append('/Users/dawson29/Dropbox/Projects/VORTEXSE/vortexse_enkf_dsd_study/configs/2016_IOP3')\n",
    "\n",
    "from PIPSsim_1km_dicts import *\n",
    "\n",
    "init_radar_dict = init_radar_dict[casedate]\n",
    "init_dis_dict = init_dis_dict[casedate]\n",
    "init_model_dict = init_model_dict[casedate]\n",
    "\n",
    "load_pkl = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T15:59:21.896684Z",
     "start_time": "2019-09-07T15:57:51.150350Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_dir = '/Users/ddawson/Dropbox/Projects/VORTEXSE/vortexse_enkf_dsd_study/data/radar_data/pkl'\n",
    "pkl_file = '{}_KGWX.pkl'.format(casedate)\n",
    "pkl_path = os.path.join(pkl_dir, pkl_file)\n",
    "\n",
    "# Now go ahead and read in the sweeps for the desired case\n",
    "if not load_pkl:\n",
    "    radar_dict = sim.read_sweeps(init_radar_dict)\n",
    "    # Dump radar dictonary to pickle file\n",
    "    with open(pkl_path, 'wb') as pkl_file_obj:\n",
    "        pickle.dump(radar_dict, pkl_file_obj)\n",
    "else:\n",
    "    with open(pkl_path, 'rb') as pkl_file_obj:\n",
    "        radar_dict = pickle.load(pkl_file_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:00:28.656311Z",
     "start_time": "2019-09-07T15:59:22.286867Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Go ahead and read in the conventional data at the sweeptimes and plot them:\n",
    "# %matplotlib notebook\n",
    "plotdir = '/Users/dawson29/Dropbox/Projects/VORTEXSE/vortexse_enkf_dsd_study/plots'\n",
    "radlims = [0.0, 250000., 0., 360.]\n",
    "plotlims = [-1, -1, -1, -1]\n",
    "ovrmap = False # Currently not working\n",
    "ovrdis = False\n",
    "dis_name_list = None\n",
    "dxy_list = None\n",
    "fields_D_list = None\n",
    "deg2rad = np.pi / 180.\n",
    "\n",
    "# Read time series\n",
    "dis_dict_at_radar = sim.read_convdata_at_sweeptimes(init_dis_dict, radar_dict)\n",
    "\n",
    "# Find disdrometer lat/lons and convert them to cartesian coordinates relative to radar lat/lon\n",
    "\n",
    "dis_dict = sim.get_dis_locs_relative_to_radar(init_dis_dict, radar_dict)\n",
    "\n",
    "dxlist = [i[0] for i in dis_dict['dradloclist']]\n",
    "dylist = [i[1] for i in dis_dict['dradloclist']]\n",
    "\n",
    "# Set plotting limits to center on the disdrometer locations \n",
    "if plotlims[0] == -1:\n",
    "    Dxmin = min(dxlist)\n",
    "    Dxmax = max(dxlist)\n",
    "    Dymin = min(dylist)\n",
    "    Dymax = max(dylist)\n",
    "    plotlims = [Dxmin - 15000., Dxmax + 15000., Dymin - 15000., Dymax + 15000.]\n",
    "\n",
    "# Extract stuff from radar dictionary\n",
    "sweeptimelist = radar_dict['sweeptimelist']\n",
    "radarsweeplist = radar_dict['radarsweeplist']\n",
    "outfieldnames = radar_dict['outfieldnameslist'][0] # Just need first entry\n",
    "\n",
    "# Extract stuff from disdrometer dictionary\n",
    "templist = dis_dict_at_radar['convdata_at_sweeptimes']['temp']\n",
    "dewpointlist = dis_dict_at_radar['convdata_at_sweeptimes']['dewpoint']\n",
    "pressurelist = dis_dict_at_radar['convdata_at_sweeptimes']['pressure']\n",
    "windspdavgveclist = dis_dict_at_radar['convdata_at_sweeptimes']['windspdavgvec']\n",
    "winddiravgveclist = dis_dict_at_radar['convdata_at_sweeptimes']['winddiravgvec']\n",
    "\n",
    "\n",
    "for i, sweeptime in enumerate(sweeptimelist):\n",
    "    print(\"i, sweeptime = \", sweeptime)\n",
    "    figlist, gridlist = pyPIPSradar.plotsweep_pyART(radlims, plotlims, outfieldnames, radarsweeplist[i], ovrmap, \n",
    "                                                    ovrdis, dis_name_list, dxy_list, fields_D_list, alpha=0.5)\n",
    "    ax = gridlist[0][0]\n",
    "    \n",
    "    for j, Dx, Dy in zip(range(len(dxlist)), dxlist, dylist):\n",
    "        stationplot = StationPlot(ax, [Dx], [Dy])\n",
    "        stationplot.plot_parameter('NW', [templist[j][i]], color='purple')\n",
    "        stationplot.plot_parameter('SW', [dewpointlist[j][i]], color='darkgreen')\n",
    "        stationplot.plot_parameter('NE', [pressurelist[j][i]], formatter=lambda v: format(10 * v, '.0f')[-3:])\n",
    "        u, v = get_wind_components([windspdavgveclist[j][i]] * units('m/s'), [winddiravgveclist[j][i]] * units.degree)\n",
    "        stationplot.plot_barb(u, v, barb_increments=dict(half=0.5, full=1.0, flag=5.0))\n",
    "        \n",
    "        ax.text(Dx - 5000, Dy, dis_dict_at_radar['dis_names'][j], fontsize=10, \n",
    "                bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "    figlist[0].canvas.draw()\n",
    "    figlist[0].set_size_inches(10., 10., forward = True)\n",
    "    figname = 'PIPS_station_{}.png'.format(sweeptime.strftime('%Y%m%d%H%M%S'))\n",
    "    figpath = os.path.join(plotdir, figname)\n",
    "    plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:00:29.422204Z",
     "start_time": "2019-09-07T16:00:29.348430Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Now do the same for the model output\n",
    "# First set up some stuff\n",
    "\n",
    "def get_ARPS_member_dir_and_prefix(member, cycle):\n",
    "    \"\"\"\n",
    "    Gets the proper form for the subdirectory and file prefix name given a member number\n",
    "    and cycle type (either 'posterior' or 'prior'). member number 0 is interpreted as the mean. \n",
    "    \"\"\"\n",
    "    if member == 0:\n",
    "        if cycle in 'posterior':\n",
    "            member_dir = 'ENamean'\n",
    "            member_prefix = 'enmean'\n",
    "        elif cycle in 'prior':\n",
    "            member_dir = 'ENfmean'\n",
    "            member_prefix = 'efmean'\n",
    "    else:\n",
    "        if cycle in 'posterior':\n",
    "            member_dir = 'EN{:03d}'.format(int(member))\n",
    "            member_prefix = 'ena{:03d}'.format(int(member))\n",
    "        elif cycle in 'prior':\n",
    "            member_dir = 'ENF{:03d}'.format(int(member))\n",
    "            member_prefix = 'enf{:03d}'.format(int(member))\n",
    "    \n",
    "    return member_dir, member_prefix\n",
    "\n",
    "modelname = 'ARPS'\n",
    "microphys = 'ZVD'\n",
    "\n",
    "# From desired start and end times (UTC) get a range of datetimes and corresponding range of times in\n",
    "# seconds since model initial time\n",
    "timestamp_model_init = init_model_dict['timestamp_model_init']  # Start time of model corresponding to 0 s\n",
    "datetime_model_init = datetime.strptime(timestamp_model_init, '%Y%m%d%H%M%S')\n",
    "\n",
    "timestamp_start = init_model_dict['timestamp_model_start']  # Start time of desired time window\n",
    "timestamp_stop = init_model_dict['timestamp_model_stop']  # Stop time of desired time window\n",
    "datetime_start = datetime.strptime(timestamp_start, '%Y%m%d%H%M%S')\n",
    "datetime_stop = datetime.strptime(timestamp_stop, '%Y%m%d%H%M%S')\n",
    "tintv = init_model_dict['model_dt']  # Interval in seconds for model output\n",
    "tintv_mean = init_model_dict['model_dt_mean'] # Interval in seconds for ensemble mean analysis\n",
    "\n",
    "datetime_range = CRMutils.get_datetime_range(datetime_start, datetime_stop, tintv)\n",
    "trange = CRMutils.modeltimes_from_datetimes(datetime_range, datetime_start=datetime_model_init)\n",
    "\n",
    "datetime_range_mean = CRMutils.get_datetime_range(datetime_start, datetime_stop, tintv_mean)\n",
    "trange_mean = CRMutils.modeltimes_from_datetimes(datetime_range_mean, datetime_start=datetime_model_init)\n",
    "\n",
    "#basedir = '/Volumes/scr_fast/Projects/VORTEXSE/simulations/ARPS/2016_IOP3/3DVAR/1km0331163DVARCA00005min180_3km030015min540'\n",
    "fileformat = init_model_dict['fileformat']\n",
    "expname = '1km453x453_newse'\n",
    "basedir = init_model_dict['basedirname']\n",
    "member = 1 # 0 is for ensemble mean\n",
    "cycle = 'posterior'\n",
    "member_dir, member_prefix = get_ARPS_member_dir_and_prefix(member, cycle)\n",
    "member_absdir = os.path.join(basedir, expname, member_dir)\n",
    "trailer = ''\n",
    "nproc_x = 15\n",
    "nproc_y = 6\n",
    "\n",
    "# Tell the arps_read module what the processor numbers are.\n",
    "# Yes, I know this is a bad way to do this through globals. I'll fix it eventually.\n",
    "arps_read.nproc_x = nproc_x\n",
    "arps_read.nproc_y = nproc_y\n",
    "\n",
    "if member == 0:\n",
    "    model_trange_sec = trange_mean\n",
    "    model_datetime_range = datetime_range_mean\n",
    "else:\n",
    "    model_trange_sec = trange\n",
    "    model_datetime_range = datetime_range\n",
    "    \n",
    "model_dict = init_model_dict.copy()\n",
    "\n",
    "model_dict['trange_member'] = trange\n",
    "model_dict['trange_mean'] = trange_mean\n",
    "model_dict['datetime_range_member'] = datetime_range\n",
    "model_dict['datetime_range_mean'] = datetime_range_mean\n",
    "\n",
    "\n",
    "if member == 0:\n",
    "    model_dict['trange'] = trange_mean\n",
    "    model_dict['datetime_range'] = datetime_range_mean\n",
    "else:\n",
    "    model_dict['trange'] = trange\n",
    "    model_dict['datetime_range'] = datetime_range\n",
    "    \n",
    "print(model_datetime_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:01:13.968639Z",
     "start_time": "2019-09-07T16:00:30.132126Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the ARPS grid\n",
    "# Get file path for grdbas file (note that call to read_grid handles the reading of the individual patches)\n",
    "# If the grdbas file doesn't exist, fall back to a history file\n",
    "grdbas_path = arps_read.get_file_path(member_absdir, member_prefix, fileformat, filetype='grdbas')\n",
    "\n",
    "patch_x = 1\n",
    "patch_y = 1\n",
    "grdbas_path_test = arps_read.add_patch_number(grdbas_path, patch_x, patch_y)\n",
    "\n",
    "if not os.path.exists(grdbas_path_test):\n",
    "    print(\"grdbas file doesn't exist, trying a history file!\")\n",
    "    grdbas_path = arps_read.get_file_path(member_absdir, member_prefix, fileformat, time=model_trange_sec[0], \n",
    "                                          filetype='history')\n",
    "    grdbas_path_test = arps_read.add_patch_number(grdbas_path, patch_x, patch_y)\n",
    "\n",
    "    print(grdbas_path_test)\n",
    "    print(os.path.exists(grdbas_path_test))\n",
    "\n",
    "# Read in grid information\n",
    "grid_dict = arps_read.readarpsgrid(grdbas_path)\n",
    "print(grid_dict.keys())\n",
    "\n",
    "# Get map projection information and create a Basemap instance\n",
    "# TODO: convert to use cartopy!\n",
    "\n",
    "ctrlat, ctrlon, trulat1, trulat2, trulon = arps_read.readarpsmap(grdbas_path)\n",
    "\n",
    "dx = grid_dict['dx']\n",
    "dy = grid_dict['dy']\n",
    "nx = grid_dict['nx']\n",
    "ny = grid_dict['ny']\n",
    "\n",
    "mapwidth = nx * dx\n",
    "mapheight = ny * dy\n",
    "\n",
    "bgmap = Basemap(projection='lcc', width=mapwidth, height=mapheight, lat_1=trulat1,\n",
    "                lat_2=trulat2, lat_0=ctrlat, lon_0=ctrlon, resolution='h',\n",
    "                area_thresh=10., suppress_ticks=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:01:14.944831Z",
     "start_time": "2019-09-07T16:01:14.883567Z"
    }
   },
   "outputs": [],
   "source": [
    "# Put the basemap instance into the grid_dict\n",
    "grid_dict['bgmap'] = bgmap\n",
    "\n",
    "# Find coordinates of PIPS stations in the model\n",
    "dis_dict = sim.get_dis_locs_arps_real_grid(dis_dict, grid_dict)\n",
    "\n",
    "\n",
    "coord_array = np.array(dis_dict['dmodcrdlist'])\n",
    "\n",
    "print(coord_array) \n",
    "print(coord_array.shape) \n",
    "print(coord_array[0]) \n",
    "# coord_array = coord_array.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T16:09:09.667017Z",
     "start_time": "2019-09-07T16:01:15.891884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the PIPS station models on the ARPS model grid, similar to what was done with the radar sweep files\n",
    "dilist = [i[0] for i in dis_dict['dmodcrdlist']]\n",
    "djlist = [i[1] for i in dis_dict['dmodcrdlist']]\n",
    "\n",
    "print(dilist)\n",
    "print(djlist)\n",
    "\n",
    "dxlist = [i[0] for i in dis_dict['dmodloclist']]\n",
    "dylist = [i[1] for i in dis_dict['dmodloclist']]\n",
    "\n",
    "print(dxlist)\n",
    "print(dylist)\n",
    "\n",
    "xc = grid_dict['xs']\n",
    "yc = grid_dict['ys']\n",
    "xe = grid_dict['x']\n",
    "ye = grid_dict['y']\n",
    "\n",
    "xckm = xc / 1000.\n",
    "yckm = yc / 1000.\n",
    "xekm = xe / 1000.\n",
    "yekm = ye / 1000.\n",
    "\n",
    "# Set plotting limits to center on the disdrometer locations \n",
    "\n",
    "Dxmin = min(dxlist)\n",
    "Dxmax = max(dxlist)\n",
    "Dymin = min(dylist)\n",
    "Dymax = max(dylist)\n",
    "plotlims = [Dxmin - 25000., Dxmax + 25000., Dymin - 25000., Dymax + 25000.]\n",
    "\n",
    "ibgn = np.searchsorted(xc, plotlims[0])\n",
    "iend = np.searchsorted(xc, plotlims[1]) + 1\n",
    "jbgn = np.searchsorted(yc, plotlims[2])\n",
    "jend = np.searchsorted(yc, plotlims[3]) + 1\n",
    "\n",
    "print(plotlims)\n",
    "print(ibgn, iend, jbgn, jend)\n",
    "\n",
    "plotvar_dict = {\n",
    "    'xcplt': xckm,\n",
    "    'ycplt': yckm,\n",
    "    'xeplt': xekm,\n",
    "    'yeplt': yekm,\n",
    "}\n",
    "\n",
    "plotparam_dict = {\n",
    "    'cmap': pyPIPSradar.cmapdBZ,\n",
    "    'fieldlevels': np.arange(5.0, 85.0, 5.0),\n",
    "    'clvls': matplotlib.ticker.MultipleLocator(base=5.0),\n",
    "    'clabel': r'dBZ',\n",
    "    'cformat': None,\n",
    "}\n",
    "\n",
    "plotparam_dict['norm'] = matplotlib.colors.BoundaryNorm(plotparam_dict['fieldlevels'], \n",
    "                                                        plotparam_dict['cmap'].N)\n",
    "\n",
    "axesparam_dict = {\n",
    "    'axis_ticks': (10000., 10000.),\n",
    "    'axis_names': ('x', 'y')\n",
    "}\n",
    "\n",
    "plotlim_dict = {\n",
    "    'x': (plotlims[0], plotlims[1]),\n",
    "    'y': (plotlims[2], plotlims[3])\n",
    "}\n",
    "\n",
    "plotvar_name = 'dBZmod'\n",
    "\n",
    "\n",
    "dis_dict_at_model = sim.read_convdata_at_modeltimes(init_dis_dict, model_dict)\n",
    "\n",
    "# Extract stuff from disdrometer dictionary\n",
    "templist = dis_dict_at_model['convdata_at_modeltimes']['temp']\n",
    "dewpointlist = dis_dict_at_model['convdata_at_modeltimes']['dewpoint']\n",
    "pressurelist = dis_dict_at_model['convdata_at_modeltimes']['pressure']\n",
    "windspdavgveclist = dis_dict_at_model['convdata_at_modeltimes']['windspdavgvec']\n",
    "winddiravgveclist = dis_dict_at_model['convdata_at_modeltimes']['winddiravgvec']\n",
    "\n",
    "print(templist)\n",
    "\n",
    "for i, time in enumerate(model_trange_sec):\n",
    "    print(\"Loading time \", time) \n",
    "    filepath = arps_read.get_file_path(member_absdir, member_prefix, fileformat, time=time, filetype='history')\n",
    "    print(filepath)\n",
    "    \n",
    "    var_read_dict = {}\n",
    "    var_read_dict = pycaps_fields.get_fields(var_read_dict, field_names=[plotvar_name], path_grdbas=grdbas_path, \n",
    "                                             path_hdf=filepath, ibgn=ibgn, jbgn=jbgn, iend=iend, jend=jend, \n",
    "                                             klvls=[2], multipatch=True, grid_dict=grid_dict, \n",
    "                                             ignore_existing_vars=True)\n",
    "    \n",
    "    plotvar_dict = plotmod.init_plotvar_dict(plotvar_name, var_read_dict[plotvar_name], 0, 1, grid_dict)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    fig, ax = plotmod.plot2D(fig, ax, 'pcolor', plotvar_dict, plotparam_dict)\n",
    "    \n",
    "    plotmod.set_plot_axes(ax, plotlim_dict, axesparam_dict)\n",
    "\n",
    "    for j, Dx, Dy in zip(range(len(dxlist)), dxlist, dylist):\n",
    "        stationplot = StationPlot(ax, [Dx], [Dy])\n",
    "        stationplot.plot_parameter('NW', [templist[j][i]], color='red')\n",
    "        stationplot.plot_parameter('SW', [dewpointlist[j][i]], color='darkgreen')\n",
    "        stationplot.plot_parameter('NE', [pressurelist[j][i]], formatter=lambda v: format(10 * v, '.0f')[-3:])\n",
    "        u, v = get_wind_components([windspdavgveclist[j][i]] * units('m/s'), [winddiravgveclist[j][i]] * units.degree)\n",
    "        stationplot.plot_barb(u, v, barb_increments=dict(half=0.5, full=1.0, flag=5.0))\n",
    "    \n",
    "    figname = 'PIPS_station_model_{}.png'.format(model_datetime_range[i].strftime('%Y%m%d%H%M%S'))\n",
    "    figpath = os.path.join(plotdir, figname)\n",
    "    plt.savefig(figpath, dpi=300, bbox_inches='tight') \n",
    "    \n",
    "# figlist, gridlist = pyPIPSradar.plotsweep_pyART(radlims, plotlims, outfieldnames, radarsweeplist[i], ovrmap, \n",
    "#                                                     ovrdis, dis_name_list, dxy_list, fields_D_list)\n",
    "#     ax = gridlist[0][0]\n",
    "    \n",
    "#     for j, Dx, Dy in zip(range(len(dxlist)), dxlist, dylist):\n",
    "#         stationplot = StationPlot(ax, [Dx], [Dy])\n",
    "#         stationplot.plot_parameter('NW', [templist[j][i]], color='red')\n",
    "#         stationplot.plot_parameter('SW', [dewpointlist[j][i]], color='darkgreen')\n",
    "#         stationplot.plot_parameter('NE', [pressurelist[j][i]], formatter=lambda v: format(10 * v, '.0f')[-3:])\n",
    "#         u, v = get_wind_components([windspdavgveclist[j][i]] * units('m/s'), [winddiravgveclist[j][i]] * units.degree)\n",
    "#         stationplot.plot_barb(u, v, barb_increments=dict(half=0.5, full=1.0, flag=5.0))\n",
    "\n",
    "#     figlist[0].canvas.draw()\n",
    "#     figlist[0].set_size_inches(10., 10., forward = True)\n",
    "#     figname = 'PIPS_station_{}.png'.format(sweeptime.strftime('%Y%m%d%H%M%S'))\n",
    "#     figpath = os.path.join(plotdir, figname)\n",
    "#     plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T19:39:35.281634Z",
     "start_time": "2019-09-07T19:39:31.529254Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyPIPS.io as pips_io\n",
    "# Read in PIPS data\n",
    "\n",
    "print(dis_dict.keys())\n",
    "\n",
    "dis_dir = dis_dict['dis_dir']\n",
    "dis_filenames = dis_dict['disfilenames']\n",
    "dis_names = dis_dict['dis_names']\n",
    "\n",
    "conv_df_dict = {}\n",
    "parsivel_df_dict = {}\n",
    "vd_matrix_da_dict = {}\n",
    "\n",
    "for dis_filename, dis_name in zip(dis_filenames, dis_names):\n",
    "    dis_filepath = os.path.join(dis_dir, dis_filename)\n",
    "    print(\"Reading {}\".format(dis_filepath))\n",
    "    conv_df, parsivel_df, vd_matrix_da = pips_io.read_PIPS(dis_filepath, starttimestamp=timestamp_start,\n",
    "                                                           stoptimestamp=timestamp_stop)\n",
    "    # Calculate some additional thermodynamic quantities and add to the conventional data DataFrame\n",
    "    conv_df = pips.calc_thermo(conv_df)\n",
    "    conv_df_dict[dis_name] = conv_df\n",
    "    parsivel_df_dict[dis_name] = parsivel_df\n",
    "    vd_matrix_da_dict[dis_name] = vd_matrix_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T19:55:49.169666Z",
     "start_time": "2019-09-07T19:55:48.828399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resample PIPS data to a 60-s interval\n",
    "conv_rs_df_dict = {}\n",
    "parsivel_rs_df_dict = {}\n",
    "vd_matrix_rs_da_dict = {}\n",
    "for dis_name in dis_names:\n",
    "    # Conventional data\n",
    "    conv_df = conv_df_dict[dis_name]\n",
    "    datetime_range_onesec = conv_df.index.to_pydatetime()\n",
    "    sec_offset = pips.get_offset_seconds(datetime_range_onesec)\n",
    "    conv_rs_df_dict[dis_name] = pips.resample_conv('PIPS', 60., sec_offset, conv_df)\n",
    "    \n",
    "    # Parsivel 10-s derived fields\n",
    "    parsivel_df = parsivel_df_dict[dis_name]\n",
    "    datetime_range_tensec = parsivel_df.index.to_pydatetime()\n",
    "    sec_offset = pips.get_offset_seconds(datetime_range_tensec)\n",
    "    print(sec_offset)\n",
    "    parsivel_rs_df_dict[dis_name] = pips.resample_parsivel(60., parsivel_df)\n",
    "    \n",
    "    # Parsivel V-D matrix\n",
    "    vd_matrix_da = vd_matrix_da_dict[dis_name]\n",
    "    vd_matrix_rs_da_dict[dis_name] = pips.resample_vd_matrix(60., vd_matrix_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T19:39:56.304555Z",
     "start_time": "2019-09-07T19:39:55.264051Z"
    }
   },
   "outputs": [],
   "source": [
    "dateformat = '%H:%M' \n",
    "formatter = dates.DateFormatter(dateformat)\n",
    "locator = dates.MinuteLocator(byminute=[0, 15, 30, 45])\n",
    "minorlocator = None\n",
    "timelabel = 'Time (HH:MM)'\n",
    "xaxislimits = [dates.date2num(datetime_range[0]), dates.date2num(datetime_range[-1])]\n",
    "meteo_T_Td_range = [10., 25.]\n",
    "\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    conv_rs_df = conv_rs_df_dict[dis_name]\n",
    "    datetimes_PIPS_conv = conv_rs_df.index.to_pydatetime()\n",
    "    plottimes = dates.date2num(datetimes_PIPS_conv)\n",
    "    T_PIPS = conv_rs_df['fasttemp']\n",
    "    Td_PIPS = conv_rs_df['dewpoint']\n",
    "   \n",
    "    fig, ax = plt.subplots()\n",
    "    fields = [T_PIPS, Td_PIPS]\n",
    "    fieldparamdicts = [PIPSplot.temp_params, PIPSplot.dewpoint_params]\n",
    "    ax = PIPSplot.plotmeteogram(ax, [plottimes], fields, fieldparamdicts)\n",
    "    axparamdict1 = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "                    'minorxlocator': minorlocator, 'axeslimits': [xaxislimits, meteo_T_Td_range],\n",
    "                    'axeslabels': [timelabel, r'Temperature ($^{\\circ}$C)']}\n",
    "    axparamdicts = [axparamdict1]\n",
    "    ax, = PIPSplot.set_meteogram_axes([ax], axparamdicts)\n",
    "    #ax.plot(trange, T_model[:, i], color = 'r')\n",
    "    #ax.set_xlim(tstart, tstop)\n",
    "    #ax.set_ylim(15.0, 30.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-07T19:07:20.612857Z",
     "start_time": "2019-09-07T19:02:15.123211Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in needed fields from the ARPS history dumps\n",
    "# Just for one member now. Later will parallelize this and put it in a script.\n",
    "# and interpolate them to the PIPS locations, building up a time series.\n",
    "print(ibgn, iend, jbgn, jend)\n",
    "print(model_dict.keys())\n",
    "\n",
    "vardict_list = []\n",
    "\n",
    "varnames = ['p', 'pt', 'qv', 'u', 'v', 'qr', 'nr', 'zr']\n",
    "\n",
    "for time in model_dict['trange']:\n",
    "    print(\"Loading time \", time) \n",
    "    filepath = arps_read.get_file_path(member_absdir, member_prefix, fileformat, time=time, filetype='history')\n",
    "    vardict = arps_read.read_hdfvars(filepath, varnames, ibgn=ibgn, jbgn=jbgn, iend=iend, jend=jend,\n",
    "                                     klvls=[1])\n",
    "    vardict_list.append(vardict)\n",
    "\n",
    "#     #\n",
    "    \n",
    "#     p = vardict['p']\n",
    "#     pt = vardict['pt']\n",
    "#     qv = vardict['qv']\n",
    "    \n",
    "#     p_atPIPS = ndimage.map_coordinates(p[..., 1], coord_array, order=1)\n",
    "#     pt_atPIPS = ndimage.map_coordinates(pt[..., 1], coord_array, order=1)\n",
    "#     qv_atPIPS = ndimage.map_coordinates(qv[..., 1], coord_array, order=1)\n",
    "    \n",
    "# #     print p_atPIPS\n",
    "# #     print pt_atPIPS\n",
    "# #     print qv_atPIPS\n",
    "    \n",
    "#     T_atPIPS = thermo.calT(p_atPIPS, pt_atPIPS)-273.15\n",
    "#     Td_atPIPS = thermo.calTd(p_atPIPS, qv_atPIPS)-273.15\n",
    "#     pte_atPIPS = thermo.calpte(p_atPIPS, pt_atPIPS, qv_atPIPS)\n",
    "    \n",
    "#     #print T_atPIPS\n",
    "    \n",
    "#     T_model.append(T_atPIPS)\n",
    "#     Td_model.append(Td_atPIPS)\n",
    "#     pte_model.append(pte_atPIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T22:42:44.062142Z",
     "start_time": "2019-09-08T22:42:42.256642Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create an xarray Dataset out of the dictionary of variables read in from the model over the time range\n",
    "import pyPIPS.parsivel_params as pp\n",
    "import xarray as xr\n",
    "\n",
    "xc_patch = xc[ibgn:iend+1]\n",
    "yc_patch = yc[jbgn:jend+1]\n",
    "coord_dict = {'time': model_dict['datetime_range'],\n",
    "              'yc': ('yc', yc_patch),\n",
    "              'xc': ('xc', xc_patch)}\n",
    "# First, create a dict of lists out of the above list of dicts\n",
    "vardict_combined = CRMutils.make_dict_of_lists(vardict_list)\n",
    "# Set things up for creating the xr Dataset\n",
    "for varname, var in vardict_combined.items():\n",
    "    var_arr = np.array(var).T.squeeze()\n",
    "    var_arr = np.rollaxis(var_arr, 2, 0)\n",
    "    # Trim variables down to just the patch we want to work with\n",
    "    var_arr_patch = var_arr[:, jbgn:jend+1, ibgn:iend+1]\n",
    "    vardict_combined[varname] = (['time', 'yc', 'xc'], var_arr_patch)\n",
    "    \n",
    "# Create an xarray Dataset out of the variable dictionary\n",
    "var_ds = xr.Dataset(vardict_combined, coords=coord_dict)\n",
    "\n",
    "# Compute raw model DSD paramters and add them to the model Dataset\n",
    "rhor = 1000.\n",
    "cr = np.pi / 6. * rhor\n",
    "var_ds['rho'] = thermo.calrho(var_ds['p'], var_ds['pt'], var_ds['qv'])\n",
    "\n",
    "# Shape parameter\n",
    "var_ds['alphar'] = dsd.solve_alpha(var_ds['rho'], cr, var_ds['qr'], var_ds['nr'], var_ds['zr'])\n",
    "# var_ds['alphar'] = var_ds['alphar'].interpolate_na()\n",
    "# Intercept parameter\n",
    "var_ds['N0r'] = dsd.calc_N0_gamma(var_ds['rho'], var_ds['qr'], var_ds['nr'], cr, var_ds['alphar'])\n",
    "# Slope parameter\n",
    "var_ds['lamdar'] = dsd.calc_lamda_gamma(var_ds['rho'], var_ds['qr'], var_ds['nr'], cr, var_ds['alphar'])\n",
    "\n",
    "# Try computing ND and logND here\n",
    "\n",
    "mid_diameters_da = vd_matrix_da_dict['PIPS1A']['diameter']\n",
    "# Broadcast DSD parameter DataArrays to get everyone on the same dimensional page\n",
    "mid_diameters_da, N0r_model_da, lamdar_model_da, alphar_model_da = \\\n",
    "    xr.broadcast(mid_diameters_da, var_ds['N0r'], var_ds['lamdar'] , var_ds['alphar'])\n",
    "\n",
    "# Transpose these DataArrays to get time as the first dimension\n",
    "mid_diameters_da = mid_diameters_da.transpose('time', 'diameter_bin', 'yc', 'xc')\n",
    "N0r_model_da = N0r_model_da.transpose('time', 'diameter_bin', 'yc', 'xc')\n",
    "lamdar_model_da = lamdar_model_da.transpose('time', 'diameter_bin', 'yc', 'xc')\n",
    "alphar_model_da = alphar_model_da.transpose('time', 'diameter_bin', 'yc', 'xc')\n",
    "\n",
    "ND_model = dsd.calc_binned_DSD_from_params(N0r_model_da, lamdar_model_da, alphar_model_da, mid_diameters_da)\n",
    "ND_model = ND_model.fillna(0.0)\n",
    "logND_model = np.log10(ND_model)\n",
    "logND_model = logND_model.where(logND_model > -np.inf)\n",
    "#logND_model = logND_model.fillna(0.0)\n",
    "#logND_model = logND_model.where(logND_model > -1.0)\n",
    "\n",
    "var_ds['ND'] = ND_model\n",
    "var_ds['logND'] = logND_model\n",
    "\n",
    "var_ds\n",
    "\n",
    "# ND_model_raw_PIPS_modeltimes_dict = {}\n",
    "# logND_model_raw_PIPS_modeltimes_dict = {}\n",
    "# for i, dis_name in enumerate(dis_names):\n",
    "#     mid_diameters_da = vd_matrix_da_dict[dis_name]['diameter']\n",
    "#     alphar_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['alphar']\n",
    "#     N0r_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['N0r']\n",
    "#     lamdar_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['lamdar']\n",
    "#     print(alphar_model_PIPS_da)\n",
    "#     # Broadcast DSD parameter DataArrays to get everyone on the same dimensional page\n",
    "#     mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da = \\\n",
    "#         xr.broadcast(mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da)\n",
    "#     # Transpose these DataArrays to get time as the first dimension\n",
    "#     mid_diameters_da = mid_diameters_da.T\n",
    "#     N0r_model_PIPS_da = N0r_model_PIPS_da.T\n",
    "#     lamdar_model_PIPS_da = lamdar_model_PIPS_da.T\n",
    "#     alphar_model_PIPS_da = alphar_model_PIPS_da.T\n",
    "    \n",
    "#     ND_model_raw_PIPS = dsd.calc_binned_DSD_from_params(N0r_model_PIPS_da, lamdar_model_PIPS_da, \n",
    "#                                                         alphar_model_PIPS_da, mid_diameters_da)\n",
    "#     logND_model_raw_PIPS = np.log10(ND_model_raw_PIPS)\n",
    "#     logND_model_raw_PIPS = logND_model_raw_PIPS.where(logND_model_raw_PIPS > -1.0)\n",
    "    \n",
    "#     ND_model_raw_PIPS_modeltimes_dict[dis_name] = ND_model_raw_PIPS\n",
    "#     logND_model_raw_PIPS_modeltimes_dict[dis_name] = logND_model_raw_PIPS\n",
    "\n",
    "\n",
    "# var_ds\n",
    "# 3D below\n",
    "# zc = grid_dict['zs']\n",
    "# zc = zc.T\n",
    "# xc_patch = xc[ibgn:iend+1]\n",
    "# yc_patch = yc[jbgn:jend+1]\n",
    "# zc_patch = zc[:, jbgn:jend+1, ibgn:iend+1]\n",
    "# # First, create a dict of lists out of the above list of dicts\n",
    "# vardict_combined = CRMutils.make_dict_of_lists(vardict_list)\n",
    "# # Set things up for creating the xr Dataset\n",
    "# for varname, var in vardict_combined.items():\n",
    "#     var_arr = np.rollaxis(np.array(var).T, 3, 0)\n",
    "#     # Trim variables down to just the patch we want to work with\n",
    "#     var_arr_patch = var_arr[:, :, jbgn:jend+1, ibgn:iend+1]\n",
    "#     vardict_combined[varname] = (['time', 'z', 'yc', 'xc'], var_arr_patch)\n",
    "\n",
    "# coord_dict = {'time': model_dict['datetime_range'],\n",
    "#               'zc': (['z', 'yc', 'xc'], zc_patch),\n",
    "#               'yc': ('yc', yc_patch),\n",
    "#               'xc': ('xc', xc_patch)}\n",
    "# # Create an xarray Dataset out of the variable dictionary\n",
    "# var_ds = xr.Dataset(vardict_combined, coords=coord_dict)\n",
    "# var_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T22:42:59.399861Z",
     "start_time": "2019-09-08T22:42:58.905137Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save Dataset to nc file\n",
    "savedir = '/Users/dawson29/Dropbox/Projects/VORTEXSE/vortexse_enkf_dsd_study/nc'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "filename = \"{}_fields.nc\".format(member_prefix)\n",
    "filepath = os.path.join(savedir, filename)\n",
    "var_ds.to_netcdf(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T21:15:55.759594Z",
     "start_time": "2019-09-08T21:15:55.701993Z"
    }
   },
   "outputs": [],
   "source": [
    "print(dis_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T22:43:34.858724Z",
     "start_time": "2019-09-08T22:43:14.491447Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_coords = [a[0] for a in dis_dict['dmodloclist']]\n",
    "y_coords = [a[1] for a in dis_dict['dmodloclist']]\n",
    "\n",
    "x_coords_da = xr.DataArray(x_coords, coords=[dis_names], dims=['PIPS'])\n",
    "y_coords_da = xr.DataArray(y_coords, coords=[dis_names], dims=['PIPS'])\n",
    "\n",
    "var_ds_interp = var_ds.interpolate_na(dim='time')\n",
    "var_ds_interp = var_ds_interp.interp(xc=x_coords_da, yc=y_coords_da)\n",
    "\n",
    "print(var_ds_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T22:37:51.017892Z",
     "start_time": "2019-09-08T22:37:49.888821Z"
    }
   },
   "outputs": [],
   "source": [
    "p_interp = var_ds_interp['p']\n",
    "pt_interp = var_ds_interp['pt']\n",
    "qv_interp = var_ds_interp['qv']\n",
    "\n",
    "T_model_PIPS = thermo.calT(p_interp, pt_interp) - 273.15\n",
    "Td_model_PIPS = thermo.calTd(p_interp, qv_interp) - 273.15\n",
    "\n",
    "\n",
    "dateformat = '%H:%M' \n",
    "formatter = dates.DateFormatter(dateformat)\n",
    "locator = dates.MinuteLocator(byminute=[0,15,30,45])\n",
    "minorlocator = None\n",
    "timelabel = 'Time (HH:MM)'\n",
    "plottimes = dates.date2num(datetime_range)\n",
    "xaxislimits = [plottimes[0], plottimes[-1]]\n",
    "meteo_T_Td_range = [10., 25.]\n",
    "\n",
    "for i, PIPSname in enumerate(dis_dict['dis_names']):\n",
    "    #print i\n",
    "    fig, ax = plt.subplots()\n",
    "    T_model_PIPS_plt = T_model_PIPS.sel(PIPS=PIPSname)\n",
    "    Td_model_PIPS_plt = Td_model_PIPS.sel(PIPS=PIPSname)\n",
    "    fields = [T_model_PIPS_plt, Td_model_PIPS_plt]\n",
    "    fieldparamdicts = [PIPSplot.temp_params, PIPSplot.dewpoint_params]\n",
    "    ax = PIPSplot.plotmeteogram(ax, [plottimes], fields, fieldparamdicts)\n",
    "    axparamdict1 = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "                    'minorxlocator': minorlocator, 'axeslimits': [xaxislimits, meteo_T_Td_range],\n",
    "                    'axeslabels': [timelabel, r'Temperature ($^{\\circ}$C)']}\n",
    "    axparamdicts = [axparamdict1]\n",
    "    ax, = PIPSplot.set_meteogram_axes([ax], axparamdicts)\n",
    "    #ax.plot(trange, T_model[:, i], color = 'r')\n",
    "    #ax.set_xlim(tstart, tstop)\n",
    "    #ax.set_ylim(15.0, 30.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T22:56:23.076388Z",
     "start_time": "2019-09-08T22:56:22.980123Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save for posterity. The DSD parameters are now computed on the model grid first, and then interpolated to\n",
    "# the PIPS points\n",
    "\n",
    "# Compute raw model DSD at PIPS locations\n",
    "rhor = 1000.\n",
    "cr = np.pi / 6. * rhor\n",
    "\n",
    "qr_model_PIPS = var_ds_interp['qr']\n",
    "nr_model_PIPS = var_ds_interp['nr']\n",
    "zr_model_PIPS = var_ds_interp['zr']\n",
    "rho_model_PIPS = thermo.calrho(p_interp, pt_interp, qv_interp)\n",
    "\n",
    "print(qr_model_PIPS)\n",
    "print(rho_model_PIPS)\n",
    "\n",
    "# Shape parameter\n",
    "# alphar_atPIPS = dualpol.solve_alpha_iter(rhoa_atPIPS, mu, qr_atPIPS, nr_atPIPS, zr_atPIPS, rhor)\n",
    "alphar_model_PIPS = dsd.solve_alpha(rho_model_PIPS, cr, qr_model_PIPS, nr_model_PIPS, zr_model_PIPS)\n",
    "# Intercept parameter\n",
    "N0r_model_PIPS = dsd.calc_N0_gamma(rho_model_PIPS, qr_model_PIPS, nr_model_PIPS, cr, alphar_model_PIPS)\n",
    "# Slope parameter\n",
    "lamdar_model_PIPS = dsd.calc_lamda_gamma(rho_model_PIPS, qr_model_PIPS, nr_model_PIPS, cr, alphar_model_PIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:01:46.126897Z",
     "start_time": "2019-09-08T23:01:46.049672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save for posterity, now part of var_ds dataset above\n",
    "\n",
    "# Temp fix until I get the above functions to work properly with xarray\n",
    "# convert alphar, N0r, lamdar back to DataArrays\n",
    "\n",
    "alphar_model_allPIPS_da = xr.DataArray(alphar_model_PIPS,\n",
    "                                    coords={\n",
    "                                        'time': qr_model_PIPS['time'],\n",
    "                                        'PIPS': ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B']\n",
    "                                    },\n",
    "                                    dims=['time', 'PIPS'])\n",
    "N0r_model_allPIPS_da = xr.DataArray(N0r_model_PIPS,\n",
    "                                    coords={\n",
    "                                        'time': qr_model_PIPS['time'],\n",
    "                                        'PIPS': ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B']\n",
    "                                    },\n",
    "                                    dims=['time', 'PIPS'])\n",
    "lamdar_model_allPIPS_da = xr.DataArray(lamdar_model_PIPS,\n",
    "                                    coords={\n",
    "                                        'time': qr_model_PIPS['time'],\n",
    "                                        'PIPS': ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B']\n",
    "                                    },\n",
    "                                    dims=['time', 'PIPS'])\n",
    "\n",
    "print(alphar_model_allPIPS_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:49:31.328293Z",
     "start_time": "2019-09-08T23:49:31.064385Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: maybe it's better to try to do this the other direction: namely interpolate the ND values at the PIPS\n",
    "# times, which are different for each PIPS, to the common model times.\n",
    "\n",
    "# Now, interpolate these values at the model times to the PIPS DSD times, one PIPS at a time.\n",
    "# Also get the PSD time bin edges and centers as a numpy array of python datetime objects\n",
    "model_vars_PIPS_dict = {}\n",
    "model_gamma_DSD_params_PIPS_modeltimes_dict = {}\n",
    "model_gamma_DSD_PIPS_modeltimes_dict = {}\n",
    "model_gamma_DSD_params_PIPS_dict = {}\n",
    "model_gamma_DSD_PIPS_dict = {}\n",
    "PSD_datetimes_rs_PIPS_dict = {}\n",
    "\n",
    "# Get PSD times valid at the model times\n",
    "PSD_datetimes_model = pips.get_PSD_datetimes(var_ds, dim_name='time')\n",
    "PSD_datetimes_model_dict = pips.get_PSD_time_bins(PSD_datetimes_model)\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    \n",
    "    # Get the DataArrays for individual PIPS\n",
    "    \n",
    "    # Velocity-diameter matrix\n",
    "    vd_matrix_rs_da = vd_matrix_rs_da_dict[dis_name]\n",
    "    \n",
    "    # Get times for PIPS transects as numpy arrays of python datetime objects\n",
    "    PSD_datetimes_rs = pips.get_PSD_datetimes(vd_matrix_rs_da)\n",
    "    PSD_datetimes_rs_dict = pips.get_PSD_time_bins(PSD_datetimes_rs)\n",
    "    PSD_datetimes_rs_PIPS_dict[dis_name] = PSD_datetimes_rs_dict\n",
    "    \n",
    "    # Rename \"time_10s\" to \"time\" so that we have the same dimension name as the model\n",
    "    vd_matrix_rs_da = vd_matrix_rs_da.rename({'time_10s': 'time'})\n",
    "    \n",
    "    # Shape, intercept, and slope parameters for model DSD, already interpolated in space to each\n",
    "    # PIPS location\n",
    "    # New way\n",
    "    \n",
    "#     alphar_model_PIPS_da = var_ds_interp['alphar'].loc[dict(PIPS=dis_name)]\n",
    "#     N0r_model_PIPS_da = var_ds_interp['N0r'].loc[dict(PIPS=dis_name)]\n",
    "#     lamdar_model_PIPS_da = var_ds_interp['lamdar'].loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    # Do the same for ND and logND\n",
    "    ND_model_PIPS_da = var_ds_interp['ND'].loc[dict(PIPS=dis_name)]\n",
    "    logND_model_PIPS_da = var_ds_interp['logND'].loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    # Old way\n",
    "    alphar_model_PIPS_da = alphar_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    N0r_model_PIPS_da = N0r_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    lamdar_model_PIPS_da = lamdar_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    \n",
    "    # Get the values of some needed variables from the model dataset, already interpolated in space to each\n",
    "    # PIPS location\n",
    "    \n",
    "    # We just need rho and nr\n",
    "    rho_model_pips_da = var_ds_interp['rho'].loc[dict(PIPS=dis_name)]\n",
    "    nr_model_pips_da = var_ds_interp['nr'].loc[dict(PIPS=dis_name)]\n",
    "    \n",
    "    # Now interpolate the DSD parameters in time to the PIPS times, which are different for each PIPS\n",
    "    alphar_model_PIPS_da_interp = alphar_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    N0r_model_PIPS_da_interp = N0r_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    lamdar_model_PIPS_da_interp = lamdar_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    \n",
    "    # Do the same for ND and logND\n",
    "    ND_model_PIPS_da_interp = ND_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    logND_model_PIPS_da_interp = logND_model_PIPS_da.interp_like(vd_matrix_rs_da)\n",
    "    \n",
    "    # Do the same for rho and nr\n",
    "    rho_model_pips_da_interp = rho_model_pips_da.interp_like(vd_matrix_rs_da)\n",
    "    nr_model_pips_da_interp = nr_model_pips_da.interp_like(vd_matrix_rs_da)\n",
    "    \n",
    "    # Stuff them into a dict of dicts (gahhh!)\n",
    "    model_gamma_DSD_params_modeltimes_dict = {'alphar': alphar_model_PIPS_da,\n",
    "                                              'N0r': N0r_model_PIPS_da,\n",
    "                                              'lamdar': lamdar_model_PIPS_da}\n",
    "    model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name] = model_gamma_DSD_params_modeltimes_dict\n",
    "    model_gamma_DSD_params_dict = {'alphar': alphar_model_PIPS_da_interp,\n",
    "                                   'N0r': N0r_model_PIPS_da_interp,\n",
    "                                   'lamdar': lamdar_model_PIPS_da_interp}\n",
    "    model_gamma_DSD_params_PIPS_dict[dis_name] = model_gamma_DSD_params_dict\n",
    "    \n",
    "    model_gamma_DSD_modeltimes_dict = {'ND': ND_model_PIPS_da, \n",
    "                                       'logND': logND_model_PIPS_da}\n",
    "    model_gamma_DSD_PIPS_modeltimes_dict[dis_name] = model_gamma_DSD_modeltimes_dict\n",
    "    \n",
    "    model_gamma_DSD_dict = {'ND': ND_model_PIPS_da_interp,\n",
    "                            'logND': logND_model_PIPS_da_interp}\n",
    "    model_gamma_DSD_PIPS_dict[dis_name] = model_gamma_DSD_dict\n",
    "    \n",
    "    model_vars_PIPS_dict[dis_name] = {'rho': rho_model_pips_da_interp, 'nr': nr_model_pips_da_interp}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T00:12:08.585016Z",
     "start_time": "2019-09-09T00:12:08.091338Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyPIPS.parsivel_qc as pqc\n",
    "# Compute N(D) for the observed PIPS DSDs after some QC\n",
    "min_diameters = pp.parsivel_parameters['min_diameter_bins_mm']\n",
    "mid_diameters = pp.parsivel_parameters['avg_diameter_bins_mm']\n",
    "max_diameters = pp.parsivel_parameters['max_diameter_bins_mm']\n",
    "mid_fallspeeds = pp.parsivel_parameters['avg_fallspeed_bins_mps']\n",
    "empirical_fallspeed = pips.calc_empirical_fallspeed(mid_diameters)\n",
    "fallspeed_spectrum = pips.calc_fallspeed_spectrum(mid_diameters, mid_fallspeeds, use_measured_fallspeed=True)\n",
    "\n",
    "ND_PIPS_dict = {}\n",
    "logND_PIPS_dict = {}\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    vd_matrix_rs_da = vd_matrix_rs_da_dict[dis_name]\n",
    "    vd_matrix_rs_QC = pqc.strongwindQC(vd_matrix_rs_da)\n",
    "    vd_matrix_rs_QC = pqc.rainonlyQC(vd_matrix_rs_QC)\n",
    "    # Calculate ND and log10(ND)\n",
    "    ND = pips.calc_ND(vd_matrix_rs_QC.where(vd_matrix_rs_QC > 0.0), fallspeed_spectrum, 60.)\n",
    "    logND = np.log10(ND)\n",
    "    logND = logND.where(logND > -1.0)\n",
    "    \n",
    "    ND_PIPS_dict[dis_name] = ND\n",
    "    logND_PIPS_dict[dis_name] = logND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T22:38:38.069201Z",
     "start_time": "2019-09-08T22:38:36.236102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot observed DSDs\n",
    "\n",
    "# Prepare axis parameters\n",
    "# We'll use the model times just for the boundaries of the x-axis\n",
    "timelimits = [datetime_range[0], datetime_range[-1]]\n",
    "diamlimits = [0.0, 9.0]\n",
    "diamytick = 1.0\n",
    "DSDtype = 'observed'\n",
    "locator = dates.MinuteLocator(byminute=[0,15,30,45])\n",
    "minorlocator = dates.MinuteLocator(byminute=range(0,60,5))\n",
    "dateformat = '%H:%M'\n",
    "formatter = dates.DateFormatter(dateformat)\n",
    "\n",
    "axparams = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "            'minorxlocator': minorlocator,\n",
    "            'axeslimits': [timelimits, diamlimits],\n",
    "            'majorylocator': ticker.MultipleLocator(base=diamytick),\n",
    "            'axeslabels': [None, 'D (mm)']}\n",
    "\n",
    "# Ok, now we should have everything ready to go to plot the meteograms.\n",
    "# Let'er rip!\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND = logND_PIPS_dict[dis_name]\n",
    "    PSDstarttimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_edges'])\n",
    "    PSDmidtimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_centers'])\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T}\n",
    "    dis_plot_name = dis_name + '_' + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:02:40.216176Z",
     "start_time": "2019-09-08T23:02:40.106138Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute N(D) from the raw model parameters at original model times\n",
    "import pyPIPS.parsivel_params as pp\n",
    "\n",
    "ND_model_raw_PIPS_modeltimes_dict = {}\n",
    "logND_model_raw_PIPS_modeltimes_dict = {}\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    mid_diameters_da = vd_matrix_da_dict[dis_name]['diameter']\n",
    "    alphar_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['alphar']\n",
    "    N0r_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['N0r']\n",
    "    lamdar_model_PIPS_da = model_gamma_DSD_params_PIPS_modeltimes_dict[dis_name]['lamdar']\n",
    "    print(alphar_model_PIPS_da)\n",
    "    # Broadcast DSD parameter DataArrays to get everyone on the same dimensional page\n",
    "    mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da = \\\n",
    "        xr.broadcast(mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da)\n",
    "    # Transpose these DataArrays to get time as the first dimension\n",
    "    mid_diameters_da = mid_diameters_da.T\n",
    "    N0r_model_PIPS_da = N0r_model_PIPS_da.T\n",
    "    lamdar_model_PIPS_da = lamdar_model_PIPS_da.T\n",
    "    alphar_model_PIPS_da = alphar_model_PIPS_da.T\n",
    "    \n",
    "    ND_model_raw_PIPS = dsd.calc_binned_DSD_from_params(N0r_model_PIPS_da, lamdar_model_PIPS_da, \n",
    "                                                        alphar_model_PIPS_da, mid_diameters_da)\n",
    "    logND_model_raw_PIPS = np.log10(ND_model_raw_PIPS)\n",
    "    logND_model_raw_PIPS = logND_model_raw_PIPS.where(logND_model_raw_PIPS > -1.0)\n",
    "    \n",
    "    ND_model_raw_PIPS_modeltimes_dict[dis_name] = ND_model_raw_PIPS\n",
    "    logND_model_raw_PIPS_modeltimes_dict[dis_name] = logND_model_raw_PIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:02:54.987338Z",
     "start_time": "2019-09-08T23:02:54.888844Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute N(D) from the raw model parameters (interpolated to the PIPS times and locations)\n",
    "import pyPIPS.parsivel_params as pp\n",
    "\n",
    "ND_model_raw_PIPS_dict = {}\n",
    "logND_model_raw_PIPS_dict = {}\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    mid_diameters_da = vd_matrix_da_dict[dis_name]['diameter']\n",
    "    alphar_model_PIPS_da = model_gamma_DSD_params_PIPS_dict[dis_name]['alphar']\n",
    "    N0r_model_PIPS_da = model_gamma_DSD_params_PIPS_dict[dis_name]['N0r']\n",
    "    lamdar_model_PIPS_da = model_gamma_DSD_params_PIPS_dict[dis_name]['lamdar']\n",
    "    # Broadcast DSD parameter DataArrays to get everyone on the same dimensional page\n",
    "    mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da = \\\n",
    "        xr.broadcast(mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da)\n",
    "    # Transpose these DataArrays to get time as the first dimension\n",
    "    mid_diameters_da = mid_diameters_da.T\n",
    "    N0r_model_PIPS_da = N0r_model_PIPS_da.T\n",
    "    lamdar_model_PIPS_da = lamdar_model_PIPS_da.T\n",
    "    alphar_model_PIPS_da = alphar_model_PIPS_da.T\n",
    "    \n",
    "    ND_model_raw_PIPS = dsd.calc_binned_DSD_from_params(N0r_model_PIPS_da, lamdar_model_PIPS_da, \n",
    "                                                        alphar_model_PIPS_da, mid_diameters_da)\n",
    "    logND_model_raw_PIPS = np.log10(ND_model_raw_PIPS)\n",
    "    logND_model_raw_PIPS = logND_model_raw_PIPS.where(logND_model_raw_PIPS > -1.0)\n",
    "    \n",
    "    ND_model_raw_PIPS_dict[dis_name] = ND_model_raw_PIPS\n",
    "    logND_model_raw_PIPS_dict[dis_name] = logND_model_raw_PIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:03:17.262074Z",
     "start_time": "2019-09-08T23:03:15.257690Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now plot the raw model DSDs (interpolated to PIPS locations but not the times)\n",
    "\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND = model_gamma_DSD_PIPS_modeltimes_dict[dis_name]['logND']\n",
    "    logND = logND.where(logND > -1.0)\n",
    "    print(logND)\n",
    "    print(PSDstarttimes)\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T}\n",
    "    dis_plot_name = dis_name + '_raw_model_modeltimes_' + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:04:24.928139Z",
     "start_time": "2019-09-08T23:04:22.881514Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now plot the raw model DSDs (interpolated to PIPS locations but not the times) - version 2 with logND computed\n",
    "# from interpolated alpha, lamda, N0\n",
    "\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND = logND_model_raw_PIPS_modeltimes_dict[dis_name]\n",
    "    logND = logND.where(logND > -1.0)\n",
    "    print(logND)\n",
    "    print(PSDstarttimes)\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T}\n",
    "    dis_plot_name = dis_name + '_raw_model_modeltimes_v2_' + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:04:41.544806Z",
     "start_time": "2019-09-08T23:04:39.727782Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now plot the raw model DSDs (interpolated to PIPS times and locations)\n",
    "\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND = model_gamma_DSD_PIPS_dict[dis_name]['logND']\n",
    "    logND = logND.where(logND > -1.0)\n",
    "    PSDstarttimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_edges'])\n",
    "    PSDmidtimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_centers'])\n",
    "    print(logND)\n",
    "    print(PSDstarttimes)\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T}\n",
    "    dis_plot_name = dis_name + '_raw_model_' + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-08T23:04:57.995119Z",
     "start_time": "2019-09-08T23:04:55.982881Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now plot the raw model DSDs (interpolated to PIPS times and locations) - version 2 with logND computed\n",
    "# from interpolated alpha, lamda, N0\n",
    "\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND = logND_model_raw_PIPS_dict[dis_name]\n",
    "    logND = logND.where(logND > -1.0)\n",
    "    PSDstarttimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_edges'])\n",
    "    PSDmidtimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_centers'])\n",
    "    print(logND)\n",
    "    print(PSDstarttimes)\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T}\n",
    "    dis_plot_name = dis_name + '_raw_model_v2_' + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-09T00:52:30.082061Z",
     "start_time": "2019-09-09T00:52:28.829401Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now compute sampled PSDs from the model\n",
    "\n",
    "# Now plot the sampled model DSD\n",
    "\n",
    "sampling_interval = 60.\n",
    "sampling_length = pp.parsivel_parameters['sensor_length_mm'] / 1000. # To m\n",
    "sampling_width = pp.parsivel_parameters['sensor_width_mm'] / 1000. # To m\n",
    "\n",
    "Dmax = 8.\n",
    "Dmax_index = np.searchsorted(mid_diameters, Dmax, side='right')\n",
    "print(Dmax_index)\n",
    "mid_diameters_trunc = np.array(mid_diameters[:Dmax_index+1]) / 1000.\n",
    "min_diameters_trunc = np.array(min_diameters[:Dmax_index+1]) / 1000.\n",
    "max_diameters_trunc = np.array(max_diameters[:Dmax_index+1]) / 1000.\n",
    "\n",
    "ND_raw = model_gamma_DSD_PIPS_dict['PIPS2B']['ND']\n",
    "print(ND_raw)\n",
    "nr_model = model_vars_PIPS_dict['PIPS2B']['nr'].values\n",
    "lamdar_model = model_gamma_DSD_params_PIPS_dict['PIPS2B']['lamdar'].values\n",
    "alphar_model = model_gamma_DSD_params_PIPS_dict['PIPS2B']['alphar'].values\n",
    "rho_model = model_vars_PIPS_dict['PIPS2B']['rho'].values\n",
    "\n",
    "print(mid_diameters_trunc.shape)\n",
    "Vtr = pips.calc_empirical_fallspeed(mid_diameters_trunc * 1000., correct_rho=True, rho=rho_model)\n",
    "\n",
    "Vtr = Vtr.T\n",
    "print(Vtr[0])\n",
    "print(Vtr.shape)\n",
    "print(mid_diameters_trunc.shape)\n",
    "ND_samp_series = np.zeros((np.size(PSDmidtimes), np.size(mid_diameters_trunc)))\n",
    "\n",
    "print(ND_samp_series.shape)\n",
    "print(nr_model[0])\n",
    "# Nc_bin_tmp2 = np.zeros((np.size(N0r), np.size(D[:Dmax_index+1])))\n",
    "# Nc_bin2 = np.zeros((np.size(np.array(sampling_times)), np.size(D[:Dmax_index+1])))\n",
    "\n",
    "\n",
    "# Special treatment for first sampling time. Just assume DSD valid at that time was constant for the previous \n",
    "# sampling interval\n",
    "sample_dict = sim.create_random_gamma_DSD(nr_model[0], lamdar_model[0], \n",
    "                                          alphar_model[0], Vtr[0], sampling_length, \n",
    "                                          sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                          max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                          remove_margins=True, rhocorrect=True, rho=rho_model[0], verbose=True)\n",
    "\n",
    "\n",
    "ND_sample = sample_dict['ND']\n",
    "pcount_binned_sample = sample_dict['pcount_binned']\n",
    "print(ND_sample.shape)\n",
    "print(ND_samp_series.shape)\n",
    "ND_samp_series[0, :] = 1.e-3*ND_sample\n",
    "# Nc_bin_tmp2[0, :] = 1.e-3*ND_sample\n",
    "# Nc_bin2[0, :] = Nc_bin_tmp2[0, :]\n",
    "\n",
    "pcount_binned_samples = []\n",
    "for index in range(np.size(PSDmidtimes[:-1])):\n",
    "    sample_dict = sim.create_random_gamma_DSD(nr_model[index], lamdar_model[index], \n",
    "                                              alphar_model[index], Vtr[index], sampling_length, \n",
    "                                              sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                              max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                              remove_margins=True, rhocorrect=True, rho=rho_model[index], verbose=True)\n",
    "    ND_sample = sample_dict['ND']\n",
    "    pcount_binned_samples.append(sample_dict['pcount_binned'])\n",
    "    ND_samp_series[index, :] = 1.e-3*ND_sample\n",
    "\n",
    "pcount_binned_samples = np.array(pcount_binned_samples)\n",
    "\n",
    "ND_samp_series = np.ma.masked_invalid(ND_samp_series)\n",
    "\n",
    "# sampling_volumes_D = sim.calc_sampling_volumes_D(Vtr, Dr, Dmax, sampling_interval, sampling_area)\n",
    "# for s, sample_index in enumerate(sample_indices[:-1]):\n",
    "#     sample_index_end = sample_indices[s+1]\n",
    "#     current_sample_indices = slice(sample_index, sample_index_end, None)\n",
    "#     pcount_binned = np.sum(pcount_binned_samples[current_sample_indices], axis=0)\n",
    "#     Nc_bin2[s+1, :] = 1.e-3*sim.calc_ND(pcount_binned, sampling_volumes_D, Dr, Dl, Dmax)\n",
    "# #     Nc_bin2[s+1, :] = np.sum(Nc_bin_tmp2[current_sample_indices, :]*dt[current_sample_indices, None], axis = 0)/sampling_interval\n",
    "# #     print \"s = \", s\n",
    "# #     print \"sample time (beginning) = \", sampling_times[s]\n",
    "# #     print \"sample time (end) = \", sampling_times[s+1]\n",
    "# #     print \"dt[current_sample_indices] = \", dt[current_sample_indices]\n",
    "# #     print \"Nc_bin_tmp = \", Nc_bin_tmp[current_sample_indices, :], dt[current_sample_indices]\n",
    "# #     print \"Nc_bin = \", Nc_bin[s+1, :]\n",
    "\n",
    "ND_samp_series = np.ma.masked_invalid(ND_samp_series)\n",
    "logND_samp_series = np.log10(ND_samp_series)\n",
    "logND_samp_series = np.ma.masked_where(logND_samp_series <= -1.0, logND_samp_series)\n",
    "\n",
    "disvars = {'min_diameter': min_diameters[:Dmax_index+1], 'PSDstarttimes': PSDstarttimes,\n",
    "           'PSDmidtimes': PSDmidtimes, 'logND': logND_samp_series.T}\n",
    "dis_plot_name = dis_name + '_sampled_model_' + DSDtype\n",
    "PIPSplot.plotDSDmeteograms(dis_plot_name, plotdir, axparams, disvars)\n",
    "\n",
    "\n",
    "# ND_samp = np.empty((np.size(N0r_model, axis=0), np.size(D[:Dmax_index+1]), np.size(N0r_model, axis=1)))\n",
    "# for index, _ in np.ndenumerate(nr_model.values):\n",
    "#     print(index, nr_model.values[index, 0])\n",
    "#     positions, diameters, velocities, ND_sample = create_random_gamma_DSD(nr_model[index], lamdar[index], \n",
    "#                                                                           alphar[index], Vtr, sampling_length, \n",
    "#                                                                           sampling_width, Dl, D, Dr, \n",
    "#                                                                           sampling_interval=60.)\n",
    "#     Nc_bin2[index[0],:,index[1]] = 1.e-3*ND_sample\n",
    "\n",
    "# Nc_bin2 = np.ma.masked_invalid(Nc_bin2)\n",
    "# logNc_bin2 = np.log10(Nc_bin2)\n",
    "# logNc_bin2 = np.ma.masked_where(logNc_bin2 <= -1.0,logNc_bin2)\n",
    "\n",
    "# for i, PIPSname in enumerate(ib.dis_name_list):\n",
    "#     fig = plt.figure(figsize=(8, 3))\n",
    "#     ax = fig.add_subplot(111)\n",
    "#     divider = make_axes_locatable(ax)\n",
    "#     C = ax.pcolor(PSDstarttimes,Dl[:Dmax_index+1]*1000.,logNc_bin2[:,:,i].swapaxes(0,1),vmin=-1.0,vmax=3.0)\n",
    "#     #ax.xaxis.set_major_locator(ticker.MultipleLocator(base=5.0))\n",
    "#     #ax.yaxis.set_major_locator(ticker.MultipleLocator(base=1.0))\n",
    "#     #ax.set_xlim(-30.0,30.0)\n",
    "#     axparamdict1 = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "#                     'minorxlocator': minorlocator, 'axeslimits': [None, [0.0, 9.0]],\n",
    "#                     'axeslabels': [timelabel, r'D (mm)']}\n",
    "#     axparamdicts = [axparamdict1]\n",
    "#     ax, = PIPSplot.set_meteogram_axes([ax], axparamdicts)\n",
    "# #     ax.set_ylim(0.0,9.0)\n",
    "# #     ax.set_ylabel('D (mm)')\n",
    "#     cax = divider.append_axes(\"bottom\",size=\"5%\",pad=0.75)\n",
    "#     cb = fig.colorbar(C,cax=cax,orientation='horizontal')\n",
    "#     cb.set_label(r'log[N ($m^{-3} mm^{-1}$)]')\n",
    "#     plt.savefig(PIPSname+'_'+runlabel+'_sampled_model_DSD.png',dpi=300)\n",
    "# # plt.savefig('raw_modelDSD.png',dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Cells Below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a plot of the disdrometer transects through the storm, \n",
    "# choosing a representative sweeptime as the backdrop\n",
    "plotdir = '/Users/dawson29/Dropbox/Projects/VORTEXSE/vortexse_enkf_dsd_study/plots/'+casedate\n",
    "if not os.path.exists(plotdir):\n",
    "    os.makedirs(plotdir)\n",
    "# If there is no reference sweeptime in the dictionary, just use the first one\n",
    "sweeptimeref = radar_dict[casedate]['sweeptime_ref']\n",
    "ustorm, vstorm = radar_dict[casedate]['feature_motion']\n",
    "sweepindex = np.searchsorted(sweeptimelist, sweeptimeref)\n",
    "sweepdtrel = [(sweeptime - sweeptimeref).total_seconds() for sweeptime in sweeptimelist]\n",
    "deployed = dis_dict_at_radar[casedate]['convdata_at_sweeptimes']['deployed']\n",
    "# dxsr = [[dx - ustorm * dt if d else np.nan for dt, d in zip(sweepdtrel, dp)] for dx, dp in zip(dxlist, deployed)]\n",
    "# dysr = [[dy - vstorm * dt if d else np.nan for dt, d in zip(sweepdtrel, dp)] for dy, dp in zip(dylist, deployed)]\n",
    "dxsr = [[dx - ustorm * dt for dt in sweepdtrel] for dx in dxlist]\n",
    "dysr = [[dy - vstorm * dt for dt in sweepdtrel] for dy in dylist]\n",
    "\n",
    "# Split up disdrometer storm relative locations by whether the disdrometer was actually deployed at a given time\n",
    "dxsr_d = [[x for x, d in zip(dx, dp) if d] for dx, dp in zip(dxsr, deployed)]\n",
    "dxsr_nd = [[x for x, d in zip(dx, dp) if not d] for dx, dp in zip(dxsr, deployed)]\n",
    "dysr_d = [[y for y, d in zip(dy, dp) if d] for dy, dp in zip(dysr, deployed)]\n",
    "dysr_nd = [[y for y, d in zip(dy, dp) if not d] for dy, dp in zip(dysr, deployed)]\n",
    "\n",
    "print sweeptimelist\n",
    "print sweepindex\n",
    "print deployed[0]\n",
    "print dxsr[0]\n",
    "print dxsr_d[0]\n",
    "print dxsr_nd[0]\n",
    "\n",
    "# Set plotting limits to center on the disdrometer locations \n",
    "Dxmin = np.nanmin(np.array(dxsr))\n",
    "Dxmax = np.nanmax(np.array(dxsr))\n",
    "Dymin = np.nanmin(np.array(dysr))\n",
    "Dymax = np.nanmax(np.array(dysr))\n",
    "plotlims = [Dxmin - 5000., Dxmax + 10000., Dymin - 10000., Dymax + 10000.]\n",
    "# plotlims = [15000., 45000., -15000., 0.]\n",
    "\n",
    "figlist, gridlist = radar.plotsweep_pyART(radlims, plotlims, outfieldnames, radarsweeplist[sweepindex], ovrmap, \n",
    "                                              ovrdis, dis_name_list, dxy_list, fields_D_list)\n",
    "ax = gridlist[0][0]\n",
    "\n",
    "dis_names = dis_dict_at_radar[casedate]['dis_names']\n",
    "\n",
    "for j, dx, dy, dx_d, dy_d, dx_nd, dy_nd, dp, dname in zip(xrange(len(dxlist)), dxsr, dysr, dxsr_d, dysr_d, \n",
    "                                                          dxsr_nd, dysr_nd, deployed, dis_names):\n",
    "    ax.plot(dx_d, dy_d, ls='-', c='k')\n",
    "    ax.plot(dx, dy, ls='--', c='k')\n",
    "    if dp[sweepindex]:\n",
    "        marker = 'o'\n",
    "    else:\n",
    "        marker = 'x'\n",
    "    ax.plot(dx[sweepindex], dy[sweepindex], marker=marker, ms=10, c='k')\n",
    "    ax.annotate(dname, (dx[sweepindex] + 1000., dy[sweepindex] - 2000.), clip_on=True)\n",
    "\n",
    "gridlist[0].cbar_axes[0].set_ylabel('Z (dBZ)')\n",
    "ax.set_xlabel('km')\n",
    "ax.set_ylabel('km')\n",
    "    \n",
    "figlist[0].canvas.draw()\n",
    "figlist[0].set_size_inches(10., 10., forward = True)\n",
    "\n",
    "figpath = os.path.join(plotdir, casedate+'_transects_radar.eps', bbox_inches='tight')\n",
    "plt.savefig(figpath, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up stuff for time composites\n",
    "# Initial grid limits (m)\n",
    "gridlims = [0., 100000., 0., 100000.]\n",
    "\n",
    "# Width of composite box in m\n",
    "compositewidthx = 60000.\n",
    "compositewidthy = 60000.\n",
    "\n",
    "# Width of search box for extremum in m\n",
    "searchboxwidthx = 12000.\n",
    "searchboxwidthy = 12000.\n",
    "\n",
    "# Name of variable for whose extrema to track for compositing (that's an awkward phrasing)\n",
    "tracking_varname = 'vortz'\n",
    "# level (height in m) at which to track the extrema\n",
    "tracking_level = 0.0 # 0.0 for 5 June, 3000.0 for 7 June, 3000.0 for 9 June \n",
    "# Type of extremum (max or min)\n",
    "tracking_extremum = 'max'\n",
    "# Threshold magnitude of extremum below which to throw out a time from the composite\n",
    "tracking_thresh = 0.01\n",
    "\n",
    "compositedict = {'gridlims': gridlims,\n",
    "                 'compositewidth': (compositewidthx, compositewidthy), \n",
    "                 'searchboxwidth': (searchboxwidthx, searchboxwidthy),\n",
    "                 'tracking_varname': tracking_varname,\n",
    "                 'tracking_extremum': tracking_extremum, \n",
    "                 'tracking_level': tracking_level, \n",
    "                 'tracking_thresh': tracking_thresh}\n",
    "\n",
    "# Read in the model information for the case we want\n",
    "model_dict = sim.set_dh(casedate, init_model_dict, radar_dict)\n",
    "dh = model_dict[casedate]['DataHandler']\n",
    "modeltime_ref = model_dict[casedate]['modeltime_ref']\n",
    "\n",
    "# Read in the model grid info\n",
    "grid_dict = sim.read_model_grid(dh)\n",
    "# Initialize composite parameters\n",
    "if model_dict[casedate]['composite']:\n",
    "    compositedict = sim.init_composite(compositedict, grid_dict)\n",
    "\n",
    "# dp_data, consts = dh.loadMicrophysics()\n",
    "# # Extract the lowest model level and store in dp_data_2D\n",
    "# dp_data_2D = {}\n",
    "# for key, dat in dp_data.iteritems():\n",
    "#     dp_data_2D[key] = dat[:,:,0]\n",
    "# dp_data_plot = {}\n",
    "# for key, dat in dp_data_2D.iteritems():\n",
    "#     dp_data_plot[key] = dat.swapaxes(0, 1).squeeze()\n",
    "# dp_data_plot_list.append(dp_data_plot)\n",
    "\n",
    "if model_dict[casedate]['composite']:\n",
    "    print \"Building composite!\"\n",
    "    varcompdict = sim.build_composite(casedate, model_dict, compositedict, dh)\n",
    "    Zmod = varcompdict['DBZ']\n",
    "    Zmodplot = Zmod\n",
    "else:    \n",
    "    Zmod = dh.loadModelReflectivity()\n",
    "    Zmodplot = Zmod[:, :, 0].T\n",
    "# Zmodplot_list.append(Zmodplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Quick plot of the reflectivity composite for testing\n",
    "runname = model_dict[casedate]['runname']\n",
    "model_times = model_dict[casedate]['model_times']\n",
    "xckm_comp, yckm_comp = compositedict['ccoords']\n",
    "uccomp = varcompdict['UC']\n",
    "vccomp = varcompdict['VC']\n",
    "wind_pltscale = 2.0 # Scale of wind vectors\n",
    "windintv = 4        # Interval in grid points to plot wind vectors\n",
    "\n",
    "clevels = np.arange(0., 85., 5.)\n",
    "cintv = clevels[1] - clevels[0]\n",
    "norm, cmap = ctables.registry.get_with_steps('NWSReflectivity', 5., 5.)\n",
    "cbarlevels = ticker.MultipleLocator(base=cintv)\n",
    "clabel = 'Z (dBZ)'\n",
    "# qrplot = varcompdict['qg']*1000.\n",
    "# clevels = np.arange(0., 5.05, 0.05)\n",
    "# cintv = clevels[1] - clevels[0]\n",
    "# norm = None\n",
    "# cmap = cm.Blues\n",
    "# cbarlevels = np.arange(0., 5.5, 0.5) # ticker.MultipleLocator(base=1.0)\n",
    "# clabel = 'qg (g/kg)'\n",
    "\n",
    "compfig = plt.figure(figsize=(8,8))\n",
    "compax = compfig.add_subplot(111)\n",
    "plt.title(model_dict[casedate]['runname'])\n",
    "dBZplt = compax.contourf(xckm_comp, yckm_comp, Zmodplot, levels=clevels, cmap=cmap)\n",
    "# compax.contour(xskm_comp,yskm_comp,dBZ.T,levels=np.arange(30.,90.,10.),colors='k')\n",
    "windplt = compax.quiver(xckm_comp[::windintv], yckm_comp[::windintv], uccomp[::windintv, ::windintv],\n",
    "    vccomp[::windintv, ::windintv], pivot='middle', units='width', scale_units='width', \n",
    "    scale=1200.0/float(wind_pltscale), width=0.001*float(wind_pltscale), headwidth=5, headlength=5, color='k')\n",
    "\n",
    "compax.set_aspect('equal')\n",
    "divider = make_axes_locatable(compax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad = 0.05)\n",
    "clabels = cbarlevels\n",
    "clvllocator = ticker.FixedLocator(clabels)\n",
    "plt.colorbar(dBZplt, ticks=clvllocator, cax=cax)\n",
    "cax.set_ylabel('Z (dBZ)')\n",
    "#cax.set_ylabel('qg (g/kg)')\n",
    "\n",
    "compax.set_xlabel('km')\n",
    "compax.set_ylabel('km')\n",
    "\n",
    "compfig.savefig(runname+'_dBZ_comp_{:06d}_{:06d}.pdf'.format(int(model_times[0]),int(model_times[-1])),dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a plot of the disdrometer transects through the *simulated* storm, \n",
    "# choosing a representative *model time* as the backdrop\n",
    "\n",
    "# First we need to set up a list of x and y coordinates within the model for each disdrometer. We'll use the\n",
    "# coordinates computed relative to the radar above, but shifted so that they are in the same relative position\n",
    "# to the model storm (necessarily subjective) as they are for the observed storm.\n",
    "# For example, we'll use P2's coordinates near the tip of the hook for 5 June 2009.\n",
    "\n",
    "if model_dict[casedate]['composite']:\n",
    "    xref_model, yref_model = model_dict[casedate]['ref_coords_comp']\n",
    "    # Some coordinate array shenanigans\n",
    "    composite_grid_dict = sim.get_composite_grid(grid_dict, compositedict)\n",
    "    xcplot = composite_grid_dict['xcplot']\n",
    "    ycplot = composite_grid_dict['ycplot']\n",
    "    xeplot = composite_grid_dict['xeplot']\n",
    "    yeplot = composite_grid_dict['yeplot']\n",
    "    xcorplot = composite_grid_dict['xcorplot']\n",
    "    ycorplot = composite_grid_dict['ycorplot']\n",
    "else:\n",
    "    xref_model, yref_model = model_dict[casedate]['ref_coords']\n",
    "    xcplot = grid_dict['xcplot']\n",
    "    ycplot = grid_dict['ycplot']\n",
    "    xeplot = grid_dict['xeplot']\n",
    "    yeplot = grid_dict['yeplot']\n",
    "    xcorplot = grid_dict['xcorplot']\n",
    "    ycorplot = grid_dict['ycorplot']\n",
    "\n",
    "xref_rad = dxlist[-1]\n",
    "yref_rad = dylist[-1]\n",
    "\n",
    "xshift = xref_model - xref_rad\n",
    "yshift = yref_model - yref_rad\n",
    "\n",
    "dxmodlist = [dx + xshift for dx in dxlist]\n",
    "dymodlist = [dy + yshift for dy in dylist]\n",
    "\n",
    "# Using sweeptimelist here to facilitate matching with the disdrometer locations on the radar plot.\n",
    "sweepdtrel = [(sweeptime - modeltime_ref).total_seconds() for sweeptime in sweeptimelist]\n",
    "dxsrm = [[dx - ustorm * dt for dt in sweepdtrel] for dx in dxmodlist]\n",
    "dysrm = [[dy - vstorm * dt for dt in sweepdtrel] for dy in dymodlist]\n",
    "\n",
    "# Split up disdrometer storm relative locations by whether the disdrometer was actually deployed at a given time\n",
    "dxsrm_d = [[x for x, d in zip(dx, dp) if d] for dx, dp in zip(dxsrm, deployed)]\n",
    "dxsrm_nd = [[x for x, d in zip(dx, dp) if not d] for dx, dp in zip(dxsrm, deployed)]\n",
    "dysrm_d = [[y for y, d in zip(dy, dp) if d] for dy, dp in zip(dysrm, deployed)]\n",
    "dysrm_nd = [[y for y, d in zip(dy, dp) if not d] for dy, dp in zip(dysrm, deployed)]\n",
    "\n",
    "# Get the index where the relative time is zero. Use this below to put the probes\n",
    "# at the proper location along the transect corresponding to the reference time.\n",
    "modelindex_ref = np.searchsorted(sweepdtrel, 0.)\n",
    "\n",
    "# Set plotting limits to center on the disdrometer locations \n",
    "Dxmin = np.array(dxsrm).min()\n",
    "Dxmax = np.array(dxsrm).max()\n",
    "Dymin = np.array(dysrm).min()\n",
    "Dymax = np.array(dysrm).max()\n",
    "plotlims = [Dxmin - 5000., Dxmax + 10000., Dymin - 10000., Dymax + 10000.]\n",
    "\n",
    "fig = None\n",
    "ax = None\n",
    "ptype = 2\n",
    "xlim = [plotlims[0], plotlims[1]]\n",
    "ylim = [plotlims[2], plotlims[3]]\n",
    "clevels = np.arange(0., 85., 5.)\n",
    "cintv = clevels[1] - clevels[0]\n",
    "norm, cmap = ctables.registry.get_with_steps('NWSReflectivity', 5., 5.)\n",
    "cbarlevels = ticker.MultipleLocator(base=cintv)\n",
    "clabel = 'Z (dBZ)'\n",
    "cformat = None\n",
    "ovrmap = False\n",
    "gis_info = None\n",
    "numovr = 0\n",
    "axesticks = [10000., 10000.]\n",
    "\n",
    "fig, ax = pm.plotsingle(fig, ax, ptype, xcplot, ycplot, xcorplot, ycorplot, xlim, ylim, Zmodplot, clevels, cmap, norm,\n",
    "                            cbarlevels, clabel, cformat, ovrmap, gis_info, numovr, None, None, None, None, None,\n",
    "                            axesticks)\n",
    "\n",
    "for j, dx, dy, dx_d, dy_d, dx_nd, dy_nd, dp, dname in zip(xrange(len(dxmodlist)), dxsrm, dysrm, dxsrm_d, dysrm_d, \n",
    "                                                          dxsrm_nd, dysrm_nd, deployed, dis_names):\n",
    "    ax.plot(dx, dy, ls='--', c='k')\n",
    "    ax.plot(dx_d, dy_d, ls='-', c='k')\n",
    "    if dp[modelindex_ref]:\n",
    "        marker = 'o'\n",
    "    else:\n",
    "        marker = 'x'\n",
    "    ax.plot(dx[sweepindex], dy[sweepindex], marker=marker, ms=10, c='k')\n",
    "    ax.annotate(dname, (dx[sweepindex] + 1000., dy[sweepindex] - 2000.), clip_on=True)\n",
    "    \n",
    "fig.canvas.draw()\n",
    "fig.set_size_inches(10., 10., forward = True)\n",
    "figpath = os.path.join(plotdir, casedate+'_transects_model.eps', bbox_inches='tight')\n",
    "plt.savefig(figpath, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in time series and add to dis_dict\n",
    "dis_dict = sim.read_probe_time_series(casedate, dis_dict, radar_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not model_dict[casedate]['composite']:\n",
    "    varlists = ['DBZ', 'TH', 'QV', 'P']\n",
    "    varlistv = ['U', 'V']\n",
    "    varlist_derived = ['PTE', 'UC', 'VC']\n",
    "\n",
    "    vardictlist = sim.read_vardict(casedate, model_dict, varlists, varlistv, varlist_derived)\n",
    "\n",
    "    vardict = vardictlist[0]\n",
    "    grid_dict_in = grid_dict\n",
    "else:\n",
    "    vardict = varcompdict\n",
    "    grid_dict_in = composite_grid_dict\n",
    "\n",
    "# Find grid intersections\n",
    "dis_ts_model_dict = sim.find_transect_grid_intersections(casedate, grid_dict_in, dis_dict, model_dict, radar_dict, \n",
    "                                     vardict, plot_locations=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print dis_dict[casedate].keys()\n",
    "print dis_ts_model_dict.keys()\n",
    "print varcompdict['rhoa']\n",
    "dis_ts_vars_points = dis_ts_model_dict['dis_ts_vars_points']\n",
    "print len(dis_ts_vars_points)\n",
    "dis_names = dis_dict[casedate]['dis_names']\n",
    "print len(dis_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print dis_dict[casedate]['timeseries'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate and plot observed DSD transects\n",
    "transect_DSD_obs_dict = sim.calc_obs_transect(casedate, dis_dict, dis_ts_model_dict, Dmax=9.0, plot_transects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate and plot model DSD transects\n",
    "transect_DSD_dict = sim.interp_model_to_transect(casedate, dis_dict, model_dict, dis_ts_model_dict,\n",
    "                                                 sampling_interval=60., add_hail=False, \n",
    "                                                 use_bins_for_interp=True, use_Parsivel_simulator=True, \n",
    "                                                 Dmax=9.0, plot_transects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make some one-to-one plots of D0 (model) vs. D0 (disdrometer)\n",
    "\n",
    "yvals = sim.D*1000.\n",
    "xvals = sim.D*1000.\n",
    "color_list = ['r', 'orange', 'g', 'b']\n",
    "\n",
    "D0r_mod = transect_DSD_dict['D0r']\n",
    "D0r_mod_sampled = transect_DSD_dict['D0r_ps']\n",
    "\n",
    "D0r_obs = transect_DSD_obs_dict['D0r_obs']\n",
    "D0r_obs_gam = transect_DSD_obs_dict['D0r_gam']\n",
    "\n",
    "for d, dis_name in enumerate(dis_dict[casedate]['dis_names']):\n",
    "    obs = D0r_obs_gam[d]*1000.\n",
    "    mod = D0r_mod[d]*1000.\n",
    "    mod_sampled = D0r_mod_sampled[d]*1000.\n",
    "    bias_mod = ((np.nansum(mod-obs))/np.nansum(obs))\n",
    "    bias_mod_sampled = ((np.nansum(mod_sampled-obs))/np.nansum(obs))\n",
    "    cc_mod = pd.DataFrame({'obs': obs, 'mod': mod}).corr().iloc[0, 1]\n",
    "    cc_mod_sampled = pd.DataFrame({'obs': obs, 'mod': mod_sampled}).corr().iloc[0, 1]\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.scatter(obs, mod, c=color_list[d], marker='*', label=dis_name+'_gamma')\n",
    "    plt.scatter(obs, mod_sampled, c=color_list[d], marker='+', alpha=0.75, label=dis_name+'_sampled')\n",
    "    ax.plot(xvals, yvals, lw=2, color='k')\n",
    "    ax.set_xlim(0.0, 8.0)\n",
    "    ax.set_ylim(0.0, 8.0)\n",
    "    ax.set_xlabel('Observed')\n",
    "    ax.set_ylabel('Model')\n",
    "    ax.text(0.6, 0.20, 'Bias (model): {:2.2f}'.format(bias_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.15, 'Cor. Coef. (model) {:2.3f}'.format(cc_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.10, 'Bias (model sampled): {:2.2f}'.format(bias_mod_sampled), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.05, 'Cor. Coef. (model sampled) {:2.3f}'.format(cc_mod_sampled), transform=ax.transAxes)\n",
    "    plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate dual-pol variables for both the model and observations and make scatterplots of Z vs. ZDR\n",
    "# Z, ZDR relation from Cao et al. (2008)\n",
    "Zh_Cao = np.arange(10, 61, 0.1)\n",
    "Zdr_Cao = 10**((-2.6857 * 10**-4 * Zh_Cao**2) + 0.04892 * Zh_Cao - 1.4287)\n",
    "\n",
    "scattfile = '../tmatrix/S-band/SCTT_RAIN_fw100.dat'\n",
    "wavelength = 10.7 # mm\n",
    "Dmax = 9.0\n",
    "Dmax_index = sim.get_Dmax_index(Dmax)\n",
    "color_list = ['r', 'orange', 'g', 'b']\n",
    "ND_mod = transect_DSD_dict['ND']\n",
    "ND_obs = transect_DSD_obs_dict['ND']\n",
    "\n",
    "\n",
    "\n",
    "for d, dis_name in enumerate(dis_dict[casedate]['dis_names']):\n",
    "    dualpol_mod = dis.calpolrain(wavelength, scattfile, ND_mod[d].T, dis.bin_width[:Dmax_index])\n",
    "    dualpol_obs = dis.calpolrain(wavelength, scattfile, ND_obs[d].T, dis.bin_width[:Dmax_index])\n",
    "    sample_xlocs = np.array([xylocs[0] for xylocs in dis_ts_model_dict['dis_ts_xyslocs'][d]])\n",
    "    print sample_xlocs\n",
    "    sample_ylocs = np.array([xylocs[1] for xylocs in dis_ts_model_dict['dis_ts_xyslocs'][d]])\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    sc = plt.scatter(dualpol_mod['dBZ'], dualpol_mod['ZDR'], c=sample_xlocs, marker='*', label=dis_name+'_mod',\n",
    "                     vmin=-15000., vmax=15000.)\n",
    "    plt.scatter(dualpol_obs['dBZ'], dualpol_obs['ZDR'], c=sample_xlocs, marker='o', label=dis_name+'_obs', vmin=-15000., vmax=15000.)\n",
    "    plt.plot(Zh_Cao, Zdr_Cao, c='k', ls='-', lw=1.0)\n",
    "    plt.colorbar(sc)\n",
    "    ax.set_xlabel('dBZ')\n",
    "    ax.set_ylabel(r'Z$_DR$')\n",
    "    ax.set_xlim(10.0, 60.0)\n",
    "    ax.set_ylim(-2.0, 6.0)\n",
    "    plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pyPIPS]",
   "language": "python",
   "name": "conda-env-pyPIPS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

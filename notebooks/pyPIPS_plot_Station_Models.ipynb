{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to demonstrate plotting of station models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T14:40:32.290220Z",
     "start_time": "2020-06-24T14:40:28.958219Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid,make_axes_locatable,host_subplot\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "import os\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "#import pyPIPS.disdrometer_module as dis\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "#import pyPIPS.simulator as sim\n",
    "import pyPIPS.pips_io as pipsio\n",
    "import pyPIPS.PIPS as pips\n",
    "import pyPIPS.parsivel_params as pp\n",
    "import pyPIPS.parsivel_qc as pqc\n",
    "import pyPIPS.polarimetric as dualpol\n",
    "import pyPIPS.timemodule as ptime\n",
    "# from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "# from pyCRMtools.pycaps import arps_read\n",
    "# from pyCRMtools.pycaps import pycaps_fields\n",
    "# from pyCRMtools.pycaps import calvars_radar as radar\n",
    "\n",
    "# Stesonet plotting stuff. Need to add location to the path\n",
    "\n",
    "sys.path.append('/Users/dawson29/Projects/StickNet_Repo')\n",
    "from functions import calc_dewpoint,calc_thetae,calc_thetav,C_to_F,calc_mslp,convert_wind, parse_currtime\n",
    "from functions_plotting import scale_bar, plot_logo\n",
    "\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy.random as random\n",
    "from scipy.stats import gamma, uniform\n",
    "from scipy.special import gamma as gammafunc\n",
    "from scipy import ndimage\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.calc import wind_components\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.plots.wx_symbols import current_weather, sky_cover\n",
    "from metpy.units import units\n",
    "from metpy.plots import USCOUNTIES\n",
    "from metpy.plots import  StationPlot\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "# from natsort import natsorted\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.style.use('seaborn-bright')\n",
    "\n",
    "# # read in cartopy information    \n",
    "crs = ccrs.PlateCarree()\n",
    "# Get data to plot state and province boundaries\n",
    "states_provinces = cfeature.NaturalEarthFeature(\n",
    "        category='cultural',\n",
    "        name='admin_1_states_provinces_lakes',\n",
    "        scale='10m',\n",
    "        facecolor='none')\n",
    "\n",
    "\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T14:40:48.238022Z",
     "start_time": "2020-06-24T14:40:47.848609Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# date = '052516' # '053122' # '030622' # '061416'\n",
    "# PIPS_dir = '/Users/dawson29/Dropbox/PIPS_data/2016/{}/netcdf'.format(date)\n",
    "# PIPS_dir = '/Users/dawson29/Dropbox/Projects/PERiLS/PIPS_data/{}_IN_test/netcdf'.format(date)\n",
    "# PIPS_dir = '/Users/dawson29/Dropbox/Projects/PERiLS/PIPS_data/IOP2_033022/netcdf'\n",
    "# PIPS_dir = '/Users/dawson29/Dropbox/PIPS_data/2023/IOP2_030323/netcdf'\n",
    "# PIPS_dir = '/Users/dawson29/Projects/PERiLS/obsdata/2023/PIPS_data/IOP3_032423/netcdf'\n",
    "# PIPS_dir = '/Users/dawson29/Projects/PERiLS/obsdata/2023/PIPS_data/IOP4_033123/netcdf'\n",
    "PIPS_dir = '/Users/dawson29/Projects/PERiLS/obsdata/2023/PIPS_data/IOP5_040523/netcdf'\n",
    "# PIPS_dir = '/Users/dawson29/Dropbox/Teaching/2022/EAPS_591_SSFW/PIPS_data/{}/netcdf'.format(date)\n",
    "# PIPS_dir = '/depot/dawson29/data/Projects/SPOTTR-2016/{}/obsdata/PIPS/netcdf'.format(date)\n",
    "# PIPS_dir = '/Users/dawson29/Dropbox/PIPS_data/2016/SPOTTR2016/{}/netcdf'.format(date)\n",
    "# PIPS_dir = '/Users/dawson29/PIPS_data/2023/031123_mass_test/netcdf'\n",
    "# PIPS_dir = '/Users/dawson29/Dropbox/PIPS_data/2023/022223_mass_test/netcdf'\n",
    "# PIPS_dir = '/Users/dawson29/PIPS_data/2023/031623_mass_test/netcdf'\n",
    "# deployment_name = 'SPOTTR_{}'.format(date)\n",
    "# deployment_name = '031123_mass_test'\n",
    "# deployment_name = '022223_mass_test'\n",
    "# deployment_name = '031623_mass_test'\n",
    "# deployment_name = 'IOP3_032423'\n",
    "# deployment_name = 'IOP4_033123'\n",
    "deployment_name = 'IOP5_040523'\n",
    "PIPS_names = ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B', 'PIPS3A', 'PIPS3B']\n",
    "parsivel_interval = 10\n",
    "parsivel_filenames = ['parsivel_combined_{}_{}_{:d}s.nc'.format(deployment_name, PIPS_name, parsivel_interval)\n",
    "                      for PIPS_name in PIPS_names]\n",
    "parsivel_filepaths = [os.path.join(PIPS_dir, parsivel_filename) for parsivel_filename in parsivel_filenames]\n",
    "conv_filenames = ['conventional_raw_{}_{}.nc'.format(deployment_name, PIPS_name) for PIPS_name in PIPS_names]\n",
    "conv_filepaths = [os.path.join(PIPS_dir, conv_filename) for conv_filename in conv_filenames]\n",
    "parsivel_ds_read_dict = {}\n",
    "conv_ds_read_dict = {}\n",
    "for PIPS_name, parsivel_filepath, conv_filepath in zip(PIPS_names, parsivel_filepaths, conv_filepaths):\n",
    "    try:\n",
    "        parsivel_ds_read_dict[PIPS_name] = xr.load_dataset(parsivel_filepath)\n",
    "    except:\n",
    "        parsivel_ds_read_dict[PIPS_name] = None\n",
    "    conv_ds_read_dict[PIPS_name] = xr.load_dataset(conv_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for PIPS_name in PIPS_names:\n",
    "    conv_ds = conv_ds_read_dict[PIPS_name]\n",
    "    print(PIPS_name)\n",
    "    print(conv_ds['time'][0].values, conv_ds['time'][-1].values)\n",
    "    geo_loc = eval(str(conv_ds.location))\n",
    "    lat = np.float(geo_loc[0])\n",
    "    lon = np.float(geo_loc[1])\n",
    "    alt = np.float(geo_loc[2])\n",
    "    print(f'{lat:0.5f}, {lon:0.5f}, {alt:0.0f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrict to certain time range\n",
    "# start_time = '2022-05-31T23:00' # '2022-03-07T00:00'\n",
    "# end_time = '2022-06-01T00:05' # '2022-03-08T00:00'\n",
    "# start_time = '2022-03-30T23:40'\n",
    "# end_time = '2022-03-31T01:30'\n",
    "# start_time = '2023-03-12T00:15'\n",
    "# end_time = '2023-03-12T14:00'\n",
    "# start_time = '2023-02-22T16:00'\n",
    "# end_time = '2023-02-23T01:00'\n",
    "# start_time = '2023-03-16T17:45'\n",
    "# end_time = '2023-03-17T15:05'\n",
    "\n",
    "if False:\n",
    "    parsivel_ds_dict = {}\n",
    "    conv_ds_dict = {}\n",
    "    for PIPS_name in PIPS_names:\n",
    "        try:\n",
    "            parsivel_ds_dict[PIPS_name] = parsivel_ds_read_dict[PIPS_name].sel(time=slice(start_time, end_time))\n",
    "        except AttributeError:\n",
    "            parsivel_ds_dict[PIPS_name] = None\n",
    "        conv_ds_dict[PIPS_name] = conv_ds_read_dict[PIPS_name].sel(time=slice(start_time, end_time))\n",
    "else:\n",
    "    parsivel_ds_dict = parsivel_ds_read_dict\n",
    "    conv_ds_dict = conv_ds_read_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsivel_ds_dict['PIPS2A']\n",
    "\n",
    "datetimes = parsivel_ds_dict['PIPS2A']['time'].to_index().to_pydatetime()\n",
    "\n",
    "print(datetimes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a particular time to plot\n",
    "time_to_plot = '2023-04-05T17:00' # '2023-03-03T08:30'# '2022-03-31T00:15'\n",
    "parsivel_ds_to_plot_dict = {}\n",
    "\n",
    "for PIPS_name, parsivel_ds in parsivel_ds_dict.items():\n",
    "    try:\n",
    "        parsivel_ds_to_plot_dict[PIPS_name] = parsivel_ds.sel(time=time_to_plot, method='nearest')\n",
    "    except AttributeError:\n",
    "        parsivel_ds_to_plot_dict[PIPS_name] = None\n",
    "    \n",
    "obtime = parsivel_ds_to_plot_dict['PIPS2A']['time'].values\n",
    "obtime = pd.to_datetime(obtime)\n",
    "print(obtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a particular time to plot\n",
    "time_to_plot = '2023-04-05T17:00' # '2023-03-03T08:30'# '2022-03-31T00:15'\n",
    "conv_ds_to_plot_dict = {}\n",
    "\n",
    "for PIPS_name, conv_ds in conv_ds_dict.items():\n",
    "    try:\n",
    "        conv_ds_to_plot_dict[PIPS_name] = conv_ds.sel(time=time_to_plot, method='nearest')\n",
    "    except AttributeError:\n",
    "        conv_ds_to_plot_dict[PIPS_name] = None\n",
    "    \n",
    "obtime = conv_ds_to_plot_dict['PIPS2A']['time'].values\n",
    "obtime = pd.to_datetime(obtime)\n",
    "print(obtime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_list = []\n",
    "Td_list = []\n",
    "pressure_list = []\n",
    "u_list = []\n",
    "v_list = []\n",
    "lats = []\n",
    "lons = []\n",
    "elevs = []\n",
    "\n",
    "for PIPS_name, parsivel_ds in parsivel_ds_to_plot_dict.items():\n",
    "    geo_loc_str = parsivel_ds.location\n",
    "    geo_loc = list(map(np.float, geo_loc_str.strip('()').split(',')))\n",
    "    lats.append(geo_loc[0])\n",
    "    lons.append(geo_loc[1])\n",
    "    elevs.append(geo_loc[2])\n",
    "    \n",
    "    T_list.append(parsivel_ds['fasttemp'].values)\n",
    "    Td_list.append(parsivel_ds['dewpoint'].values)\n",
    "    pressure_list.append(parsivel_ds['pressure'].values)\n",
    "    u_list.append(parsivel_ds['uavg'].values)\n",
    "    v_list.append(parsivel_ds['vavg'].values)\n",
    "\n",
    "T_arr = np.array(T_list)\n",
    "Td_arr = np.array(Td_list)\n",
    "pressure_arr = np.array(pressure_list)\n",
    "u_arr = np.array(u_list)\n",
    "v_arr = np.array(v_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_ds_to_plot_dict['PIPS1A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_list = []\n",
    "Td_list = []\n",
    "pressure_list = []\n",
    "u_list = []\n",
    "v_list = []\n",
    "lats = []\n",
    "lons = []\n",
    "elevs = []\n",
    "\n",
    "for PIPS_name, conv_ds in conv_ds_to_plot_dict.items():\n",
    "    geo_loc_str = conv_ds.location\n",
    "    geo_loc = list(map(np.float, geo_loc_str.strip('()').split(',')))\n",
    "    lats.append(geo_loc[0])\n",
    "    lons.append(geo_loc[1])\n",
    "    elevs.append(geo_loc[2])\n",
    "    \n",
    "    T_list.append(conv_ds['fasttemp'].values)\n",
    "    Td_list.append(conv_ds['dewpoint'].values)\n",
    "    pressure_list.append(conv_ds['pressure'].values)\n",
    "    u = conv_ds['windspd'] * np.cos(np.deg2rad(-conv_ds['winddirabs'] + 270.))\n",
    "    v = conv_ds['windspd'] * np.sin(np.deg2rad(-conv_ds['winddirabs'] + 270.))\n",
    "    u_list.append(u.values)\n",
    "    v_list.append(v.values)\n",
    "\n",
    "T_arr = np.array(T_list)\n",
    "Td_arr = np.array(Td_list)\n",
    "pressure_arr = np.array(pressure_list)\n",
    "u_arr = np.array(u_list)\n",
    "v_arr = np.array(v_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find extent of plot\n",
    "# exact center of plot\n",
    "clat = np.amin(lats)+ abs(np.amax(lats) - np.amin(lats))/2\n",
    "clon = np.amin(lons) + abs(np.amin(lons) - np.amax(lons))/2\n",
    "\n",
    "# NOTE: change these hardcoded values if you want to change relative domain size\n",
    "# larger (smaller) numbers = larger (smaller) domain\n",
    "dlat = 0.75 * abs(np.amax(lats) - np.amin(lats))\n",
    "dlon = 0.75 * abs(np.amin(lons) - np.amax(lons))\n",
    "\n",
    "\n",
    "if dlon < .1:\n",
    "    dlon = .1\n",
    "if dlat < .1:\n",
    "    dlat = .1\n",
    "\n",
    "# find corners using the center and the buffers\n",
    "north_lat, south_lat = clat+dlat, clat-dlat\n",
    "west_lon, east_lon = clon-dlon, clon+dlon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### initialize figure\n",
    "fig = plt.figure(figsize = [10,10])\n",
    "ax = fig.add_subplot(1,1,1, projection=crs)\n",
    "ax.set_extent([west_lon, east_lon, north_lat,south_lat], crs )\n",
    "ax.add_feature(states_provinces, edgecolor='k', alpha=0.25, linewidth=1)\n",
    "ax.add_feature(USCOUNTIES.with_scale('20m'), alpha=0.4, linewidth=0.2)\n",
    "\n",
    "\n",
    "# mark locations of SN\n",
    "ax.plot(lons,lats,marker='s',color='0.4',markersize=5, linewidth=0)\n",
    "\n",
    "\n",
    "# use metpy to plot T, Td, MSLP (coded), and the 4-letter identifiers\n",
    "stationplot = StationPlot(ax, lons, lats, clip_on=True, transform=crs, fontsize=10)\n",
    "stationplot.plot_parameter((-1.5,1), C_to_F(T_arr), color='#b30000', formatter='0.1f')\n",
    "stationplot.plot_parameter((-1.5,-1), C_to_F(Td_arr), color='darkgreen', formatter='0.1f')\n",
    "stationplot.plot_parameter((1.5,1), pressure_arr, formatter=lambda v: format(10 * v, '.0f')[-3:])\n",
    "stationplot.plot_text((1.5, -.9), PIPS_names, fontsize=9, weight='bold')\n",
    "\n",
    "# Add wind barbs, dropping bad vals, cuz WS can == -999\n",
    "# u[abs(u)>60] = 0; v[abs(v)>60] = 0\n",
    "ax.barbs(lons, lats, u_arr, v_arr, length=7.5, sizes={'emptybarb':.18}, lw=0.8)\n",
    "                \n",
    "\n",
    "### title\n",
    "ax.set_title('Observations at {}'.format(obtime.strftime('%D %H:%M UTC')),\n",
    "             fontsize=18, y=1.01, weight='bold', color='0.3')\n",
    "\n",
    "### Plot the TTU logo, have it update location based on shape of base map\n",
    "# plot_logo(fig, ax)\n",
    "\n",
    "\n",
    "### Scale Bar\n",
    "# find appropriate lenght of scale bar\n",
    "# should be ~ 1/5th the width of the plot\n",
    "# use 1 deg lon -> 111km approximation (10*10)\n",
    "center = np.average([ax.get_position().x0, ax.get_position().x1])\n",
    "#scale_len = np.ceil((abs(np.amin(lons) - np.amax(lons))*10)/4)*10\n",
    "\n",
    "scale_len = np.ceil((dlon*10)/3.5)*10\n",
    "\n",
    "if scale_len < 10:\n",
    "    scale_len = 10\n",
    "    \n",
    "\n",
    "scale_bar(fig, ax, length=int(scale_len), location=(center, ax.get_position().y0))\n",
    "#ax.text(center, 0.01, 'km', ha='center',fontsize=10, transform=ax.transAxes)\n",
    "\n",
    "# save figure \n",
    "# savedir = 'RT_tests' # hard coded real time directory\n",
    "# nametime = parse_currtime()[1] # note that this may be different from last time on plot\n",
    "#                              # THATS OKAY... it will make data drops more apparent!\n",
    "# plt.savefig('{0}/{1}_oban_{2}.png'.format(savedir,name,nametime),dpi=300,bbox_inches = 'tight')\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLD CELLS BELOW ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to use OpenStreetMap for images. Taken from \n",
    "# https://makersportal.com/blog/2020/4/24/geographic-visualizations-in-python-with-cartopy\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import io\n",
    "from urllib.request import urlopen, Request\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_spoof(self, tile): # this function pretends not to be a Python script\n",
    "    url = self._image_url(tile) # get the url of the street map API\n",
    "    req = Request(url) # start request\n",
    "    req.add_header('User-agent','Anaconda 3') # add user agent to request\n",
    "    fh = urlopen(req) \n",
    "    im_data = io.BytesIO(fh.read()) # get image\n",
    "    fh.close() # close url\n",
    "    img = Image.open(im_data) # open image with PIL\n",
    "    img = img.convert(self.desired_tile_form) # set image format\n",
    "    return img, self.tileextent(tile), 'lower' # reformat for cartopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cimgt.OSM.get_image = image_spoof # reformat web request for street map spoofing\n",
    "# osm_img = cimgt.OSM() # spoofed, downloaded street map\n",
    "cimgt.QuadtreeTiles.get_image = image_spoof # reformat web request for street map spoofing\n",
    "osm_img = cimgt.QuadtreeTiles() # spoofed, downloaded street map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific to IOP2 2023, make a list of the unique locations (since we had pairs of PIPS collocated)\n",
    "\n",
    "# IOP2 2023\n",
    "# PIPS_names1 = ['PIPS1A', 'PIPS2A', 'PIPS3A']\n",
    "# List of those PIPS Collocated with each of the above:\n",
    "# PIPS_names2 = ['PIPS2B', 'PIPS1B', 'PIPS3B']\n",
    "\n",
    "# IOP3 2023\n",
    "# PIPS_names1 = ['PIPS2A', 'PIPS3A']\n",
    "# PIPS_names2 = []\n",
    "\n",
    "# IOP4 2023\n",
    "# PIPS_names1 = ['PIPS1A', 'PIPS1B', 'PIPS3A', 'PIPS3B']\n",
    "# PIPS_names2 = ['PIPS2A', 'PIPS2B']\n",
    "\n",
    "# IOP5 2023\n",
    "PIPS_names1 = ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B', 'PIPS3A', 'PIPS3B']\n",
    "PIPS_names2 = []\n",
    "\n",
    "lats1 = []\n",
    "lats2 = []\n",
    "lons1 = []\n",
    "lons2 = []\n",
    "\n",
    "\n",
    "for PIPS_name1 in PIPS_names1:\n",
    "    conv_ds = conv_ds_to_plot_dict[PIPS_name1]\n",
    "    geo_loc_str = conv_ds.location\n",
    "    geo_loc = list(map(np.float, geo_loc_str.strip('()').split(',')))\n",
    "    lats1.append(geo_loc[0])\n",
    "    lons1.append(geo_loc[1])\n",
    "    # elevs.append(geo_loc[2])\n",
    "\n",
    "for PIPS_name2 in PIPS_names2:\n",
    "    conv_ds = conv_ds_to_plot_dict[PIPS_name2]\n",
    "    geo_loc_str = conv_ds.location\n",
    "    geo_loc = list(map(np.float, geo_loc_str.strip('()').split(',')))\n",
    "    lats2.append(geo_loc[0])\n",
    "    lons2.append(geo_loc[1])\n",
    "    # elevs.append(geo_loc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9,9)) # open matplotlib figure\n",
    "ax1 = plt.axes(projection=osm_img.crs) # project using coordinate reference system (CRS) of street map\n",
    "# location = eval(str(conv_ds.location))\n",
    "center_pt = [clat, clon]\n",
    "zoom = 0.12 # for zooming out of center point\n",
    "lat_extent_mult = 1.5\n",
    "extent = [center_pt[1]-(zoom*lat_extent_mult), center_pt[1]+(zoom*lat_extent_mult), \n",
    "          center_pt[0]-zoom, center_pt[0]+zoom] # adjust to zoom\n",
    "ax1.set_extent(extent) # set extents\n",
    "scale = np.ceil(-np.sqrt(2)*np.log(np.divide(zoom,350.0))) # empirical solve for scale based on zoom\n",
    "scale = (scale<20) and scale or 19 # scale cannot be larger than 19\n",
    "print(scale)\n",
    "ax1.add_image(osm_img, int(scale)) # add OSM with zoom specification\n",
    "# NOTE: zoom specifications should be selected based on extent:\n",
    "# -- 2     = coarse image, select for worldwide or continental scales\n",
    "# -- 4-6   = medium coarseness, select for countries and larger states\n",
    "# -- 6-10  = medium fineness, select for smaller states, regions, and cities\n",
    "# -- 10-12 = fine image, select for city boundaries and zip codes\n",
    "# -- 14+   = extremely fine image, select for roads, blocks, buildings\n",
    "\n",
    "# mark locations of SN\n",
    "ax1.scatter(lons, lats, marker='s', c='r', alpha=1, transform=ccrs.PlateCarree())\n",
    "\n",
    "# For IOP2-2023 only, make two different station plots for each of the pairs, so that we can plot the text labels\n",
    "# so they don't overlap. This is a pretty dumb hack but need something quick and dirty right now\n",
    "stationplot1 = StationPlot(ax1, lons1, lats1, clip_on=True, transform=ccrs.PlateCarree(), fontsize=10)\n",
    "if len(lons2) > 0:\n",
    "    stationplot2 = StationPlot(ax1, lons2, lats2, clip_on=True, transform=ccrs.PlateCarree(), fontsize=10)\n",
    "# stationplot.plot_parameter((-1.5,1), C_to_F(T_arr), color='#b30000', formatter='0.1f')\n",
    "# stationplot.plot_parameter((-1.5,-1), C_to_F(Td_arr), color='darkgreen', formatter='0.1f')\n",
    "# stationplot.plot_parameter((1.5,1), pressure_arr, formatter=lambda v: format(10 * v, '.0f')[-3:])\n",
    "stationplot1.plot_text((2.75, -1.), PIPS_names1, fontsize=12, weight='bold', color='red')\n",
    "if len(lons2) > 0:\n",
    "    stationplot2.plot_text((2.75, -2.25), PIPS_names2, fontsize=12, weight='bold', color='red')\n",
    "\n",
    "# for PIPS_name, conv_ds in conv_ds_dict.items():\n",
    "#     lons = conv_ds['GPS_lon']\n",
    "#     lons = lons.where(conv_ds['GPS_status'] == 'A', drop=True)\n",
    "#     lats = conv_ds['GPS_lat']\n",
    "#     lats = lats.where(conv_ds['GPS_status'] == 'A', drop=True)\n",
    "#     times = conv_ds['time']\n",
    "#     times = times.where(conv_ds['GPS_status'] == 'A', drop=True)\n",
    "#     sc = ax1.scatter(lons, lats, c=times, marker='o', facecolor='none', alpha=1, transform=ccrs.PlateCarree())\n",
    "\n",
    "# fig.colorbar(sc, ax=ax1)\n",
    "\n",
    "# save figure \n",
    "\n",
    "plotdir = '/Users/dawson29/Dropbox/Projects/PERiLS/Documentation_for_EOL/'\n",
    "plotname = f'{deployment_name}_overview.png'\n",
    "plotpath = os.path.join(plotdir, plotname)\n",
    "plt.savefig(plotpath, dpi=300, bbox_inches='tight')\n",
    "# savedir = 'RT_tests' # hard coded real time directory\n",
    "# nametime = parse_currtime()[1] # note that this may be different from last time on plot\n",
    "#                              # THATS OKAY... it will make data drops more apparent!\n",
    "# plt.savefig('{0}/{1}_oban_{2}.png'.format(savedir,name,nametime),dpi=300,bbox_inches = 'tight')\n",
    "plt.show() # show the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old cells below. Check if there is anything important there and then get rid of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up map\n",
    "width_x = 500. # m\n",
    "width_y = 500. # m\n",
    "\n",
    "location = eval(str(conv_ds.location))\n",
    "ctrlat = location[0]\n",
    "ctrlon = location[1]\n",
    "\n",
    "trulon = ctrlon\n",
    "trulat1 = 35.\n",
    "trulat2 = 45.\n",
    "projection = ccrs.LambertConformal(ctrlon, ctrlat, false_easting=width_x/2., false_northing=width_y/2.,\n",
    "                                   standard_parallels=[trulat1, trulat2])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 10), subplot_kw={'projection': projection})\n",
    "\n",
    "# ax.stock_img()\n",
    "# Add coastlines and states\n",
    "ax.coastlines()\n",
    "land = feature.LAND\n",
    "ax.add_feature(land) # , edgecolor='face', facecolor=feature.COLORS['land'])\n",
    "states = feature.STATES\n",
    "# states = feature.NaturalEarthFeature(category=\"cultural\", scale=\"50m\",\n",
    "#                                      facecolor=\"none\",\n",
    "#                                      name=\"admin_1_states_provinces_shp\")\n",
    "ax.add_feature(states, linewidth=1., edgecolor='k', alpha=0.5)\n",
    "rivers = feature.RIVERS\n",
    "ax.add_feature(rivers, linewidth=0.75, edgecolor='b', alpha=0.5)\n",
    "ax.add_feature(feature.NaturalEarthFeature('cultural', 'roads', '10m'), facecolor='none', edgecolor='b')\n",
    "# # Add counties if desired. TODO: add back more features here after testing\n",
    "\n",
    "# # if runname == pc.runname_list[0] and time == time_list[0]:\n",
    "\n",
    "# print(\"Reading counties from shapefile\")\n",
    "county_shapefile_location = '/Users/dawson29/Projects/pyCRMtools/data/shapefiles/county/countyp020'\n",
    "counties = plotmod.read_shapefile(county_shapefile_location)\n",
    "ax.add_feature(counties, linewidth=0.5, edgecolor='grey', alpha=0.5)\n",
    "\n",
    "# Add urban areas\n",
    "# urban_shapefile_location = '/Users/dawson29/Projects/pyCRMtools/data/shapefiles/urban2/tl_2008_us_cbsa'\n",
    "# urban = plotmod.read_shapefile(urban_shapefile_location)\n",
    "# ax.add_feature(urban, linewidth=0.5, facecolor='purple', edgecolor='none', alpha=0.25)\n",
    "\n",
    "# Add more stuff from GADM database (EDIT: doesn't seem to add anything beyond counties)\n",
    "# gadm_shapefile_location = '/Users/dawson29/Projects/pyCRMtools/data/shapefiles/gadm/gadm36_USA_2'\n",
    "# gadm_shapes = plotmod.read_shapefile(gadm_shapefile_location)\n",
    "# ax.add_feature(gadm_shapes, linewidth=0.5, edgecolor='purple', alpha=0.8)\n",
    "\n",
    "ax.set_xlim(0., width_x)\n",
    "ax.set_ylim(0., width_y)\n",
    "# ax.scatter([ctrlon], [ctrlat], color='black', marker='o', facecolor='none', transform=ccrs.PlateCarree())\n",
    "\n",
    "lons = conv_ds['GPS_lon']\n",
    "lats = conv_ds['GPS_lat']\n",
    "ax.scatter(lons, lats, color='black', marker='o', facecolor='none', alpha=0.75, transform=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T20:58:13.817825Z",
     "start_time": "2020-06-23T20:58:13.717395Z"
    }
   },
   "outputs": [],
   "source": [
    "print(wind_dir_conv.coords['time'])\n",
    "print(len(wind_dir_conv.time))\n",
    "print(len(np.unique(wind_dir_conv.time.data)))\n",
    "unique_times = np.unique(wind_dir_conv['time'])\n",
    "print(unique_times)\n",
    "duplicated = wind_dir_conv.indexes['time'].duplicated()\n",
    "print(duplicated)\n",
    "dup_indices = np.where(duplicated)[0]\n",
    "print(dup_indices)\n",
    "#duplicated = xr.DataArray(parsivel_ds_read.indexes['time'].duplicated())\n",
    "duplicated_times = wind_dir_conv['time'].isel(time=dup_indices)\n",
    "print(duplicated_times)\n",
    "duplicated_times_only = wind_dir_conv.isel(time=dup_indices)\n",
    "print(duplicated_times_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T21:09:54.931677Z",
     "start_time": "2020-06-23T21:09:54.842408Z"
    }
   },
   "outputs": [],
   "source": [
    "time_diff = wind_spd_conv['time'].diff('time').astype(np.float)*1.e-9\n",
    "print(time_diff)\n",
    "out_of_order_times = time_diff.where(time_diff < 0, drop=True)['time']\n",
    "print(out_of_order_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T21:21:19.136212Z",
     "start_time": "2020-06-23T21:21:19.037622Z"
    }
   },
   "outputs": [],
   "source": [
    "int_indices = range(wind_spd_conv.sizes['time'])\n",
    "print(wind_spd_conv.coords['time'].values)\n",
    "int_ind_da = xr.DataArray(int_indices, coords=[('time', wind_spd_conv.coords['time'].values)])\n",
    "print(int_ind_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T21:22:48.263764Z",
     "start_time": "2020-06-23T21:22:48.181759Z"
    }
   },
   "outputs": [],
   "source": [
    "print(int_ind_da.sel(time='2017-04-30T20:40:18.000000000'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T21:26:00.767618Z",
     "start_time": "2020-06-23T21:26:00.682095Z"
    }
   },
   "outputs": [],
   "source": [
    "print(wind_spd_conv.isel(time=74415))\n",
    "print(wind_spd_conv.isel(time=74416))\n",
    "print(wind_spd_conv.isel(time=74417))\n",
    "print(wind_spd_conv.isel(time=74418))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T21:29:09.768836Z",
     "start_time": "2020-06-23T21:29:09.677148Z"
    }
   },
   "outputs": [],
   "source": [
    "time_diff = parsivel_ds['time'].diff('time').astype(np.float)*1.e-9\n",
    "print(time_diff)\n",
    "out_of_order_times = time_diff.where(time_diff < 0, drop=True)['time']\n",
    "print(out_of_order_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T21:54:20.671583Z",
     "start_time": "2020-06-23T21:54:20.258003Z"
    }
   },
   "outputs": [],
   "source": [
    "PIPS_dir2 = '/Volumes/scr_fast/Projects/VORTEXSE/obsdata/full_PIPS_dataset_new_test/'\n",
    "parsivel_filepath2 = os.path.join(PIPS_dir, 'parsivel_combined_FMCW_2017_043017_PIPS2A_60s.nc')\n",
    "conv_filepath2 = os.path.join(PIPS_dir, 'conventional_raw_FMCW_2017_043017_PIPS2A.nc')\n",
    "parsivel_ds2 = xr.load_dataset(parsivel_filepath2)\n",
    "conv_ds2 = xr.load_dataset(conv_filepath2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T21:54:34.264035Z",
     "start_time": "2020-06-23T21:54:34.180687Z"
    }
   },
   "outputs": [],
   "source": [
    "time_diff = parsivel_ds2['time'].diff('time').astype(np.float)*1.e-9\n",
    "print(time_diff)\n",
    "out_of_order_times = time_diff.where(time_diff < 0, drop=True)['time']\n",
    "print(out_of_order_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pyPIPS]",
   "language": "python",
   "name": "conda-env-pyPIPS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

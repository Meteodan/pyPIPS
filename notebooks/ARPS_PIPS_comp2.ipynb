{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T01:32:14.344375Z",
     "start_time": "2019-09-10T01:32:14.248723Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.dates as dates\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid,make_axes_locatable,host_subplot\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from datetime import datetime, timedelta\n",
    "import pytz as pytz\n",
    "import sys\n",
    "import os\n",
    "import pyPIPS.utils as utils\n",
    "import pyPIPS.thermolib as thermo\n",
    "import pyPIPS.DSDlib as dsd\n",
    "import pyPIPS.disdrometer_module as dis\n",
    "import pyPIPS.plotmodule as PIPSplot\n",
    "import pyPIPS.simulator as sim\n",
    "import pyPIPS.radarmodule as pyPIPSradar\n",
    "import pyPIPS.PIPS as pips\n",
    "import pyPIPS.pips_io as pips_io\n",
    "import pyPIPS.parsivel_qc as pqc\n",
    "import pyPIPS.parsivel_params as pp\n",
    "from pyCRMtools.modules import plotmodule as plotmod\n",
    "from pyCRMtools.modules import utils as CRMutils\n",
    "from pyCRMtools.pycaps import arps_read\n",
    "from pyCRMtools.pycaps import pycaps_fields\n",
    "from pyCRMtools.pycaps import calvars_radar as radar\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "import numpy.random as random\n",
    "from scipy.stats import gamma, uniform\n",
    "from scipy.special import gamma as gammafunc\n",
    "from scipy import ndimage\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.calc import get_wind_components\n",
    "from metpy.cbook import get_test_data\n",
    "from metpy.plots import StationPlot\n",
    "from metpy.plots.wx_symbols import current_weather, sky_cover\n",
    "from metpy.units import units\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T00:09:17.374225Z",
     "start_time": "2019-09-10T00:09:17.312809Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define dictionaries, keyed by case date (i.e. '060509', '060709', '060909', '033116'), to store parameters related\n",
    "# to NEXRAD radar data, disdrometer data, and model output, respectively\n",
    "\n",
    "# Case we are looking at right now. Should only have to change this up here and then execute all the cells below\n",
    "# to generate the appropriate analysis\n",
    "casedate = '033116'\n",
    "\n",
    "# Import the file containing the dictionaries needed to gather the radar, disdrometer, and model data.\n",
    "sys.path.append('/Users/dawson29/Dropbox/Projects/VORTEXSE/vortexse_enkf_dsd_study/configs/2016_IOP3')\n",
    "\n",
    "from PIPSsim_1km_dicts import *\n",
    "\n",
    "init_radar_dict = init_radar_dict[casedate]\n",
    "init_dis_dict = init_dis_dict[casedate]\n",
    "init_model_dict = init_model_dict[casedate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T00:11:16.512777Z",
     "start_time": "2019-09-10T00:09:24.448134Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now go ahead and read in the sweeps for the desired case\n",
    "radar_dict = sim.read_sweeps(init_radar_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T05:00:37.732947Z",
     "start_time": "2019-09-11T04:59:29.845118Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Go ahead and read in the conventional data at the sweeptimes and plot them:\n",
    "# %matplotlib notebook\n",
    "plotdir = '/Users/dawson29/Dropbox/Projects/VORTEXSE/vortexse_enkf_dsd_study/plots'\n",
    "radlims = [0.0, 250000., 0., 360.]\n",
    "plotlims = [-1, -1, -1, -1]\n",
    "ovrmap = False # Currently not working\n",
    "ovrdis = False\n",
    "dis_name_list = None\n",
    "dxy_list = None\n",
    "fields_D_list = None\n",
    "deg2rad = np.pi / 180.\n",
    "\n",
    "# Read time series\n",
    "dis_dict_at_radar = sim.read_convdata_at_sweeptimes(init_dis_dict, radar_dict)\n",
    "\n",
    "# Find disdrometer lat/lons and convert them to cartesian coordinates relative to radar lat/lon\n",
    "\n",
    "dis_dict = sim.get_dis_locs_relative_to_radar(init_dis_dict, radar_dict)\n",
    "\n",
    "dxlist = [i[0] for i in dis_dict['dradloclist']]\n",
    "dylist = [i[1] for i in dis_dict['dradloclist']]\n",
    "\n",
    "# Set plotting limits to center on the disdrometer locations \n",
    "if plotlims[0] == -1:\n",
    "    Dxmin = min(dxlist)\n",
    "    Dxmax = max(dxlist)\n",
    "    Dymin = min(dylist)\n",
    "    Dymax = max(dylist)\n",
    "    plotlims = [Dxmin - 25000., Dxmax + 25000., Dymin - 25000., Dymax + 25000.]\n",
    "\n",
    "# Extract stuff from radar dictionary\n",
    "sweeptimelist = radar_dict['sweeptimelist']\n",
    "radarsweeplist = radar_dict['radarsweeplist']\n",
    "outfieldnames = radar_dict['outfieldnameslist'][0] # Just need first entry\n",
    "\n",
    "# Extract stuff from disdrometer dictionary\n",
    "templist = dis_dict_at_radar['convdata_at_sweeptimes']['temp']\n",
    "dewpointlist = dis_dict_at_radar['convdata_at_sweeptimes']['dewpoint']\n",
    "pressurelist = dis_dict_at_radar['convdata_at_sweeptimes']['pressure']\n",
    "windspdavgveclist = dis_dict_at_radar['convdata_at_sweeptimes']['windspdavgvec']\n",
    "winddiravgveclist = dis_dict_at_radar['convdata_at_sweeptimes']['winddiravgvec']\n",
    "\n",
    "\n",
    "for i, sweeptime in enumerate(sweeptimelist):\n",
    "    print(\"i, sweeptime = \", sweeptime)\n",
    "    figlist, gridlist = pyPIPSradar.plotsweep_pyART(radlims, plotlims, outfieldnames, radarsweeplist[i], ovrmap, \n",
    "                                                    ovrdis, dis_name_list, dxy_list, fields_D_list)\n",
    "    ax = gridlist[0][0]\n",
    "    \n",
    "    for j, Dx, Dy in zip(range(len(dxlist)), dxlist, dylist):\n",
    "        stationplot = StationPlot(ax, [Dx], [Dy])\n",
    "        stationplot.plot_parameter('NW', [templist[j][i]], color='blue')\n",
    "        stationplot.plot_parameter('SW', [dewpointlist[j][i]], color='darkgreen')\n",
    "        stationplot.plot_parameter('NE', [pressurelist[j][i]], formatter=lambda v: format(10 * v, '.0f')[-3:])\n",
    "        u, v = get_wind_components([windspdavgveclist[j][i]] * units('m/s'), [winddiravgveclist[j][i]] * units.degree)\n",
    "        stationplot.plot_barb(u, v, barb_increments=dict(half=0.5, full=1.0, flag=5.0))\n",
    "\n",
    "    figlist[0].canvas.draw()\n",
    "    figlist[0].set_size_inches(10., 10., forward = True)\n",
    "    figname = 'PIPS_station_{}.png'.format(sweeptime.strftime('%Y%m%d%H%M%S'))\n",
    "    figpath = os.path.join(plotdir, figname)\n",
    "    plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T05:05:48.852767Z",
     "start_time": "2019-09-11T05:05:48.780143Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Now do the same for the model output\n",
    "# First set up some stuff\n",
    "\n",
    "def get_ARPS_member_dir_and_prefix(member, cycle):\n",
    "    \"\"\"\n",
    "    Gets the proper form for the subdirectory and file prefix name given a member number\n",
    "    and cycle type (either 'posterior' or 'prior'). member number 0 is interpreted as the mean. \n",
    "    \"\"\"\n",
    "    if member == 0:\n",
    "        if cycle in 'posterior':\n",
    "            member_dir = 'ENamean'\n",
    "            member_prefix = 'enmean'\n",
    "        elif cycle in 'prior':\n",
    "            member_dir = 'ENfmean'\n",
    "            member_prefix = 'efmean'\n",
    "    else:\n",
    "        if cycle in 'posterior':\n",
    "            member_dir = 'EN{:03d}'.format(int(member))\n",
    "            member_prefix = 'ena{:03d}'.format(int(member))\n",
    "        elif cycle in 'prior':\n",
    "            member_dir = 'ENF{:03d}'.format(int(member))\n",
    "            member_prefix = 'enf{:03d}'.format(int(member))\n",
    "    \n",
    "    return member_dir, member_prefix\n",
    "\n",
    "modelname = 'ARPS'\n",
    "microphys = 'ZVD'\n",
    "\n",
    "# From desired start and end times (UTC) get a range of datetimes and corresponding range of times in\n",
    "# seconds since model initial time\n",
    "timestamp_model_init = init_model_dict['timestamp_model_init']  # Start time of model corresponding to 0 s\n",
    "datetime_model_init = datetime.strptime(timestamp_model_init, '%Y%m%d%H%M%S')\n",
    "\n",
    "timestamp_start = init_model_dict['timestamp_model_start']  # Start time of desired time window\n",
    "timestamp_stop = init_model_dict['timestamp_model_stop']  # Stop time of desired time window\n",
    "datetime_start = datetime.strptime(timestamp_start, '%Y%m%d%H%M%S')\n",
    "datetime_stop = datetime.strptime(timestamp_stop, '%Y%m%d%H%M%S')\n",
    "tintv = init_model_dict['model_dt']  # Interval in seconds for model output\n",
    "tintv_mean = init_model_dict['model_dt_mean'] # Interval in seconds for ensemble mean analysis\n",
    "\n",
    "datetime_range = CRMutils.get_datetime_range(datetime_start, datetime_stop, tintv)\n",
    "trange = CRMutils.modeltimes_from_datetimes(datetime_range, datetime_start=datetime_model_init)\n",
    "\n",
    "datetime_range_mean = CRMutils.get_datetime_range(datetime_start, datetime_stop, tintv_mean)\n",
    "trange_mean = CRMutils.modeltimes_from_datetimes(datetime_range_mean, datetime_start=datetime_model_init)\n",
    "\n",
    "#basedir = '/Volumes/scr_fast/Projects/VORTEXSE/simulations/ARPS/2016_IOP3/3DVAR/1km0331163DVARCA00005min180_3km030015min540'\n",
    "fileformat = init_model_dict['fileformat']\n",
    "expname = '1km453x453_newse'\n",
    "basedir = init_model_dict['basedirname']\n",
    "member = 13 # 0 is for ensemble mean\n",
    "cycle = 'posterior'\n",
    "member_dir, member_prefix = get_ARPS_member_dir_and_prefix(member, cycle)\n",
    "member_absdir = os.path.join(basedir, expname, member_dir)\n",
    "trailer = ''\n",
    "nproc_x = 15\n",
    "nproc_y = 6\n",
    "\n",
    "if member == 0:\n",
    "    model_trange_sec = trange_mean\n",
    "    model_datetime_range = datetime_range_mean\n",
    "else:\n",
    "    model_trange_sec = trange\n",
    "    model_datetime_range = datetime_range\n",
    "    \n",
    "model_dict = init_model_dict.copy()\n",
    "\n",
    "model_dict['trange_member'] = trange\n",
    "model_dict['trange_mean'] = trange_mean\n",
    "model_dict['datetime_range_member'] = datetime_range\n",
    "model_dict['datetime_range_mean'] = datetime_range_mean\n",
    "\n",
    "\n",
    "if member == 0:\n",
    "    model_dict['trange'] = trange_mean\n",
    "    model_dict['datetime_range'] = datetime_range_mean\n",
    "else:\n",
    "    model_dict['trange'] = trange\n",
    "    model_dict['datetime_range'] = datetime_range\n",
    "    \n",
    "print(model_datetime_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T00:15:50.927396Z",
     "start_time": "2019-09-10T00:15:28.318295Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the ARPS grid\n",
    "# Get file path for grdbas file (note that call to read_grid handles the reading of the individual patches)\n",
    "# If the grdbas file doesn't exist, fall back to a history file\n",
    "grdbas_path = arps_read.get_file_path(member_absdir, member_prefix, fileformat, filetype='grdbas')\n",
    "\n",
    "patch_x = 1\n",
    "patch_y = 1\n",
    "grdbas_path_test = arps_read.add_patch_number(grdbas_path, patch_x, patch_y)\n",
    "\n",
    "if not os.path.exists(grdbas_path_test):\n",
    "    print(\"grdbas file doesn't exist, trying a history file!\")\n",
    "    grdbas_path = arps_read.get_file_path(member_absdir, member_prefix, fileformat, time=model_trange_sec[0], \n",
    "                                          filetype='history')\n",
    "    grdbas_path_test = arps_read.add_patch_number(grdbas_path, patch_x, patch_y)\n",
    "\n",
    "    print(grdbas_path_test)\n",
    "    print(os.path.exists(grdbas_path_test))\n",
    "\n",
    "# Read in grid information\n",
    "grid_dict = arps_read.readarpsgrid(grdbas_path, nproc_x=nproc_x, nproc_y=nproc_y)\n",
    "print(grid_dict.keys())\n",
    "\n",
    "# Get map projection information and create a Basemap instance\n",
    "# TODO: convert to use cartopy!\n",
    "\n",
    "ctrlat, ctrlon, trulat1, trulat2, trulon = arps_read.readarpsmap(grdbas_path, nproc_x=nproc_x, nproc_y=nproc_y)\n",
    "\n",
    "dx = grid_dict['dx']\n",
    "dy = grid_dict['dy']\n",
    "nx = grid_dict['nx']\n",
    "ny = grid_dict['ny']\n",
    "\n",
    "mapwidth = nx * dx\n",
    "mapheight = ny * dy\n",
    "\n",
    "bgmap = Basemap(projection='lcc', width=mapwidth, height=mapheight, lat_1=trulat1,\n",
    "                lat_2=trulat2, lat_0=ctrlat, lon_0=ctrlon, resolution='h',\n",
    "                area_thresh=10., suppress_ticks=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T22:17:24.402806Z",
     "start_time": "2019-09-10T22:17:24.340486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Put the basemap instance into the grid_dict\n",
    "grid_dict['bgmap'] = bgmap\n",
    "\n",
    "# Find coordinates of PIPS stations in the model\n",
    "dis_dict = sim.get_dis_locs_arps_real_grid(dis_dict, grid_dict)\n",
    "\n",
    "\n",
    "coord_array = np.array(dis_dict['dmodcrdlist'])\n",
    "print(dis_dict['dgeoloclist'])\n",
    "\n",
    "print(coord_array) \n",
    "print(coord_array.shape) \n",
    "print(coord_array[0]) \n",
    "# coord_array = coord_array.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-11T05:12:34.739800Z",
     "start_time": "2019-09-11T05:05:58.583197Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the PIPS station models on the ARPS model grid, similar to what was done with the radar sweep files\n",
    "dilist = [i[0] for i in dis_dict['dmodcrdlist']]\n",
    "djlist = [i[1] for i in dis_dict['dmodcrdlist']]\n",
    "\n",
    "print(dilist)\n",
    "print(djlist)\n",
    "\n",
    "dxlist = [i[0] for i in dis_dict['dmodloclist']]\n",
    "dylist = [i[1] for i in dis_dict['dmodloclist']]\n",
    "\n",
    "print(dxlist)\n",
    "print(dylist)\n",
    "\n",
    "xc = grid_dict['xs']\n",
    "yc = grid_dict['ys']\n",
    "xe = grid_dict['x']\n",
    "ye = grid_dict['y']\n",
    "\n",
    "xckm = xc / 1000.\n",
    "yckm = yc / 1000.\n",
    "xekm = xe / 1000.\n",
    "yekm = ye / 1000.\n",
    "\n",
    "# Set plotting limits to center on the disdrometer locations \n",
    "\n",
    "Dxmin = min(dxlist)\n",
    "Dxmax = max(dxlist)\n",
    "Dymin = min(dylist)\n",
    "Dymax = max(dylist)\n",
    "plotlims = [Dxmin - 25000., Dxmax + 25000., Dymin - 25000., Dymax + 25000.]\n",
    "\n",
    "ibgn = np.searchsorted(xc, plotlims[0])\n",
    "iend = np.searchsorted(xc, plotlims[1]) + 1\n",
    "jbgn = np.searchsorted(yc, plotlims[2])\n",
    "jend = np.searchsorted(yc, plotlims[3]) + 1\n",
    "\n",
    "print(plotlims)\n",
    "print(ibgn, iend, jbgn, jend)\n",
    "\n",
    "plotvar_dict = {\n",
    "    'xcplt': xckm,\n",
    "    'ycplt': yckm,\n",
    "    'xeplt': xekm,\n",
    "    'yeplt': yekm,\n",
    "}\n",
    "\n",
    "plotparam_dict = {\n",
    "    'cmap': pyPIPSradar.cmapdBZ,\n",
    "    'fieldlevels': np.arange(5.0, 85.0, 5.0),\n",
    "    'clvls': matplotlib.ticker.MultipleLocator(base=5.0),\n",
    "    'clabel': r'dBZ',\n",
    "    'cformat': None,\n",
    "}\n",
    "\n",
    "plotparam_dict['norm'] = matplotlib.colors.BoundaryNorm(plotparam_dict['fieldlevels'], \n",
    "                                                        plotparam_dict['cmap'].N)\n",
    "\n",
    "axesparam_dict = {\n",
    "    'axis_ticks': (10000., 10000.),\n",
    "    'axis_names': ('x', 'y')\n",
    "}\n",
    "\n",
    "plotlim_dict = {\n",
    "    'x': (plotlims[0], plotlims[1]),\n",
    "    'y': (plotlims[2], plotlims[3])\n",
    "}\n",
    "\n",
    "plotvar_name = 'dBZmod'\n",
    "\n",
    "\n",
    "dis_dict_at_model = sim.read_convdata_at_modeltimes(init_dis_dict, model_dict)\n",
    "\n",
    "# Extract stuff from disdrometer dictionary\n",
    "templist = dis_dict_at_model['convdata_at_modeltimes']['temp']\n",
    "dewpointlist = dis_dict_at_model['convdata_at_modeltimes']['dewpoint']\n",
    "pressurelist = dis_dict_at_model['convdata_at_modeltimes']['pressure']\n",
    "windspdavgveclist = dis_dict_at_model['convdata_at_modeltimes']['windspdavgvec']\n",
    "winddiravgveclist = dis_dict_at_model['convdata_at_modeltimes']['winddiravgvec']\n",
    "\n",
    "print(templist)\n",
    "\n",
    "for i, time in enumerate(model_trange_sec):\n",
    "    print(\"Loading time \", time) \n",
    "    filepath = arps_read.get_file_path(member_absdir, member_prefix, fileformat, time=time, filetype='history')\n",
    "    print(filepath)\n",
    "    \n",
    "    var_read_dict = {}\n",
    "    var_read_dict = pycaps_fields.get_fields(var_read_dict, field_names=[plotvar_name], path_grdbas=grdbas_path, \n",
    "                                             path_hdf=filepath, ibgn=ibgn, jbgn=jbgn, iend=iend, jend=jend, \n",
    "                                             klvls=[2], multipatch=True, grid_dict=grid_dict, \n",
    "                                             ignore_existing_vars=True, nproc_x=nproc_x, nproc_y=nproc_y)\n",
    "    \n",
    "    plotvar_dict = plotmod.init_plotvar_dict(plotvar_name, var_read_dict[plotvar_name], 0, 1, grid_dict)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    fig, ax = plotmod.plot2D(fig, ax, 'pcolor', plotvar_dict, plotparam_dict)\n",
    "    \n",
    "    plotmod.set_plot_axes(ax, plotlim_dict, axesparam_dict)\n",
    "\n",
    "    for j, Dx, Dy in zip(range(len(dxlist)), dxlist, dylist):\n",
    "        stationplot = StationPlot(ax, [Dx], [Dy])\n",
    "        stationplot.plot_parameter('NW', [templist[j][i]], color='blue')\n",
    "        stationplot.plot_parameter('SW', [dewpointlist[j][i]], color='darkgreen')\n",
    "        stationplot.plot_parameter('NE', [pressurelist[j][i]], formatter=lambda v: format(10 * v, '.0f')[-3:])\n",
    "        u, v = get_wind_components([windspdavgveclist[j][i]] * units('m/s'), [winddiravgveclist[j][i]] * units.degree)\n",
    "        stationplot.plot_barb(u, v, barb_increments=dict(half=0.5, full=1.0, flag=5.0))\n",
    "    \n",
    "    figname = 'PIPS_station_model_{}.png'.format(model_datetime_range[i].strftime('%Y%m%d%H%M%S'))\n",
    "    figpath = os.path.join(plotdir, figname)\n",
    "    plt.savefig(figpath, dpi=300, bbox_inches='tight') \n",
    "    \n",
    "# figlist, gridlist = pyPIPSradar.plotsweep_pyART(radlims, plotlims, outfieldnames, radarsweeplist[i], ovrmap, \n",
    "#                                                     ovrdis, dis_name_list, dxy_list, fields_D_list)\n",
    "#     ax = gridlist[0][0]\n",
    "    \n",
    "#     for j, Dx, Dy in zip(range(len(dxlist)), dxlist, dylist):\n",
    "#         stationplot = StationPlot(ax, [Dx], [Dy])\n",
    "#         stationplot.plot_parameter('NW', [templist[j][i]], color='red')\n",
    "#         stationplot.plot_parameter('SW', [dewpointlist[j][i]], color='darkgreen')\n",
    "#         stationplot.plot_parameter('NE', [pressurelist[j][i]], formatter=lambda v: format(10 * v, '.0f')[-3:])\n",
    "#         u, v = get_wind_components([windspdavgveclist[j][i]] * units('m/s'), [winddiravgveclist[j][i]] * units.degree)\n",
    "#         stationplot.plot_barb(u, v, barb_increments=dict(half=0.5, full=1.0, flag=5.0))\n",
    "\n",
    "#     figlist[0].canvas.draw()\n",
    "#     figlist[0].set_size_inches(10., 10., forward = True)\n",
    "#     figname = 'PIPS_station_{}.png'.format(sweeptime.strftime('%Y%m%d%H%M%S'))\n",
    "#     figpath = os.path.join(plotdir, figname)\n",
    "#     plt.savefig(figpath, dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T00:21:21.292004Z",
     "start_time": "2019-09-10T00:21:18.969687Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in PIPS data\n",
    "\n",
    "print(dis_dict.keys())\n",
    "\n",
    "dis_dir = dis_dict['dis_dir']\n",
    "dis_filenames = dis_dict['disfilenames']\n",
    "dis_names = dis_dict['dis_names']\n",
    "\n",
    "conv_df_dict = {}\n",
    "parsivel_df_dict = {}\n",
    "vd_matrix_da_dict = {}\n",
    "\n",
    "for dis_filename, dis_name in zip(dis_filenames, dis_names):\n",
    "    dis_filepath = os.path.join(dis_dir, dis_filename)\n",
    "    print(\"Reading {}\".format(dis_filepath))\n",
    "    conv_df, parsivel_df, vd_matrix_da = pips_io.read_PIPS(dis_filepath, starttimestamp=timestamp_start,\n",
    "                                                           stoptimestamp=timestamp_stop)\n",
    "    # Calculate some additional thermodynamic quantities and add to the conventional data DataFrame\n",
    "    conv_df = pips.calc_thermo(conv_df)\n",
    "    conv_df_dict[dis_name] = conv_df\n",
    "    parsivel_df_dict[dis_name] = parsivel_df\n",
    "    vd_matrix_da_dict[dis_name] = vd_matrix_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T00:21:31.319214Z",
     "start_time": "2019-09-10T00:21:30.987804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Resample PIPS data to a 60-s interval\n",
    "conv_rs_df_dict = {}\n",
    "parsivel_rs_df_dict = {}\n",
    "vd_matrix_rs_da_dict = {}\n",
    "for dis_name in dis_names:\n",
    "    # Conventional data\n",
    "    conv_df = conv_df_dict[dis_name]\n",
    "    datetime_range_onesec = conv_df.index.to_pydatetime()\n",
    "    sec_offset = pips.get_offset_seconds(datetime_range_onesec)\n",
    "    conv_rs_df_dict[dis_name] = pips.resample_conv('PIPS', 60., sec_offset, conv_df)\n",
    "    \n",
    "    # Parsivel 10-s derived fields\n",
    "    parsivel_df = parsivel_df_dict[dis_name]\n",
    "    datetime_range_tensec = parsivel_df.index.to_pydatetime()\n",
    "    sec_offset = pips.get_offset_seconds(datetime_range_tensec)\n",
    "    print(sec_offset)\n",
    "    parsivel_rs_df_dict[dis_name] = pips.resample_parsivel(60., parsivel_df)\n",
    "    \n",
    "    # Parsivel V-D matrix\n",
    "    vd_matrix_da = vd_matrix_da_dict[dis_name]\n",
    "    vd_matrix_rs_da_dict[dis_name] = pips.resample_vd_matrix(60., vd_matrix_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T00:54:30.465142Z",
     "start_time": "2019-09-10T00:54:30.032651Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute N(D) for the observed PIPS DSDs after some QC\n",
    "min_diameters = pp.parsivel_parameters['min_diameter_bins_mm']\n",
    "mid_diameters = pp.parsivel_parameters['avg_diameter_bins_mm']\n",
    "max_diameters = pp.parsivel_parameters['max_diameter_bins_mm']\n",
    "mid_fallspeeds = pp.parsivel_parameters['avg_fallspeed_bins_mps']\n",
    "empirical_fallspeed = pips.calc_empirical_fallspeed(mid_diameters)\n",
    "fallspeed_spectrum = pips.calc_fallspeed_spectrum(mid_diameters, mid_fallspeeds, use_measured_fallspeed=True)\n",
    "\n",
    "ND_PIPS_dict = {}\n",
    "logND_PIPS_dict = {}\n",
    "PSD_datetimes_rs_PIPS_dict = {}\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    vd_matrix_rs_da = vd_matrix_rs_da_dict[dis_name]\n",
    "    vd_matrix_rs_QC = pqc.strongwindQC(vd_matrix_rs_da)\n",
    "    vd_matrix_rs_QC = pqc.rainonlyQC(vd_matrix_rs_QC)\n",
    "    # Calculate ND and log10(ND)\n",
    "    ND = pips.calc_ND(vd_matrix_rs_QC.where(vd_matrix_rs_QC > 0.0), fallspeed_spectrum, 60.)\n",
    "    logND = np.log10(ND)\n",
    "    logND = logND.where(logND > -1.0)\n",
    "    \n",
    "    ND_PIPS_dict[dis_name] = ND\n",
    "    logND_PIPS_dict[dis_name] = logND\n",
    "    # Get times for PIPS transects as numpy arrays of python datetime objects\n",
    "    PSD_datetimes_rs = pips.get_PSD_datetimes(vd_matrix_rs_da)\n",
    "    PSD_datetimes_rs_dict = pips.get_PSD_time_bins(PSD_datetimes_rs)\n",
    "    PSD_datetimes_rs_PIPS_dict[dis_name] = PSD_datetimes_rs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T01:00:30.231851Z",
     "start_time": "2019-09-10T01:00:30.031516Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute some radar and DSD parameters from DSD\n",
    "dBZ_PIPS_dict = {}\n",
    "D0_PIPS_dict = {}\n",
    "for dis_name in dis_names:\n",
    "    dBZ_PIPS = dsd.calc_dBZ_from_bins(ND_PIPS_dict[dis_name])\n",
    "    dBZ_PIPS = dBZ_PIPS.where(dBZ_PIPS > -np.inf)\n",
    "    dBZ_PIPS_dict[dis_name] = dBZ_PIPS\n",
    "    D0_PIPS = dsd.calc_D0_bin(ND_PIPS_dict[dis_name])\n",
    "    D0_PIPS_dict[dis_name] = D0_PIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:08:14.292671Z",
     "start_time": "2019-09-10T15:08:12.554307Z"
    }
   },
   "outputs": [],
   "source": [
    "meteogram_dir = os.path.join(plotdir, 'meteograms')\n",
    "\n",
    "dateformat = '%H:%M' \n",
    "formatter = dates.DateFormatter(dateformat)\n",
    "locator = dates.MinuteLocator(byminute=[0, 15, 30, 45])\n",
    "minorlocator = None\n",
    "timelabel = 'Time (HH:MM)'\n",
    "xaxislimits = [dates.date2num(datetime_range[0]), dates.date2num(datetime_range[-1])]\n",
    "meteo_T_Td_range = [10., 25.]\n",
    "\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    conv_rs_df = conv_rs_df_dict[dis_name]\n",
    "    datetimes_PIPS_conv = conv_rs_df.index.to_pydatetime()\n",
    "    plottimes = dates.date2num(datetimes_PIPS_conv)\n",
    "    T_PIPS = conv_rs_df['fasttemp']\n",
    "    Td_PIPS = conv_rs_df['dewpoint']\n",
    "   \n",
    "    fig, ax = plt.subplots()\n",
    "    fields = [T_PIPS, Td_PIPS]\n",
    "    fieldparamdicts = [PIPSplot.temp_params, PIPSplot.dewpoint_params]\n",
    "    ax = PIPSplot.plotmeteogram(ax, [plottimes], fields, fieldparamdicts)\n",
    "    axparamdict1 = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "                    'minorxlocator': minorlocator, 'axeslimits': [xaxislimits, meteo_T_Td_range],\n",
    "                    'axeslabels': [timelabel, r'Temperature ($^{\\circ}$C)']}\n",
    "    axparamdicts = [axparamdict1]\n",
    "    ax, = PIPSplot.set_meteogram_axes([ax], axparamdicts)\n",
    "    figfilepath = os.path.join(meteogram_dir, dis_name + '_T_Td.png')\n",
    "    plt.savefig(figfilepath, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:09:04.125781Z",
     "start_time": "2019-09-10T15:09:01.819689Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot observed DSD meteograms\n",
    "\n",
    "# Prepare axis parameters\n",
    "# We'll use the model times just for the boundaries of the x-axis\n",
    "timelimits = [datetime_range[0], datetime_range[-1]]\n",
    "diamlimits = [0.0, 9.0]\n",
    "diamytick = 1.0\n",
    "DSDtype = 'observed'\n",
    "locator = dates.MinuteLocator(byminute=[0,15,30,45])\n",
    "minorlocator = dates.MinuteLocator(byminute=range(0,60,5))\n",
    "dateformat = '%H:%M'\n",
    "formatter = dates.DateFormatter(dateformat)\n",
    "\n",
    "axparams = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "            'minorxlocator': minorlocator,\n",
    "            'axeslimits': [timelimits, diamlimits],\n",
    "            'majorylocator': ticker.MultipleLocator(base=diamytick),\n",
    "            'axeslabels': [None, 'D (mm)']}\n",
    "\n",
    "# Ok, now we should have everything ready to go to plot the meteograms.\n",
    "# Let'er rip!\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND = logND_PIPS_dict[dis_name]\n",
    "    D0 = D0_PIPS_dict[dis_name] * 1000. # Get to mm again\n",
    "    dBZ = dBZ_PIPS_dict[dis_name]\n",
    "    PSDstarttimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_edges'])\n",
    "    PSDmidtimes = dates.date2num(PSD_datetimes_rs_PIPS_dict[dis_name]['PSD_datetimes_centers'])\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'D_0': D0, 'dBZ': dBZ}\n",
    "    \n",
    "    dis_plot_name = dis_name + '_' + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_dir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:30:56.514775Z",
     "start_time": "2019-09-10T15:30:56.403392Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in the model fields from previously generated netCDF files\n",
    "\n",
    "# Choose a member\n",
    "member = 1\n",
    "member_dir, member_prefix = get_ARPS_member_dir_and_prefix(member, cycle)\n",
    "ncfilename = member_prefix + '_fields.nc'\n",
    "ncdir = '/Users/dawson29/sshfs_mounts/depot/data/Projects/vortexse_enkf_dsd_study/data/nc'\n",
    "ncfilepath = os.path.join(ncdir, ncfilename)\n",
    "\n",
    "# Open the Dataset\n",
    "var_ds = xr.open_dataset(ncfilepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:31:37.733620Z",
     "start_time": "2019-09-10T15:30:59.761958Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Interpolate the model variables to the PIPS locations\n",
    "x_coords = [a[0] for a in dis_dict['dmodloclist']]\n",
    "y_coords = [a[1] for a in dis_dict['dmodloclist']]\n",
    "\n",
    "x_coords_da = xr.DataArray(x_coords, coords=[dis_names], dims=['PIPS'])\n",
    "y_coords_da = xr.DataArray(y_coords, coords=[dis_names], dims=['PIPS'])\n",
    "\n",
    "#var_ds_interp = var_ds.interpolate_na(dim='time')\n",
    "var_ds_interp = var_ds.interp(xc=x_coords_da, yc=y_coords_da)\n",
    "#var_ds_interp = var_ds_interp.interpolate_na(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:31:41.385372Z",
     "start_time": "2019-09-10T15:31:39.506278Z"
    }
   },
   "outputs": [],
   "source": [
    "p_interp = var_ds_interp['p']\n",
    "pt_interp = var_ds_interp['pt']\n",
    "qv_interp = var_ds_interp['qv']\n",
    "\n",
    "T_model_PIPS = thermo.calT(p_interp, pt_interp) - 273.15\n",
    "Td_model_PIPS = thermo.calTd(p_interp, qv_interp) - 273.15\n",
    "\n",
    "\n",
    "dateformat = '%H:%M' \n",
    "formatter = dates.DateFormatter(dateformat)\n",
    "locator = dates.MinuteLocator(byminute=[0,15,30,45])\n",
    "minorlocator = None\n",
    "timelabel = 'Time (HH:MM)'\n",
    "plottimes = dates.date2num(datetime_range)\n",
    "xaxislimits = [plottimes[0], plottimes[-1]]\n",
    "meteo_T_Td_range = [10., 25.]\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    #print i\n",
    "    fig, ax = plt.subplots()\n",
    "    T_model_PIPS_plt = T_model_PIPS.sel(PIPS=dis_name)\n",
    "    Td_model_PIPS_plt = Td_model_PIPS.sel(PIPS=dis_name)\n",
    "    fields = [T_model_PIPS_plt, Td_model_PIPS_plt]\n",
    "    fieldparamdicts = [PIPSplot.temp_params, PIPSplot.dewpoint_params]\n",
    "    ax = PIPSplot.plotmeteogram(ax, [plottimes], fields, fieldparamdicts)\n",
    "    axparamdict1 = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "                    'minorxlocator': minorlocator, 'axeslimits': [xaxislimits, meteo_T_Td_range],\n",
    "                    'axeslabels': [timelabel, r'Temperature ($^{\\circ}$C)']}\n",
    "    axparamdicts = [axparamdict1]\n",
    "    ax, = PIPSplot.set_meteogram_axes([ax], axparamdicts)\n",
    "    figfilepath = os.path.join(meteogram_dir, dis_name + '_model_member_{:02d}_T_Td.png'.format(member))\n",
    "    plt.savefig(figfilepath, dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:31:43.183067Z",
     "start_time": "2019-09-10T15:31:43.103405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save for posterity. The DSD parameters are now computed on the model grid first, and then interpolated to\n",
    "# the PIPS points: EDIT: brought this back. Computing the parameters *first* seems to have problems. I don't\n",
    "# yet know why.\n",
    "\n",
    "# Compute raw model DSD at PIPS locations\n",
    "rhor = 1000.\n",
    "cr = np.pi / 6. * rhor\n",
    "\n",
    "qr_model_PIPS = var_ds_interp['qr']\n",
    "nr_model_PIPS = var_ds_interp['nr']\n",
    "zr_model_PIPS = var_ds_interp['zr']\n",
    "rho_model_PIPS = thermo.calrho(p_interp, pt_interp, qv_interp)\n",
    "\n",
    "# Shape parameter\n",
    "# alphar_atPIPS = dualpol.solve_alpha_iter(rhoa_atPIPS, mu, qr_atPIPS, nr_atPIPS, zr_atPIPS, rhor)\n",
    "alphar_model_PIPS = dsd.solve_alpha(rho_model_PIPS, cr, qr_model_PIPS, nr_model_PIPS, zr_model_PIPS)\n",
    "# Intercept parameter\n",
    "N0r_model_PIPS = dsd.calc_N0_gamma(rho_model_PIPS, qr_model_PIPS, nr_model_PIPS, cr, alphar_model_PIPS)\n",
    "# Slope parameter\n",
    "lamdar_model_PIPS = dsd.calc_lamda_gamma(rho_model_PIPS, qr_model_PIPS, nr_model_PIPS, cr, alphar_model_PIPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:31:44.943706Z",
     "start_time": "2019-09-10T15:31:44.878121Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save for posterity, now part of var_ds dataset above: EDIT: brought this back\n",
    "\n",
    "# Temp fix until I get the above functions to work properly with xarray\n",
    "# convert alphar, N0r, lamdar back to DataArrays\n",
    "\n",
    "alphar_model_allPIPS_da = xr.DataArray(alphar_model_PIPS,\n",
    "                                    coords={\n",
    "                                        'time': qr_model_PIPS['time'],\n",
    "                                        'PIPS': ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B']\n",
    "                                    },\n",
    "                                    dims=['time', 'PIPS'])\n",
    "N0r_model_allPIPS_da = xr.DataArray(N0r_model_PIPS,\n",
    "                                    coords={\n",
    "                                        'time': qr_model_PIPS['time'],\n",
    "                                        'PIPS': ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B']\n",
    "                                    },\n",
    "                                    dims=['time', 'PIPS'])\n",
    "lamdar_model_allPIPS_da = xr.DataArray(lamdar_model_PIPS,\n",
    "                                    coords={\n",
    "                                        'time': qr_model_PIPS['time'],\n",
    "                                        'PIPS': ['PIPS1A', 'PIPS1B', 'PIPS2A', 'PIPS2B']\n",
    "                                    },\n",
    "                                    dims=['time', 'PIPS'])\n",
    "\n",
    "print(lamdar_model_allPIPS_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:31:46.731955Z",
     "start_time": "2019-09-10T15:31:46.637654Z"
    }
   },
   "outputs": [],
   "source": [
    "# Interpolate the PIPS DSD to the model times\n",
    "\n",
    "ND_interp_to_model_times_dict = {}\n",
    "logND_interp_to_model_times_dict = {}\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    \n",
    "    ND = ND_PIPS_dict[dis_name]\n",
    "    # Rename time dimension to match\n",
    "    ND = ND.rename({'time_10s': 'time'})\n",
    "    ND_interp_model = ND.interp_like(var_ds_interp['ND'])\n",
    "    \n",
    "    # Now recompute logND from new interpolated ND\n",
    "    logND_interp_model = np.log10(ND_interp_model)\n",
    "    logND_interp_model = logND_interp_model.where(logND_interp_model > -np.inf)\n",
    "    \n",
    "    ND_interp_to_model_times_dict[dis_name] = ND_interp_model\n",
    "    logND_interp_to_model_times_dict[dis_name] = logND_interp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:31:48.615453Z",
     "start_time": "2019-09-10T15:31:48.409633Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute some radar and DSD parameters from observed DSD that was just interpolated to model times\n",
    "dBZ_PIPS_interp_to_model_times_dict = {}\n",
    "D0_PIPS_interp_to_model_times_dict = {}\n",
    "for dis_name in dis_names:\n",
    "    dBZ_PIPS_interp = dsd.calc_dBZ_from_bins(ND_interp_to_model_times_dict[dis_name])\n",
    "    dBZ_PIPS_interp = dBZ_PIPS_interp.where(dBZ_PIPS_interp > -np.inf)\n",
    "    dBZ_PIPS_interp_to_model_times_dict[dis_name] = dBZ_PIPS_interp\n",
    "    D0_PIPS_interp = dsd.calc_D0_bin(ND_interp_to_model_times_dict[dis_name])\n",
    "    D0_PIPS_interp_to_model_times_dict[dis_name] = D0_PIPS_interp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:31:52.760224Z",
     "start_time": "2019-09-10T15:31:50.340902Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plot observed DSD meteograms interpolated to model times\n",
    "\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "# Prepare axis parameters\n",
    "# We'll use the model times for the boundaries of the x-axis\n",
    "timelimits = [datetime_range[0], datetime_range[-1]]\n",
    "diamlimits = [0.0, 9.0]\n",
    "diamytick = 1.0\n",
    "DSDtype = 'observed'\n",
    "locator = dates.MinuteLocator(byminute=[0,15,30,45])\n",
    "minorlocator = dates.MinuteLocator(byminute=range(0,60,5))\n",
    "dateformat = '%H:%M'\n",
    "formatter = dates.DateFormatter(dateformat)\n",
    "\n",
    "axparams = {'majorxlocator': locator, 'majorxformatter': formatter,\n",
    "            'minorxlocator': minorlocator,\n",
    "            'axeslimits': [timelimits, diamlimits],\n",
    "            'majorylocator': ticker.MultipleLocator(base=diamytick),\n",
    "            'axeslabels': [None, 'D (mm)']}\n",
    "\n",
    "# Ok, now we should have everything ready to go to plot the meteograms.\n",
    "# Let'er rip!\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND = logND_interp_to_model_times_dict[dis_name]\n",
    "    D0 = D0_PIPS_interp_to_model_times_dict[dis_name] * 1000. # Get to mm again\n",
    "    dBZ = dBZ_PIPS_interp_to_model_times_dict[dis_name]\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'D_0': D0, 'dBZ': dBZ}\n",
    "    \n",
    "    dis_plot_name = dis_name + '_interp_to_model_' + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_dir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:31:54.576429Z",
     "start_time": "2019-09-10T15:31:54.479523Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute N(D) from the raw model parameters at original model times\n",
    "import pyPIPS.parsivel_params as pp\n",
    "\n",
    "ND_model_raw_PIPS_dict = {}\n",
    "logND_model_raw_PIPS_dict = {}\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    mid_diameters_da = vd_matrix_da_dict[dis_name]['diameter']\n",
    "    alphar_model_PIPS_da = alphar_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    N0r_model_PIPS_da = N0r_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    lamdar_model_PIPS_da = lamdar_model_allPIPS_da.loc[dict(PIPS=dis_name)]\n",
    "    # Broadcast DSD parameter DataArrays to get everyone on the same dimensional page\n",
    "    mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da = \\\n",
    "        xr.broadcast(mid_diameters_da, N0r_model_PIPS_da, lamdar_model_PIPS_da, alphar_model_PIPS_da)\n",
    "    # Transpose these DataArrays to get time as the first dimension\n",
    "    mid_diameters_da = mid_diameters_da.T\n",
    "    N0r_model_PIPS_da = N0r_model_PIPS_da.T\n",
    "    lamdar_model_PIPS_da = lamdar_model_PIPS_da.T\n",
    "    alphar_model_PIPS_da = alphar_model_PIPS_da.T\n",
    "    \n",
    "    ND_model_raw_PIPS = dsd.calc_binned_DSD_from_params(N0r_model_PIPS_da, lamdar_model_PIPS_da, \n",
    "                                                        alphar_model_PIPS_da, mid_diameters_da)\n",
    "    logND_model_raw_PIPS = np.log10(ND_model_raw_PIPS)\n",
    "    logND_model_raw_PIPS = logND_model_raw_PIPS.where(logND_model_raw_PIPS > -np.inf)\n",
    "    \n",
    "    ND_model_raw_PIPS_dict[dis_name] = ND_model_raw_PIPS\n",
    "    logND_model_raw_PIPS_dict[dis_name] = logND_model_raw_PIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:31:56.501614Z",
     "start_time": "2019-09-10T15:31:56.309757Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute some radar and DSD parameters from the raw model DSDs (interpolated to PIPS locations but not times)\n",
    "dBZ_raw_model_dict = {}\n",
    "D0_raw_model_dict = {}\n",
    "for dis_name in dis_names:\n",
    "    dBZ_raw_model = dsd.calc_dBZ_from_bins(ND_model_raw_PIPS_dict[dis_name])\n",
    "    dBZ_raw_model = dBZ_raw_model.where(dBZ_raw_model > -np.inf)\n",
    "    dBZ_raw_model_dict[dis_name] = dBZ_raw_model\n",
    "    D0_raw_model = dsd.calc_D0_bin(ND_model_raw_PIPS_dict[dis_name])\n",
    "    D0_raw_model_dict[dis_name] = D0_raw_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:32:00.631881Z",
     "start_time": "2019-09-10T15:31:58.268063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now plot the raw model DSDs (interpolated to PIPS locations but not the times)\n",
    "\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "for i, dis_name in enumerate(dis_names):\n",
    "    logND = logND_model_raw_PIPS_dict[dis_name]\n",
    "    logND = logND.where(logND > -1.0)\n",
    "    D0 = D0_raw_model_dict[dis_name] * 1000. # Get to mm again\n",
    "    dBZ = dBZ_raw_model_dict[dis_name]\n",
    "    disvars = {'min_diameter': min_diameters, 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND.T, 'D_0': D0, 'dBZ': dBZ}\n",
    "    dis_plot_name = dis_name + '_raw_model_member_{:02d}_'.format(member) + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_dir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T15:32:06.744324Z",
     "start_time": "2019-09-10T15:32:02.332678Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now compute sampled PSDs from the model\n",
    "\n",
    "# Now plot the sampled model DSD\n",
    "\n",
    "sampling_interval = 60.\n",
    "sampling_length = pp.parsivel_parameters['sensor_length_mm'] / 1000. # To m\n",
    "sampling_width = pp.parsivel_parameters['sensor_width_mm'] / 1000. # To m\n",
    "\n",
    "Dmax = 9.\n",
    "Dmax_index = np.searchsorted(mid_diameters, Dmax, side='right')\n",
    "# print(Dmax_index)\n",
    "mid_diameters_trunc = np.array(mid_diameters[:Dmax_index+1]) / 1000.\n",
    "min_diameters_trunc = np.array(min_diameters[:Dmax_index+1]) / 1000.\n",
    "max_diameters_trunc = np.array(max_diameters[:Dmax_index+1]) / 1000.\n",
    "\n",
    "PSDstarttimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_edges'])\n",
    "PSDmidtimes = dates.date2num(PSD_datetimes_model_dict['PSD_datetimes_centers'])\n",
    "\n",
    "for dis_name in dis_names:\n",
    "    nr_model = var_ds_interp['nr'].loc[dict(PIPS=dis_name)].values\n",
    "    lamdar_model = var_ds_interp['lamdar'].loc[dict(PIPS=dis_name)].values\n",
    "    alphar_model = var_ds_interp['alphar'].loc[dict(PIPS=dis_name)].values\n",
    "    rho_model = var_ds_interp['rho'].loc[dict(PIPS=dis_name)].values\n",
    "\n",
    "    # print(mid_diameters_trunc.shape)\n",
    "    Vtr = pips.calc_empirical_fallspeed(mid_diameters_trunc * 1000., correct_rho=True, rho=rho_model)\n",
    "\n",
    "    Vtr = Vtr.T\n",
    "#     print(Vtr[0])\n",
    "#     print(Vtr.shape)\n",
    "#     print(mid_diameters_trunc.shape)\n",
    "    ND_samp_series = np.zeros((np.size(PSDmidtimes), np.size(mid_diameters_trunc)))\n",
    "\n",
    "#     print(ND_samp_series.shape)\n",
    "#     print(nr_model[0])\n",
    "    # Nc_bin_tmp2 = np.zeros((np.size(N0r), np.size(D[:Dmax_index+1])))\n",
    "    # Nc_bin2 = np.zeros((np.size(np.array(sampling_times)), np.size(D[:Dmax_index+1])))\n",
    "\n",
    "    all_valid = (not np.isnan(lamdar_model[0]) and (not np.isnan(alphar_model[0])) and (not np.isnan(nr_model[0])))\n",
    "    if all_valid:\n",
    "        # Special treatment for first sampling time. Just assume DSD valid at that time was constant for the previous \n",
    "        # sampling interval\n",
    "        sample_dict = sim.create_random_gamma_DSD(nr_model[0], lamdar_model[0], \n",
    "                                                  alphar_model[0], Vtr[0], sampling_length, \n",
    "                                                  sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                                  max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                                  remove_margins=True, rhocorrect=True, rho=rho_model[0], verbose=True)\n",
    "\n",
    "\n",
    "        ND_sample = sample_dict['ND']\n",
    "        pcount_binned_sample = sample_dict['pcount_binned']\n",
    "    #     print(ND_sample.shape)\n",
    "    #     print(ND_samp_series.shape)\n",
    "        ND_samp_series[0, :] = 1.e-3*ND_sample\n",
    "        # Nc_bin_tmp2[0, :] = 1.e-3*ND_sample\n",
    "        # Nc_bin2[0, :] = Nc_bin_tmp2[0, :]\n",
    "\n",
    "    \n",
    "    pcount_binned_samples = []\n",
    "    for index in range(np.size(PSDmidtimes[1:-1])):\n",
    "        all_valid = (not np.isnan(lamdar_model[index]) \n",
    "                     and (not np.isnan(alphar_model[index]))\n",
    "                     and (not np.isnan(nr_model[index])))\n",
    "        print('nr = ', nr_model[index], 'lamdar = ', lamdar_model[index], 'alphar = ', alphar_model[index])\n",
    "        if all_valid:\n",
    "            sample_dict = sim.create_random_gamma_DSD(nr_model[index], lamdar_model[index], \n",
    "                                                      alphar_model[index], Vtr[index], sampling_length, \n",
    "                                                      sampling_width, min_diameters_trunc, mid_diameters_trunc, \n",
    "                                                      max_diameters_trunc, Dmax=Dmax, sampling_interval=sampling_interval,\n",
    "                                                      remove_margins=True, rhocorrect=True, rho=rho_model[index], verbose=True)\n",
    "            ND_sample = sample_dict['ND']\n",
    "            pcount_binned_samples.append(sample_dict['pcount_binned'])\n",
    "            ND_samp_series[index, :] = 1.e-3*ND_sample\n",
    "        else:\n",
    "            pcount_binned_samples.append(np.zeros_like(sample_dict['pcount_binned']))\n",
    "\n",
    "    pcount_binned_samples = np.array(pcount_binned_samples)\n",
    "    \n",
    "    ND_samp_da = xr.DataArray(ND_samp_series,\n",
    "                                     coords={'time': PSDmidtimes,\n",
    "                                             'diameter': ('diameter_bin', mid_diameters_trunc * 1000.),\n",
    "                                             'max_diameter': ('diameter_bin', max_diameters_trunc * 1000.),\n",
    "                                             'min_diameter': ('diameter_bin', min_diameters_trunc * 1000.)\n",
    "                                            },\n",
    "                                     dims=['time', 'diameter_bin'])\n",
    "    \n",
    "    ND_samp_da = ND_samp_da.fillna(0.0)\n",
    "\n",
    "    # sampling_volumes_D = sim.calc_sampling_volumes_D(Vtr, Dr, Dmax, sampling_interval, sampling_area)\n",
    "    # for s, sample_index in enumerate(sample_indices[:-1]):\n",
    "    #     sample_index_end = sample_indices[s+1]\n",
    "    #     current_sample_indices = slice(sample_index, sample_index_end, None)\n",
    "    #     pcount_binned = np.sum(pcount_binned_samples[current_sample_indices], axis=0)\n",
    "    #     Nc_bin2[s+1, :] = 1.e-3*sim.calc_ND(pcount_binned, sampling_volumes_D, Dr, Dl, Dmax)\n",
    "    # #     Nc_bin2[s+1, :] = np.sum(Nc_bin_tmp2[current_sample_indices, :]*dt[current_sample_indices, None], axis = 0)/sampling_interval\n",
    "    # #     print \"s = \", s\n",
    "    # #     print \"sample time (beginning) = \", sampling_times[s]\n",
    "    # #     print \"sample time (end) = \", sampling_times[s+1]\n",
    "    # #     print \"dt[current_sample_indices] = \", dt[current_sample_indices]\n",
    "    # #     print \"Nc_bin_tmp = \", Nc_bin_tmp[current_sample_indices, :], dt[current_sample_indices]\n",
    "    # #     print \"Nc_bin = \", Nc_bin[s+1, :]\n",
    "\n",
    "    logND_samp_da = np.log10(ND_samp_da)\n",
    "    logND_samp_da = logND_samp_da.where(logND_samp_da > -1.0)\n",
    "\n",
    "    # Compute dBZ and D0 from the sampled DSD\n",
    "    dBZ_samp_model = dsd.calc_dBZ_from_bins(ND_samp_da)\n",
    "    dBZ_samp_model = dBZ_samp_model.where(dBZ_samp_model > -np.inf)\n",
    "    D0_samp_model = dsd.calc_D0_bin(ND_samp_da) * 1000. # Get to mm again\n",
    "    \n",
    "    disvars = {'min_diameter': min_diameters[:Dmax_index+1], 'PSDstarttimes': PSDstarttimes,\n",
    "               'PSDmidtimes': PSDmidtimes, 'logND': logND_samp_da.T, 'D_0': D0_samp_model, \n",
    "               'dBZ': dBZ_samp_model}\n",
    "    dis_plot_name = dis_name + '_sampled_model_member_{:02d}_'.format(member) + DSDtype\n",
    "    PIPSplot.plotDSDmeteograms(dis_plot_name, meteogram_dir, axparams, disvars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-10T03:32:22.342960Z",
     "start_time": "2019-09-10T03:32:22.267770Z"
    }
   },
   "outputs": [],
   "source": [
    "print(model_vars_PIPS_dict['PIPS1B']['nr'].loc['2016-03-31T22:25':'2016-03-31T22:30'])\n",
    "print(model_gamma_DSD_params_PIPS_dict['PIPS1B']['lamdar'].loc['2016-03-31T22:25':'2016-03-31T22:30'])\n",
    "print(model_gamma_DSD_params_PIPS_dict['PIPS1B']['alphar'].loc['2016-03-31T22:25':'2016-03-31T22:30'])\n",
    "print(model_gamma_DSD_params_PIPS_modeltimes_dict['PIPS1B']['alphar'].loc['2016-03-31T22:25':'2016-03-31T22:30'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old Cells Below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a plot of the disdrometer transects through the storm, \n",
    "# choosing a representative sweeptime as the backdrop\n",
    "plotdir = '/Users/dawson29/Dropbox/Projects/VORTEXSE/vortexse_enkf_dsd_study/plots/'+casedate\n",
    "if not os.path.exists(plotdir):\n",
    "    os.makedirs(plotdir)\n",
    "# If there is no reference sweeptime in the dictionary, just use the first one\n",
    "sweeptimeref = radar_dict[casedate]['sweeptime_ref']\n",
    "ustorm, vstorm = radar_dict[casedate]['feature_motion']\n",
    "sweepindex = np.searchsorted(sweeptimelist, sweeptimeref)\n",
    "sweepdtrel = [(sweeptime - sweeptimeref).total_seconds() for sweeptime in sweeptimelist]\n",
    "deployed = dis_dict_at_radar[casedate]['convdata_at_sweeptimes']['deployed']\n",
    "# dxsr = [[dx - ustorm * dt if d else np.nan for dt, d in zip(sweepdtrel, dp)] for dx, dp in zip(dxlist, deployed)]\n",
    "# dysr = [[dy - vstorm * dt if d else np.nan for dt, d in zip(sweepdtrel, dp)] for dy, dp in zip(dylist, deployed)]\n",
    "dxsr = [[dx - ustorm * dt for dt in sweepdtrel] for dx in dxlist]\n",
    "dysr = [[dy - vstorm * dt for dt in sweepdtrel] for dy in dylist]\n",
    "\n",
    "# Split up disdrometer storm relative locations by whether the disdrometer was actually deployed at a given time\n",
    "dxsr_d = [[x for x, d in zip(dx, dp) if d] for dx, dp in zip(dxsr, deployed)]\n",
    "dxsr_nd = [[x for x, d in zip(dx, dp) if not d] for dx, dp in zip(dxsr, deployed)]\n",
    "dysr_d = [[y for y, d in zip(dy, dp) if d] for dy, dp in zip(dysr, deployed)]\n",
    "dysr_nd = [[y for y, d in zip(dy, dp) if not d] for dy, dp in zip(dysr, deployed)]\n",
    "\n",
    "print sweeptimelist\n",
    "print sweepindex\n",
    "print deployed[0]\n",
    "print dxsr[0]\n",
    "print dxsr_d[0]\n",
    "print dxsr_nd[0]\n",
    "\n",
    "# Set plotting limits to center on the disdrometer locations \n",
    "Dxmin = np.nanmin(np.array(dxsr))\n",
    "Dxmax = np.nanmax(np.array(dxsr))\n",
    "Dymin = np.nanmin(np.array(dysr))\n",
    "Dymax = np.nanmax(np.array(dysr))\n",
    "plotlims = [Dxmin - 5000., Dxmax + 10000., Dymin - 10000., Dymax + 10000.]\n",
    "# plotlims = [15000., 45000., -15000., 0.]\n",
    "\n",
    "figlist, gridlist = radar.plotsweep_pyART(radlims, plotlims, outfieldnames, radarsweeplist[sweepindex], ovrmap, \n",
    "                                              ovrdis, dis_name_list, dxy_list, fields_D_list)\n",
    "ax = gridlist[0][0]\n",
    "\n",
    "dis_names = dis_dict_at_radar[casedate]['dis_names']\n",
    "\n",
    "for j, dx, dy, dx_d, dy_d, dx_nd, dy_nd, dp, dname in zip(xrange(len(dxlist)), dxsr, dysr, dxsr_d, dysr_d, \n",
    "                                                          dxsr_nd, dysr_nd, deployed, dis_names):\n",
    "    ax.plot(dx_d, dy_d, ls='-', c='k')\n",
    "    ax.plot(dx, dy, ls='--', c='k')\n",
    "    if dp[sweepindex]:\n",
    "        marker = 'o'\n",
    "    else:\n",
    "        marker = 'x'\n",
    "    ax.plot(dx[sweepindex], dy[sweepindex], marker=marker, ms=10, c='k')\n",
    "    ax.annotate(dname, (dx[sweepindex] + 1000., dy[sweepindex] - 2000.), clip_on=True)\n",
    "\n",
    "gridlist[0].cbar_axes[0].set_ylabel('Z (dBZ)')\n",
    "ax.set_xlabel('km')\n",
    "ax.set_ylabel('km')\n",
    "    \n",
    "figlist[0].canvas.draw()\n",
    "figlist[0].set_size_inches(10., 10., forward = True)\n",
    "\n",
    "figpath = os.path.join(plotdir, casedate+'_transects_radar.eps', bbox_inches='tight')\n",
    "plt.savefig(figpath, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up stuff for time composites\n",
    "# Initial grid limits (m)\n",
    "gridlims = [0., 100000., 0., 100000.]\n",
    "\n",
    "# Width of composite box in m\n",
    "compositewidthx = 60000.\n",
    "compositewidthy = 60000.\n",
    "\n",
    "# Width of search box for extremum in m\n",
    "searchboxwidthx = 12000.\n",
    "searchboxwidthy = 12000.\n",
    "\n",
    "# Name of variable for whose extrema to track for compositing (that's an awkward phrasing)\n",
    "tracking_varname = 'vortz'\n",
    "# level (height in m) at which to track the extrema\n",
    "tracking_level = 0.0 # 0.0 for 5 June, 3000.0 for 7 June, 3000.0 for 9 June \n",
    "# Type of extremum (max or min)\n",
    "tracking_extremum = 'max'\n",
    "# Threshold magnitude of extremum below which to throw out a time from the composite\n",
    "tracking_thresh = 0.01\n",
    "\n",
    "compositedict = {'gridlims': gridlims,\n",
    "                 'compositewidth': (compositewidthx, compositewidthy), \n",
    "                 'searchboxwidth': (searchboxwidthx, searchboxwidthy),\n",
    "                 'tracking_varname': tracking_varname,\n",
    "                 'tracking_extremum': tracking_extremum, \n",
    "                 'tracking_level': tracking_level, \n",
    "                 'tracking_thresh': tracking_thresh}\n",
    "\n",
    "# Read in the model information for the case we want\n",
    "model_dict = sim.set_dh(casedate, init_model_dict, radar_dict)\n",
    "dh = model_dict[casedate]['DataHandler']\n",
    "modeltime_ref = model_dict[casedate]['modeltime_ref']\n",
    "\n",
    "# Read in the model grid info\n",
    "grid_dict = sim.read_model_grid(dh)\n",
    "# Initialize composite parameters\n",
    "if model_dict[casedate]['composite']:\n",
    "    compositedict = sim.init_composite(compositedict, grid_dict)\n",
    "\n",
    "# dp_data, consts = dh.loadMicrophysics()\n",
    "# # Extract the lowest model level and store in dp_data_2D\n",
    "# dp_data_2D = {}\n",
    "# for key, dat in dp_data.iteritems():\n",
    "#     dp_data_2D[key] = dat[:,:,0]\n",
    "# dp_data_plot = {}\n",
    "# for key, dat in dp_data_2D.iteritems():\n",
    "#     dp_data_plot[key] = dat.swapaxes(0, 1).squeeze()\n",
    "# dp_data_plot_list.append(dp_data_plot)\n",
    "\n",
    "if model_dict[casedate]['composite']:\n",
    "    print \"Building composite!\"\n",
    "    varcompdict = sim.build_composite(casedate, model_dict, compositedict, dh)\n",
    "    Zmod = varcompdict['DBZ']\n",
    "    Zmodplot = Zmod\n",
    "else:    \n",
    "    Zmod = dh.loadModelReflectivity()\n",
    "    Zmodplot = Zmod[:, :, 0].T\n",
    "# Zmodplot_list.append(Zmodplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Quick plot of the reflectivity composite for testing\n",
    "runname = model_dict[casedate]['runname']\n",
    "model_times = model_dict[casedate]['model_times']\n",
    "xckm_comp, yckm_comp = compositedict['ccoords']\n",
    "uccomp = varcompdict['UC']\n",
    "vccomp = varcompdict['VC']\n",
    "wind_pltscale = 2.0 # Scale of wind vectors\n",
    "windintv = 4        # Interval in grid points to plot wind vectors\n",
    "\n",
    "clevels = np.arange(0., 85., 5.)\n",
    "cintv = clevels[1] - clevels[0]\n",
    "norm, cmap = ctables.registry.get_with_steps('NWSReflectivity', 5., 5.)\n",
    "cbarlevels = ticker.MultipleLocator(base=cintv)\n",
    "clabel = 'Z (dBZ)'\n",
    "# qrplot = varcompdict['qg']*1000.\n",
    "# clevels = np.arange(0., 5.05, 0.05)\n",
    "# cintv = clevels[1] - clevels[0]\n",
    "# norm = None\n",
    "# cmap = cm.Blues\n",
    "# cbarlevels = np.arange(0., 5.5, 0.5) # ticker.MultipleLocator(base=1.0)\n",
    "# clabel = 'qg (g/kg)'\n",
    "\n",
    "compfig = plt.figure(figsize=(8,8))\n",
    "compax = compfig.add_subplot(111)\n",
    "plt.title(model_dict[casedate]['runname'])\n",
    "dBZplt = compax.contourf(xckm_comp, yckm_comp, Zmodplot, levels=clevels, cmap=cmap)\n",
    "# compax.contour(xskm_comp,yskm_comp,dBZ.T,levels=np.arange(30.,90.,10.),colors='k')\n",
    "windplt = compax.quiver(xckm_comp[::windintv], yckm_comp[::windintv], uccomp[::windintv, ::windintv],\n",
    "    vccomp[::windintv, ::windintv], pivot='middle', units='width', scale_units='width', \n",
    "    scale=1200.0/float(wind_pltscale), width=0.001*float(wind_pltscale), headwidth=5, headlength=5, color='k')\n",
    "\n",
    "compax.set_aspect('equal')\n",
    "divider = make_axes_locatable(compax)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad = 0.05)\n",
    "clabels = cbarlevels\n",
    "clvllocator = ticker.FixedLocator(clabels)\n",
    "plt.colorbar(dBZplt, ticks=clvllocator, cax=cax)\n",
    "cax.set_ylabel('Z (dBZ)')\n",
    "#cax.set_ylabel('qg (g/kg)')\n",
    "\n",
    "compax.set_xlabel('km')\n",
    "compax.set_ylabel('km')\n",
    "\n",
    "compfig.savefig(runname+'_dBZ_comp_{:06d}_{:06d}.pdf'.format(int(model_times[0]),int(model_times[-1])),dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a plot of the disdrometer transects through the *simulated* storm, \n",
    "# choosing a representative *model time* as the backdrop\n",
    "\n",
    "# First we need to set up a list of x and y coordinates within the model for each disdrometer. We'll use the\n",
    "# coordinates computed relative to the radar above, but shifted so that they are in the same relative position\n",
    "# to the model storm (necessarily subjective) as they are for the observed storm.\n",
    "# For example, we'll use P2's coordinates near the tip of the hook for 5 June 2009.\n",
    "\n",
    "if model_dict[casedate]['composite']:\n",
    "    xref_model, yref_model = model_dict[casedate]['ref_coords_comp']\n",
    "    # Some coordinate array shenanigans\n",
    "    composite_grid_dict = sim.get_composite_grid(grid_dict, compositedict)\n",
    "    xcplot = composite_grid_dict['xcplot']\n",
    "    ycplot = composite_grid_dict['ycplot']\n",
    "    xeplot = composite_grid_dict['xeplot']\n",
    "    yeplot = composite_grid_dict['yeplot']\n",
    "    xcorplot = composite_grid_dict['xcorplot']\n",
    "    ycorplot = composite_grid_dict['ycorplot']\n",
    "else:\n",
    "    xref_model, yref_model = model_dict[casedate]['ref_coords']\n",
    "    xcplot = grid_dict['xcplot']\n",
    "    ycplot = grid_dict['ycplot']\n",
    "    xeplot = grid_dict['xeplot']\n",
    "    yeplot = grid_dict['yeplot']\n",
    "    xcorplot = grid_dict['xcorplot']\n",
    "    ycorplot = grid_dict['ycorplot']\n",
    "\n",
    "xref_rad = dxlist[-1]\n",
    "yref_rad = dylist[-1]\n",
    "\n",
    "xshift = xref_model - xref_rad\n",
    "yshift = yref_model - yref_rad\n",
    "\n",
    "dxmodlist = [dx + xshift for dx in dxlist]\n",
    "dymodlist = [dy + yshift for dy in dylist]\n",
    "\n",
    "# Using sweeptimelist here to facilitate matching with the disdrometer locations on the radar plot.\n",
    "sweepdtrel = [(sweeptime - modeltime_ref).total_seconds() for sweeptime in sweeptimelist]\n",
    "dxsrm = [[dx - ustorm * dt for dt in sweepdtrel] for dx in dxmodlist]\n",
    "dysrm = [[dy - vstorm * dt for dt in sweepdtrel] for dy in dymodlist]\n",
    "\n",
    "# Split up disdrometer storm relative locations by whether the disdrometer was actually deployed at a given time\n",
    "dxsrm_d = [[x for x, d in zip(dx, dp) if d] for dx, dp in zip(dxsrm, deployed)]\n",
    "dxsrm_nd = [[x for x, d in zip(dx, dp) if not d] for dx, dp in zip(dxsrm, deployed)]\n",
    "dysrm_d = [[y for y, d in zip(dy, dp) if d] for dy, dp in zip(dysrm, deployed)]\n",
    "dysrm_nd = [[y for y, d in zip(dy, dp) if not d] for dy, dp in zip(dysrm, deployed)]\n",
    "\n",
    "# Get the index where the relative time is zero. Use this below to put the probes\n",
    "# at the proper location along the transect corresponding to the reference time.\n",
    "modelindex_ref = np.searchsorted(sweepdtrel, 0.)\n",
    "\n",
    "# Set plotting limits to center on the disdrometer locations \n",
    "Dxmin = np.array(dxsrm).min()\n",
    "Dxmax = np.array(dxsrm).max()\n",
    "Dymin = np.array(dysrm).min()\n",
    "Dymax = np.array(dysrm).max()\n",
    "plotlims = [Dxmin - 5000., Dxmax + 10000., Dymin - 10000., Dymax + 10000.]\n",
    "\n",
    "fig = None\n",
    "ax = None\n",
    "ptype = 2\n",
    "xlim = [plotlims[0], plotlims[1]]\n",
    "ylim = [plotlims[2], plotlims[3]]\n",
    "clevels = np.arange(0., 85., 5.)\n",
    "cintv = clevels[1] - clevels[0]\n",
    "norm, cmap = ctables.registry.get_with_steps('NWSReflectivity', 5., 5.)\n",
    "cbarlevels = ticker.MultipleLocator(base=cintv)\n",
    "clabel = 'Z (dBZ)'\n",
    "cformat = None\n",
    "ovrmap = False\n",
    "gis_info = None\n",
    "numovr = 0\n",
    "axesticks = [10000., 10000.]\n",
    "\n",
    "fig, ax = pm.plotsingle(fig, ax, ptype, xcplot, ycplot, xcorplot, ycorplot, xlim, ylim, Zmodplot, clevels, cmap, norm,\n",
    "                            cbarlevels, clabel, cformat, ovrmap, gis_info, numovr, None, None, None, None, None,\n",
    "                            axesticks)\n",
    "\n",
    "for j, dx, dy, dx_d, dy_d, dx_nd, dy_nd, dp, dname in zip(xrange(len(dxmodlist)), dxsrm, dysrm, dxsrm_d, dysrm_d, \n",
    "                                                          dxsrm_nd, dysrm_nd, deployed, dis_names):\n",
    "    ax.plot(dx, dy, ls='--', c='k')\n",
    "    ax.plot(dx_d, dy_d, ls='-', c='k')\n",
    "    if dp[modelindex_ref]:\n",
    "        marker = 'o'\n",
    "    else:\n",
    "        marker = 'x'\n",
    "    ax.plot(dx[sweepindex], dy[sweepindex], marker=marker, ms=10, c='k')\n",
    "    ax.annotate(dname, (dx[sweepindex] + 1000., dy[sweepindex] - 2000.), clip_on=True)\n",
    "    \n",
    "fig.canvas.draw()\n",
    "fig.set_size_inches(10., 10., forward = True)\n",
    "figpath = os.path.join(plotdir, casedate+'_transects_model.eps', bbox_inches='tight')\n",
    "plt.savefig(figpath, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in time series and add to dis_dict\n",
    "dis_dict = sim.read_probe_time_series(casedate, dis_dict, radar_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not model_dict[casedate]['composite']:\n",
    "    varlists = ['DBZ', 'TH', 'QV', 'P']\n",
    "    varlistv = ['U', 'V']\n",
    "    varlist_derived = ['PTE', 'UC', 'VC']\n",
    "\n",
    "    vardictlist = sim.read_vardict(casedate, model_dict, varlists, varlistv, varlist_derived)\n",
    "\n",
    "    vardict = vardictlist[0]\n",
    "    grid_dict_in = grid_dict\n",
    "else:\n",
    "    vardict = varcompdict\n",
    "    grid_dict_in = composite_grid_dict\n",
    "\n",
    "# Find grid intersections\n",
    "dis_ts_model_dict = sim.find_transect_grid_intersections(casedate, grid_dict_in, dis_dict, model_dict, radar_dict, \n",
    "                                     vardict, plot_locations=False, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print dis_dict[casedate].keys()\n",
    "print dis_ts_model_dict.keys()\n",
    "print varcompdict['rhoa']\n",
    "dis_ts_vars_points = dis_ts_model_dict['dis_ts_vars_points']\n",
    "print len(dis_ts_vars_points)\n",
    "dis_names = dis_dict[casedate]['dis_names']\n",
    "print len(dis_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print dis_dict[casedate]['timeseries'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate and plot observed DSD transects\n",
    "transect_DSD_obs_dict = sim.calc_obs_transect(casedate, dis_dict, dis_ts_model_dict, Dmax=9.0, plot_transects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate and plot model DSD transects\n",
    "transect_DSD_dict = sim.interp_model_to_transect(casedate, dis_dict, model_dict, dis_ts_model_dict,\n",
    "                                                 sampling_interval=60., add_hail=False, \n",
    "                                                 use_bins_for_interp=True, use_Parsivel_simulator=True, \n",
    "                                                 Dmax=9.0, plot_transects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make some one-to-one plots of D0 (model) vs. D0 (disdrometer)\n",
    "\n",
    "yvals = sim.D*1000.\n",
    "xvals = sim.D*1000.\n",
    "color_list = ['r', 'orange', 'g', 'b']\n",
    "\n",
    "D0r_mod = transect_DSD_dict['D0r']\n",
    "D0r_mod_sampled = transect_DSD_dict['D0r_ps']\n",
    "\n",
    "D0r_obs = transect_DSD_obs_dict['D0r_obs']\n",
    "D0r_obs_gam = transect_DSD_obs_dict['D0r_gam']\n",
    "\n",
    "for d, dis_name in enumerate(dis_dict[casedate]['dis_names']):\n",
    "    obs = D0r_obs_gam[d]*1000.\n",
    "    mod = D0r_mod[d]*1000.\n",
    "    mod_sampled = D0r_mod_sampled[d]*1000.\n",
    "    bias_mod = ((np.nansum(mod-obs))/np.nansum(obs))\n",
    "    bias_mod_sampled = ((np.nansum(mod_sampled-obs))/np.nansum(obs))\n",
    "    cc_mod = pd.DataFrame({'obs': obs, 'mod': mod}).corr().iloc[0, 1]\n",
    "    cc_mod_sampled = pd.DataFrame({'obs': obs, 'mod': mod_sampled}).corr().iloc[0, 1]\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    plt.scatter(obs, mod, c=color_list[d], marker='*', label=dis_name+'_gamma')\n",
    "    plt.scatter(obs, mod_sampled, c=color_list[d], marker='+', alpha=0.75, label=dis_name+'_sampled')\n",
    "    ax.plot(xvals, yvals, lw=2, color='k')\n",
    "    ax.set_xlim(0.0, 8.0)\n",
    "    ax.set_ylim(0.0, 8.0)\n",
    "    ax.set_xlabel('Observed')\n",
    "    ax.set_ylabel('Model')\n",
    "    ax.text(0.6, 0.20, 'Bias (model): {:2.2f}'.format(bias_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.15, 'Cor. Coef. (model) {:2.3f}'.format(cc_mod), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.10, 'Bias (model sampled): {:2.2f}'.format(bias_mod_sampled), transform=ax.transAxes)\n",
    "    ax.text(0.6, 0.05, 'Cor. Coef. (model sampled) {:2.3f}'.format(cc_mod_sampled), transform=ax.transAxes)\n",
    "    plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Calculate dual-pol variables for both the model and observations and make scatterplots of Z vs. ZDR\n",
    "# Z, ZDR relation from Cao et al. (2008)\n",
    "Zh_Cao = np.arange(10, 61, 0.1)\n",
    "Zdr_Cao = 10**((-2.6857 * 10**-4 * Zh_Cao**2) + 0.04892 * Zh_Cao - 1.4287)\n",
    "\n",
    "scattfile = '../tmatrix/S-band/SCTT_RAIN_fw100.dat'\n",
    "wavelength = 10.7 # mm\n",
    "Dmax = 9.0\n",
    "Dmax_index = sim.get_Dmax_index(Dmax)\n",
    "color_list = ['r', 'orange', 'g', 'b']\n",
    "ND_mod = transect_DSD_dict['ND']\n",
    "ND_obs = transect_DSD_obs_dict['ND']\n",
    "\n",
    "\n",
    "\n",
    "for d, dis_name in enumerate(dis_dict[casedate]['dis_names']):\n",
    "    dualpol_mod = dis.calpolrain(wavelength, scattfile, ND_mod[d].T, dis.bin_width[:Dmax_index])\n",
    "    dualpol_obs = dis.calpolrain(wavelength, scattfile, ND_obs[d].T, dis.bin_width[:Dmax_index])\n",
    "    sample_xlocs = np.array([xylocs[0] for xylocs in dis_ts_model_dict['dis_ts_xyslocs'][d]])\n",
    "    print sample_xlocs\n",
    "    sample_ylocs = np.array([xylocs[1] for xylocs in dis_ts_model_dict['dis_ts_xyslocs'][d]])\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    sc = plt.scatter(dualpol_mod['dBZ'], dualpol_mod['ZDR'], c=sample_xlocs, marker='*', label=dis_name+'_mod',\n",
    "                     vmin=-15000., vmax=15000.)\n",
    "    plt.scatter(dualpol_obs['dBZ'], dualpol_obs['ZDR'], c=sample_xlocs, marker='o', label=dis_name+'_obs', vmin=-15000., vmax=15000.)\n",
    "    plt.plot(Zh_Cao, Zdr_Cao, c='k', ls='-', lw=1.0)\n",
    "    plt.colorbar(sc)\n",
    "    ax.set_xlabel('dBZ')\n",
    "    ax.set_ylabel(r'Z$_DR$')\n",
    "    ax.set_xlim(10.0, 60.0)\n",
    "    ax.set_ylim(-2.0, 6.0)\n",
    "    plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:pyPIPS]",
   "language": "python",
   "name": "conda-env-pyPIPS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
